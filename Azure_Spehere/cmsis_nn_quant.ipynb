{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cmsis_nn_quant.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amita-kapoor/ailabs/blob/master/Azure_Spehere/cmsis_nn_quant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eOhW0hBJ_do",
        "colab_type": "text"
      },
      "source": [
        "# Complementary colab for blog post \n",
        "### [How to run deep learning model on microcontroller with CMSIS-NN (Part 3)](https://www.dlology.com/blog/how-to-run-deep-learning-model-on-microcontroller-with-cmsis-nn-part-3/)\n",
        "# Install caffe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A1ADqgj_2p5",
        "colab_type": "code",
        "outputId": "d6323332-9e1d-4fe0-e16b-b0835628f984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt-get update -y -qq\n",
        "!apt-get upgrade -y -qq\n",
        "!apt-get install -y -qq build-essential cmake git pkg-config\n",
        "!apt-get install -y -qq libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler\n",
        "!apt-get install -y -qq libatlas-base-dev \n",
        "!apt-get install -y -qq --no-install-recommends libboost-all-dev\n",
        "!apt-get install -y -qq libgflags-dev libgoogle-glog-dev liblmdb-dev"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../base-files_10.1ubuntu2.8_amd64.deb ...\n",
            "Unpacking base-files (10.1ubuntu2.8) over (10.1ubuntu2.7) ...\n",
            "Setting up base-files (10.1ubuntu2.8) ...\n",
            "Installing new version of config file /etc/issue ...\n",
            "Installing new version of config file /etc/issue.net ...\n",
            "Installing new version of config file /etc/lsb-release ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../bsdutils_1%3a2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking bsdutils (1:2.31.1-0.4ubuntu3.6) over (1:2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up bsdutils (1:2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libext2fs2_1.44.1-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libext2fs2:amd64 (1.44.1-1ubuntu1.3) over (1.44.1-1ubuntu1.2) ...\n",
            "Setting up libext2fs2:amd64 (1.44.1-1ubuntu1.3) ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../e2fsprogs_1.44.1-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking e2fsprogs (1.44.1-1ubuntu1.3) over (1.44.1-1ubuntu1.2) ...\n",
            "Setting up e2fsprogs (1.44.1-1ubuntu1.3) ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libblkid1_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking libblkid1:amd64 (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up libblkid1:amd64 (2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libfdisk1_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking libfdisk1:amd64 (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up libfdisk1:amd64 (2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libmount1_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking libmount1:amd64 (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up libmount1:amd64 (2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libsmartcols1_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking libsmartcols1:amd64 (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up libsmartcols1:amd64 (2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../fdisk_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking fdisk (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up fdisk (2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../util-linux_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking util-linux (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up util-linux (2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../mount_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking mount (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Preparing to unpack .../libcom-err2_1.44.1-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libcom-err2:amd64 (1.44.1-1ubuntu1.3) over (1.44.1-1ubuntu1.2) ...\n",
            "Setting up libcom-err2:amd64 (1.44.1-1ubuntu1.3) ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libgcrypt20_1.8.1-4ubuntu1.2_amd64.deb ...\n",
            "Unpacking libgcrypt20:amd64 (1.8.1-4ubuntu1.2) over (1.8.1-4ubuntu1.1) ...\n",
            "Setting up libgcrypt20:amd64 (1.8.1-4ubuntu1.2) ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libss2_1.44.1-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libss2:amd64 (1.44.1-1ubuntu1.3) over (1.44.1-1ubuntu1.2) ...\n",
            "Setting up libss2:amd64 (1.44.1-1ubuntu1.3) ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libgnutls30_3.5.18-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libgnutls30:amd64 (3.5.18-1ubuntu1.3) over (3.5.18-1ubuntu1.1) ...\n",
            "Setting up libgnutls30:amd64 (3.5.18-1ubuntu1.3) ...\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../00-openssl_1.1.1-1ubuntu2.1~18.04.6_amd64.deb ...\n",
            "Unpacking openssl (1.1.1-1ubuntu2.1~18.04.6) over (1.1.1-1ubuntu2.1~18.04.5) ...\n",
            "Preparing to unpack .../01-ca-certificates_20190110~18.04.1_all.deb ...\n",
            "Unpacking ca-certificates (20190110~18.04.1) over (20180409) ...\n",
            "Preparing to unpack .../02-libsqlite3-0_3.22.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libsqlite3-0:amd64 (3.22.0-1ubuntu0.3) over (3.22.0-1ubuntu0.1) ...\n",
            "Preparing to unpack .../03-python-apt-common_1.6.5ubuntu0.3_all.deb ...\n",
            "Unpacking python-apt-common (1.6.5ubuntu0.3) over (1.6.5ubuntu0.2) ...\n",
            "Preparing to unpack .../04-python3-apt_1.6.5ubuntu0.3_amd64.deb ...\n",
            "Unpacking python3-apt (1.6.5ubuntu0.3) over (1.6.5ubuntu0.2) ...\n",
            "Preparing to unpack .../05-binutils-x86-64-linux-gnu_2.30-21ubuntu1~18.04.3_amd64.deb ...\n",
            "Unpacking binutils-x86-64-linux-gnu (2.30-21ubuntu1~18.04.3) over (2.30-21ubuntu1~18.04.2) ...\n",
            "Preparing to unpack .../06-binutils-common_2.30-21ubuntu1~18.04.3_amd64.deb ...\n",
            "Unpacking binutils-common:amd64 (2.30-21ubuntu1~18.04.3) over (2.30-21ubuntu1~18.04.2) ...\n",
            "Preparing to unpack .../07-binutils_2.30-21ubuntu1~18.04.3_amd64.deb ...\n",
            "Unpacking binutils (2.30-21ubuntu1~18.04.3) over (2.30-21ubuntu1~18.04.2) ...\n",
            "Preparing to unpack .../08-libbinutils_2.30-21ubuntu1~18.04.3_amd64.deb ...\n",
            "Unpacking libbinutils:amd64 (2.30-21ubuntu1~18.04.3) over (2.30-21ubuntu1~18.04.2) ...\n",
            "Preparing to unpack .../09-libsasl2-modules-db_2.1.27~101-g0780600+dfsg-3ubuntu2.1_amd64.deb ...\n",
            "Unpacking libsasl2-modules-db:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.1) over (2.1.27~101-g0780600+dfsg-3ubuntu2) ...\n",
            "Preparing to unpack .../10-libsasl2-2_2.1.27~101-g0780600+dfsg-3ubuntu2.1_amd64.deb ...\n",
            "Unpacking libsasl2-2:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.1) over (2.1.27~101-g0780600+dfsg-3ubuntu2) ...\n",
            "Preparing to unpack .../11-libldap-common_2.4.45+dfsg-1ubuntu1.5_all.deb ...\n",
            "Unpacking libldap-common (2.4.45+dfsg-1ubuntu1.5) over (2.4.45+dfsg-1ubuntu1.4) ...\n",
            "Preparing to unpack .../12-libldap-2.4-2_2.4.45+dfsg-1ubuntu1.5_amd64.deb ...\n",
            "Unpacking libldap-2.4-2:amd64 (2.4.45+dfsg-1ubuntu1.5) over (2.4.45+dfsg-1ubuntu1.4) ...\n",
            "Preparing to unpack .../13-nvidia-driver-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Unpacking nvidia-driver-440 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../14-libnvidia-extra-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Unpacking libnvidia-extra-440:amd64 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../15-libnvidia-common-440_440.82-0ubuntu0~0.18.04.2_all.deb ...\n",
            "Unpacking libnvidia-common-440 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../16-libnvidia-decode-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Unpacking libnvidia-decode-440:amd64 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../17-libnvidia-compute-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Unpacking libnvidia-compute-440:amd64 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../18-libnvidia-gl-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Unpacking libnvidia-gl-440:amd64 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../19-nvidia-dkms-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Removing all DKMS Modules\n",
            "Done.\n",
            "Unpacking nvidia-dkms-440 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../20-nvidia-kernel-source-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Unpacking nvidia-kernel-source-440 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../21-nvidia-kernel-common-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Unpacking nvidia-kernel-common-440 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../22-nvidia-compute-utils-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "System has not been booted with systemd as init system (PID 1). Can't operate.\n",
            "System has not been booted with systemd as init system (PID 1). Can't operate.\n",
            "Unpacking nvidia-compute-utils-440 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../23-libnvidia-encode-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Unpacking libnvidia-encode-440:amd64 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../24-nvidia-utils-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Unpacking nvidia-utils-440 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../25-xserver-xorg-video-nvidia-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Unpacking xserver-xorg-video-nvidia-440 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../26-libnvidia-ifr1-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Unpacking libnvidia-ifr1-440:amd64 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../27-libnvidia-fbc1-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Unpacking libnvidia-fbc1-440:amd64 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../28-libnvidia-cfg1-440_440.82-0ubuntu0~0.18.04.2_amd64.deb ...\n",
            "Unpacking libnvidia-cfg1-440:amd64 (440.82-0ubuntu0~0.18.04.2) over (440.82-0ubuntu0~0.18.04.1) ...\n",
            "Preparing to unpack .../29-libpulse0_1%3a11.1-1ubuntu7.8_amd64.deb ...\n",
            "Unpacking libpulse0:amd64 (1:11.1-1ubuntu7.8) over (1:11.1-1ubuntu7.7) ...\n",
            "Preparing to unpack .../30-linux-libc-dev_4.15.0-101.102_amd64.deb ...\n",
            "Unpacking linux-libc-dev:amd64 (4.15.0-101.102) over (4.15.0-72.81) ...\n",
            "Preparing to unpack .../31-software-properties-common_0.96.24.32.13_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.32.13) over (0.96.24.32.12) ...\n",
            "Preparing to unpack .../32-python3-software-properties_0.96.24.32.13_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.32.13) over (0.96.24.32.12) ...\n",
            "Preparing to unpack .../33-r-cran-dplyr_1.0.0-1cran1.1804.0_amd64.deb ...\n",
            "Unpacking r-cran-dplyr (1.0.0-1cran1.1804.0) over (0.8.5-1cran1ppabionic0) ...\n",
            "Preparing to unpack .../34-r-cran-ggplot2_3.3.1-1cran1.1804.0_all.deb ...\n",
            "Unpacking r-cran-ggplot2 (3.3.1-1cran1.1804.0) over (3.3.0-1cran1ppabionic0) ...\n",
            "Preparing to unpack .../35-r-cran-haven_2.3.1-1cran1.1804.0_amd64.deb ...\n",
            "Unpacking r-cran-haven (2.3.1-1cran1.1804.0) over (2.3.0-1cran1.1804.0) ...\n",
            "Preparing to unpack .../36-r-cran-rmarkdown_2.2-1cran1.1804.0_all.deb ...\n",
            "Unpacking r-cran-rmarkdown (2.2-1cran1.1804.0) over (2.1-1cran1ppabionic0) ...\n",
            "Setting up python-apt-common (1.6.5ubuntu0.3) ...\n",
            "Setting up python3-apt (1.6.5ubuntu0.3) ...\n",
            "Setting up libnvidia-common-440 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up libnvidia-fbc1-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up libldap-common (2.4.45+dfsg-1ubuntu1.5) ...\n",
            "Setting up libsasl2-modules-db:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.1) ...\n",
            "Setting up linux-libc-dev:amd64 (4.15.0-101.102) ...\n",
            "Setting up mount (2.31.1-0.4ubuntu3.6) ...\n",
            "Setting up libsasl2-2:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.1) ...\n",
            "Setting up libnvidia-compute-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up libpulse0:amd64 (1:11.1-1ubuntu7.8) ...\n",
            "Setting up r-cran-haven (2.3.1-1cran1.1804.0) ...\n",
            "Setting up nvidia-utils-440 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up binutils-common:amd64 (2.30-21ubuntu1~18.04.3) ...\n",
            "Setting up nvidia-kernel-common-440 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up libnvidia-cfg1-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up libldap-2.4-2:amd64 (2.4.45+dfsg-1ubuntu1.5) ...\n",
            "Setting up r-cran-dplyr (1.0.0-1cran1.1804.0) ...\n",
            "Setting up openssl (1.1.1-1ubuntu2.1~18.04.6) ...\n",
            "Setting up libsqlite3-0:amd64 (3.22.0-1ubuntu0.3) ...\n",
            "Setting up python3-software-properties (0.96.24.32.13) ...\n",
            "Setting up libnvidia-decode-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up r-cran-ggplot2 (3.3.1-1cran1.1804.0) ...\n",
            "Setting up nvidia-compute-utils-440 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up libnvidia-extra-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up r-cran-rmarkdown (2.2-1cran1.1804.0) ...\n",
            "Setting up ca-certificates (20190110~18.04.1) ...\n",
            "Updating certificates in /etc/ssl/certs...\n",
            "2 added, 8 removed; done.\n",
            "Setting up libnvidia-encode-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up nvidia-kernel-source-440 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up xserver-xorg-video-nvidia-440 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up libnvidia-gl-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up software-properties-common (0.96.24.32.13) ...\n",
            "Setting up libbinutils:amd64 (2.30-21ubuntu1~18.04.3) ...\n",
            "Setting up nvidia-dkms-440 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Loading new nvidia-440.82 DKMS files...\n",
            "It is likely that 4.19.104+ belongs to a chroot's host\n",
            "Building for 4.15.0-101-generic\n",
            "Building for architecture x86_64\n",
            "Building initial module for 4.15.0-101-generic\n",
            "Done.\n",
            "\n",
            "nvidia:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/4.15.0-101-generic/updates/dkms/\n",
            "\n",
            "nvidia-modeset.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/4.15.0-101-generic/updates/dkms/\n",
            "\n",
            "nvidia-drm.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/4.15.0-101-generic/updates/dkms/\n",
            "\n",
            "nvidia-uvm.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/4.15.0-101-generic/updates/dkms/\n",
            "\n",
            "depmod...\n",
            "\n",
            "DKMS: install completed.\n",
            "Setting up libnvidia-ifr1-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up binutils-x86-64-linux-gnu (2.30-21ubuntu1~18.04.3) ...\n",
            "Setting up nvidia-driver-440 (440.82-0ubuntu0~0.18.04.2) ...\n",
            "Setting up binutils (2.30-21ubuntu1~18.04.3) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for systemd (237-3ubuntu10.41) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for dbus (1.12.2-1ubuntu1.1) ...\n",
            "Processing triggers for ca-certificates (20190110~18.04.1) ...\n",
            "Updating certificates in /etc/ssl/certs...\n",
            "0 added, 0 removed; done.\n",
            "Running hooks in /etc/ca-certificates/update.d...\n",
            "\n",
            "done.\n",
            "done.\n",
            "Selecting previously unselected package libhdf5-serial-dev.\n",
            "(Reading database ... 144362 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libhdf5-serial-dev_1.10.0-patch1+docs-4_all.deb ...\n",
            "Unpacking libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Selecting previously unselected package libleveldb1v5:amd64.\n",
            "Preparing to unpack .../1-libleveldb1v5_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb1v5:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package libleveldb-dev:amd64.\n",
            "Preparing to unpack .../2-libleveldb-dev_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb-dev:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package libprotobuf-lite10:amd64.\n",
            "Preparing to unpack .../3-libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libprotobuf-dev:amd64.\n",
            "Preparing to unpack .../4-libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libsnappy-dev:amd64.\n",
            "Preparing to unpack .../5-libsnappy-dev_1.1.7-1_amd64.deb ...\n",
            "Unpacking libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Setting up libleveldb1v5:amd64 (1.20-2) ...\n",
            "Setting up libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Setting up libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libleveldb-dev:amd64 (1.20-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Selecting previously unselected package libgflags2.2.\n",
            "(Reading database ... 144533 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libgflags2.2_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags2.2 (2.2.1-1) ...\n",
            "Selecting previously unselected package libgflags-dev.\n",
            "Preparing to unpack .../1-libgflags-dev_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags-dev (2.2.1-1) ...\n",
            "Selecting previously unselected package libgoogle-glog0v5.\n",
            "Preparing to unpack .../2-libgoogle-glog0v5_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Selecting previously unselected package libgoogle-glog-dev.\n",
            "Preparing to unpack .../3-libgoogle-glog-dev_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog-dev (0.3.5-1) ...\n",
            "Selecting previously unselected package liblmdb0:amd64.\n",
            "Preparing to unpack .../4-liblmdb0_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package liblmdb-dev:amd64.\n",
            "Preparing to unpack .../5-liblmdb-dev_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package lmdb-doc.\n",
            "Preparing to unpack .../6-lmdb-doc_0.9.21-1ubuntu0.1_all.deb ...\n",
            "Unpacking lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Setting up libgflags2.2 (2.2.1-1) ...\n",
            "Setting up libgflags-dev (2.2.1-1) ...\n",
            "Setting up liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Setting up liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Setting up libgoogle-glog-dev (0.3.5-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d8Ji0XQASEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y -qq libopencv-dev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0-UN87iAjYd",
        "colab_type": "code",
        "outputId": "742ffce8-607b-4f2b-f588-de2ff19f8db2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt install -y -qq caffe-cuda"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following package was automatically installed and is no longer required:\n",
            "  r-cran-plogr\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  caffe-tools-cuda cython3 fonts-lyx javascript-common libblosc1\n",
            "  libcaffe-cuda1 libcublas9.1 libcudart9.1 libcurand9.1 libjs-jquery\n",
            "  libjs-jquery-ui python-matplotlib-data python-tables-data python3-bs4\n",
            "  python3-caffe-cuda python3-chardet python3-cycler python3-dateutil\n",
            "  python3-decorator python3-gflags python3-h5py python3-html5lib\n",
            "  python3-ipython python3-ipython-genutils python3-leveldb python3-lxml\n",
            "  python3-matplotlib python3-networkx python3-nose python3-numexpr\n",
            "  python3-olefile python3-pandas python3-pandas-lib python3-pexpect\n",
            "  python3-pickleshare python3-pil python3-pkg-resources python3-prompt-toolkit\n",
            "  python3-protobuf python3-ptyprocess python3-pygments python3-pyparsing\n",
            "  python3-pywt python3-scipy python3-simplegeneric python3-six python3-skimage\n",
            "  python3-skimage-lib python3-tables python3-tables-lib python3-traitlets\n",
            "  python3-tz python3-wcwidth python3-webencodings python3-yaml\n",
            "  ttf-bitstream-vera\n",
            "Suggested packages:\n",
            "  libcaffe-cuda-dev caffe-doc cython-doc apache2 | lighttpd | httpd\n",
            "  libjs-jquery-ui-docs python-cycler-doc python-h5py-doc python3-genshi\n",
            "  python3-lxml-dbg python-lxml-doc dvipng gir1.2-gtk-3.0 ghostscript inkscape\n",
            "  ipython3 python-matplotlib-doc python3-cairocffi python3-gi-cairo\n",
            "  python3-gobject python3-pyqt4 python3-sip python3-tornado\n",
            "  texlive-extra-utils texlive-latex-extra ttf-staypuft python3-pydotplus\n",
            "  python-nose-doc python-pandas-doc python-pexpect-doc python-pil-doc\n",
            "  python3-pil-dbg python3-setuptools python-pyparsing-doc python-scipy-doc\n",
            "  python-skimage-doc python-tables-doc python3-netcdf4 vitables\n",
            "The following NEW packages will be installed:\n",
            "  caffe-cuda caffe-tools-cuda cython3 fonts-lyx javascript-common libblosc1\n",
            "  libcaffe-cuda1 libcublas9.1 libcudart9.1 libcurand9.1 libjs-jquery\n",
            "  libjs-jquery-ui python-matplotlib-data python-tables-data python3-bs4\n",
            "  python3-caffe-cuda python3-chardet python3-cycler python3-dateutil\n",
            "  python3-decorator python3-gflags python3-h5py python3-html5lib\n",
            "  python3-ipython python3-ipython-genutils python3-leveldb python3-lxml\n",
            "  python3-matplotlib python3-networkx python3-nose python3-numexpr\n",
            "  python3-olefile python3-pandas python3-pandas-lib python3-pexpect\n",
            "  python3-pickleshare python3-pil python3-pkg-resources python3-prompt-toolkit\n",
            "  python3-protobuf python3-ptyprocess python3-pygments python3-pyparsing\n",
            "  python3-pywt python3-scipy python3-simplegeneric python3-six python3-skimage\n",
            "  python3-skimage-lib python3-tables python3-tables-lib python3-traitlets\n",
            "  python3-tz python3-wcwidth python3-webencodings python3-yaml\n",
            "  ttf-bitstream-vera\n",
            "0 upgraded, 57 newly installed, 0 to remove and 6 not upgraded.\n",
            "Need to get 120 MB of archives.\n",
            "After this operation, 315 MB of additional disk space will be used.\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package python3-yaml.\n",
            "(Reading database ... 144811 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python3-yaml_3.12-1build2_amd64.deb ...\n",
            "Unpacking python3-yaml (3.12-1build2) ...\n",
            "Selecting previously unselected package libcublas9.1:amd64.\n",
            "Preparing to unpack .../01-libcublas9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcublas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcudart9.1:amd64.\n",
            "Preparing to unpack .../02-libcudart9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcudart9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcurand9.1:amd64.\n",
            "Preparing to unpack .../03-libcurand9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcurand9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcaffe-cuda1:amd64.\n",
            "Preparing to unpack .../04-libcaffe-cuda1_1.0.0-6build1_amd64.deb ...\n",
            "Unpacking libcaffe-cuda1:amd64 (1.0.0-6build1) ...\n",
            "Selecting previously unselected package caffe-tools-cuda.\n",
            "Preparing to unpack .../05-caffe-tools-cuda_1.0.0-6build1_amd64.deb ...\n",
            "Unpacking caffe-tools-cuda (1.0.0-6build1) ...\n",
            "Selecting previously unselected package cython3.\n",
            "Preparing to unpack .../06-cython3_0.26.1-0.4_amd64.deb ...\n",
            "Unpacking cython3 (0.26.1-0.4) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../07-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-dateutil.\n",
            "Preparing to unpack .../08-python3-dateutil_2.6.1-1_all.deb ...\n",
            "Unpacking python3-dateutil (2.6.1-1) ...\n",
            "Selecting previously unselected package python3-gflags.\n",
            "Preparing to unpack .../09-python3-gflags_1.5.1-5_all.deb ...\n",
            "Unpacking python3-gflags (1.5.1-5) ...\n",
            "Selecting previously unselected package python3-h5py.\n",
            "Preparing to unpack .../10-python3-h5py_2.7.1-2_amd64.deb ...\n",
            "Unpacking python3-h5py (2.7.1-2) ...\n",
            "Selecting previously unselected package python3-decorator.\n",
            "Preparing to unpack .../11-python3-decorator_4.1.2-1_all.deb ...\n",
            "Unpacking python3-decorator (4.1.2-1) ...\n",
            "Selecting previously unselected package python3-ptyprocess.\n",
            "Preparing to unpack .../12-python3-ptyprocess_0.5.2-1_all.deb ...\n",
            "Unpacking python3-ptyprocess (0.5.2-1) ...\n",
            "Selecting previously unselected package python3-pexpect.\n",
            "Preparing to unpack .../13-python3-pexpect_4.2.1-1_all.deb ...\n",
            "Unpacking python3-pexpect (4.2.1-1) ...\n",
            "Selecting previously unselected package python3-pickleshare.\n",
            "Preparing to unpack .../14-python3-pickleshare_0.7.4-2_all.deb ...\n",
            "Unpacking python3-pickleshare (0.7.4-2) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../15-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-wcwidth.\n",
            "Preparing to unpack .../16-python3-wcwidth_0.1.7+dfsg1-1_all.deb ...\n",
            "Unpacking python3-wcwidth (0.1.7+dfsg1-1) ...\n",
            "Selecting previously unselected package python3-prompt-toolkit.\n",
            "Preparing to unpack .../17-python3-prompt-toolkit_1.0.15-1_all.deb ...\n",
            "Unpacking python3-prompt-toolkit (1.0.15-1) ...\n",
            "Selecting previously unselected package python3-pygments.\n",
            "Preparing to unpack .../18-python3-pygments_2.2.0+dfsg-1_all.deb ...\n",
            "Unpacking python3-pygments (2.2.0+dfsg-1) ...\n",
            "Selecting previously unselected package python3-simplegeneric.\n",
            "Preparing to unpack .../19-python3-simplegeneric_0.8.1-1_all.deb ...\n",
            "Unpacking python3-simplegeneric (0.8.1-1) ...\n",
            "Selecting previously unselected package python3-ipython-genutils.\n",
            "Preparing to unpack .../20-python3-ipython-genutils_0.2.0-1_all.deb ...\n",
            "Unpacking python3-ipython-genutils (0.2.0-1) ...\n",
            "Selecting previously unselected package python3-traitlets.\n",
            "Preparing to unpack .../21-python3-traitlets_4.3.2-1_all.deb ...\n",
            "Unpacking python3-traitlets (4.3.2-1) ...\n",
            "Selecting previously unselected package python3-ipython.\n",
            "Preparing to unpack .../22-python3-ipython_5.5.0-1_all.deb ...\n",
            "Unpacking python3-ipython (5.5.0-1) ...\n",
            "Selecting previously unselected package python3-leveldb.\n",
            "Preparing to unpack .../23-python3-leveldb_0~svn68-3build3_amd64.deb ...\n",
            "Unpacking python3-leveldb (0~svn68-3build3) ...\n",
            "Selecting previously unselected package fonts-lyx.\n",
            "Preparing to unpack .../24-fonts-lyx_2.2.4-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking fonts-lyx (2.2.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package ttf-bitstream-vera.\n",
            "Preparing to unpack .../25-ttf-bitstream-vera_1.10-8_all.deb ...\n",
            "Unpacking ttf-bitstream-vera (1.10-8) ...\n",
            "Selecting previously unselected package python-matplotlib-data.\n",
            "Preparing to unpack .../26-python-matplotlib-data_2.1.1-2ubuntu3_all.deb ...\n",
            "Unpacking python-matplotlib-data (2.1.1-2ubuntu3) ...\n",
            "Selecting previously unselected package python3-pyparsing.\n",
            "Preparing to unpack .../27-python3-pyparsing_2.2.0+dfsg1-2_all.deb ...\n",
            "Unpacking python3-pyparsing (2.2.0+dfsg1-2) ...\n",
            "Selecting previously unselected package python3-tz.\n",
            "Preparing to unpack .../28-python3-tz_2018.3-2_all.deb ...\n",
            "Unpacking python3-tz (2018.3-2) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../29-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package libjs-jquery-ui.\n",
            "Preparing to unpack .../30-libjs-jquery-ui_1.12.1+dfsg-5_all.deb ...\n",
            "Unpacking libjs-jquery-ui (1.12.1+dfsg-5) ...\n",
            "Selecting previously unselected package python3-cycler.\n",
            "Preparing to unpack .../31-python3-cycler_0.10.0-1_all.deb ...\n",
            "Unpacking python3-cycler (0.10.0-1) ...\n",
            "Selecting previously unselected package python3-matplotlib.\n",
            "Preparing to unpack .../32-python3-matplotlib_2.1.1-2ubuntu3_amd64.deb ...\n",
            "Unpacking python3-matplotlib (2.1.1-2ubuntu3) ...\n",
            "Selecting previously unselected package python3-networkx.\n",
            "Preparing to unpack .../33-python3-networkx_1.11-1ubuntu3_all.deb ...\n",
            "Unpacking python3-networkx (1.11-1ubuntu3) ...\n",
            "Selecting previously unselected package python3-nose.\n",
            "Preparing to unpack .../34-python3-nose_1.3.7-3_all.deb ...\n",
            "Unpacking python3-nose (1.3.7-3) ...\n",
            "Selecting previously unselected package python3-pandas-lib.\n",
            "Preparing to unpack .../35-python3-pandas-lib_0.22.0-4ubuntu1_amd64.deb ...\n",
            "Unpacking python3-pandas-lib (0.22.0-4ubuntu1) ...\n",
            "Selecting previously unselected package python3-pandas.\n",
            "Preparing to unpack .../36-python3-pandas_0.22.0-4ubuntu1_all.deb ...\n",
            "Unpacking python3-pandas (0.22.0-4ubuntu1) ...\n",
            "Selecting previously unselected package python3-pil:amd64.\n",
            "Preparing to unpack .../37-python3-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking python3-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Selecting previously unselected package python3-protobuf.\n",
            "Preparing to unpack .../38-python3-protobuf_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking python3-protobuf (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package python3-scipy.\n",
            "Preparing to unpack .../39-python3-scipy_0.19.1-2ubuntu1_amd64.deb ...\n",
            "Unpacking python3-scipy (0.19.1-2ubuntu1) ...\n",
            "Selecting previously unselected package python3-skimage-lib:amd64.\n",
            "Preparing to unpack .../40-python3-skimage-lib_0.13.1-2_amd64.deb ...\n",
            "Unpacking python3-skimage-lib:amd64 (0.13.1-2) ...\n",
            "Selecting previously unselected package python3-pywt.\n",
            "Preparing to unpack .../41-python3-pywt_0.5.1-1.1ubuntu4_amd64.deb ...\n",
            "Unpacking python3-pywt (0.5.1-1.1ubuntu4) ...\n",
            "Selecting previously unselected package python3-skimage.\n",
            "Preparing to unpack .../42-python3-skimage_0.13.1-2_all.deb ...\n",
            "Unpacking python3-skimage (0.13.1-2) ...\n",
            "Selecting previously unselected package python3-caffe-cuda.\n",
            "Preparing to unpack .../43-python3-caffe-cuda_1.0.0-6build1_amd64.deb ...\n",
            "Unpacking python3-caffe-cuda (1.0.0-6build1) ...\n",
            "Selecting previously unselected package caffe-cuda.\n",
            "Preparing to unpack .../44-caffe-cuda_1.0.0-6build1_amd64.deb ...\n",
            "Unpacking caffe-cuda (1.0.0-6build1) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../45-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libblosc1.\n",
            "Preparing to unpack .../46-libblosc1_1.14.2+ds1-1_amd64.deb ...\n",
            "Unpacking libblosc1 (1.14.2+ds1-1) ...\n",
            "Selecting previously unselected package python-tables-data.\n",
            "Preparing to unpack .../47-python-tables-data_3.4.2-4_all.deb ...\n",
            "Unpacking python-tables-data (3.4.2-4) ...\n",
            "Selecting previously unselected package python3-bs4.\n",
            "Preparing to unpack .../48-python3-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python3-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python3-chardet.\n",
            "Preparing to unpack .../49-python3-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python3-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python3-webencodings.\n",
            "Preparing to unpack .../50-python3-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python3-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python3-html5lib.\n",
            "Preparing to unpack .../51-python3-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python3-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python3-lxml:amd64.\n",
            "Preparing to unpack .../52-python3-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python3-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-numexpr.\n",
            "Preparing to unpack .../53-python3-numexpr_2.6.4-1_amd64.deb ...\n",
            "Unpacking python3-numexpr (2.6.4-1) ...\n",
            "Selecting previously unselected package python3-olefile.\n",
            "Preparing to unpack .../54-python3-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python3-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python3-tables-lib.\n",
            "Preparing to unpack .../55-python3-tables-lib_3.4.2-4_amd64.deb ...\n",
            "Unpacking python3-tables-lib (3.4.2-4) ...\n",
            "Selecting previously unselected package python3-tables.\n",
            "Preparing to unpack .../56-python3-tables_3.4.2-4_all.deb ...\n",
            "Unpacking python3-tables (3.4.2-4) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up python3-yaml (3.12-1build2) ...\n",
            "Setting up libblosc1 (1.14.2+ds1-1) ...\n",
            "Setting up python3-pickleshare (0.7.4-2) ...\n",
            "Setting up python3-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python3-simplegeneric (0.8.1-1) ...\n",
            "Setting up python3-webencodings (0.5-2) ...\n",
            "Setting up python3-tables-lib (3.4.2-4) ...\n",
            "Setting up python3-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python3-olefile (0.45.1-1) ...\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "Setting up python3-pyparsing (2.2.0+dfsg1-2) ...\n",
            "Setting up python3-cycler (0.10.0-1) ...\n",
            "Setting up python-tables-data (3.4.2-4) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up python3-bs4 (4.6.0-1) ...\n",
            "Setting up python3-gflags (1.5.1-5) ...\n",
            "update-alternatives: using /usr/bin/python3-gflags2man to provide /usr/bin/gflags2man (gflags2man) in auto mode\n",
            "Setting up python3-skimage-lib:amd64 (0.13.1-2) ...\n",
            "Setting up python3-pandas-lib (0.22.0-4ubuntu1) ...\n",
            "Setting up python3-wcwidth (0.1.7+dfsg1-1) ...\n",
            "Setting up libcurand9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up python3-protobuf (3.0.0-9.1ubuntu1) ...\n",
            "Setting up python3-ipython-genutils (0.2.0-1) ...\n",
            "Setting up python3-nose (1.3.7-3) ...\n",
            "Setting up python3-chardet (3.0.4-1) ...\n",
            "Setting up python3-html5lib (0.999999999-1) ...\n",
            "Setting up libjs-jquery-ui (1.12.1+dfsg-5) ...\n",
            "Setting up libcublas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up ttf-bitstream-vera (1.10-8) ...\n",
            "Setting up cython3 (0.26.1-0.4) ...\n",
            "Setting up python3-pywt (0.5.1-1.1ubuntu4) ...\n",
            "Setting up libcudart9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up python3-decorator (4.1.2-1) ...\n",
            "Setting up python3-traitlets (4.3.2-1) ...\n",
            "Setting up python3-ptyprocess (0.5.2-1) ...\n",
            "Setting up python3-tz (2018.3-2) ...\n",
            "Setting up python3-leveldb (0~svn68-3build3) ...\n",
            "Setting up python3-dateutil (2.6.1-1) ...\n",
            "Setting up python3-h5py (2.7.1-2) ...\n",
            "Setting up fonts-lyx (2.2.4-0ubuntu0.18.04.1) ...\n",
            "Setting up python3-pygments (2.2.0+dfsg-1) ...\n",
            "Setting up libcaffe-cuda1:amd64 (1.0.0-6build1) ...\n",
            "Setting up python3-scipy (0.19.1-2ubuntu1) ...\n",
            "Setting up python3-prompt-toolkit (1.0.15-1) ...\n",
            "Setting up python-matplotlib-data (2.1.1-2ubuntu3) ...\n",
            "Setting up python3-numexpr (2.6.4-1) ...\n",
            "Setting up python3-tables (3.4.2-4) ...\n",
            "Setting up python3-pexpect (4.2.1-1) ...\n",
            "Setting up python3-networkx (1.11-1ubuntu3) ...\n",
            "Setting up python3-pandas (0.22.0-4ubuntu1) ...\n",
            "Setting up caffe-tools-cuda (1.0.0-6build1) ...\n",
            "Setting up python3-matplotlib (2.1.1-2ubuntu3) ...\n",
            "Setting up python3-ipython (5.5.0-1) ...\n",
            "Setting up python3-skimage (0.13.1-2) ...\n",
            "Setting up python3-caffe-cuda (1.0.0-6build1) ...\n",
            "Setting up caffe-cuda (1.0.0-6build1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqhn9qILBHWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import caffe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abFmIJxogvWm",
        "colab_type": "text"
      },
      "source": [
        "# Caffe train the *CIFAR10 Example* model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzjTcoaUrhKe",
        "colab_type": "text"
      },
      "source": [
        "## Train the model\n",
        "Start by cloning caffe repo since it contains some useful scripts to download and extract data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOJZVe2Wgxs7",
        "colab_type": "code",
        "outputId": "cfb58c7e-d04c-4e2c-9043-94542ecf7a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import os\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/BVLC/caffe"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'caffe'...\n",
            "remote: Enumerating objects: 65274, done.\u001b[K\n",
            "remote: Total 65274 (delta 0), reused 0 (delta 0), pack-reused 65274\u001b[K\n",
            "Receiving objects: 100% (65274/65274), 74.41 MiB | 22.80 MiB/s, done.\n",
            "Resolving deltas: 100% (41264/41264), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebnFG5Feiv0z",
        "colab_type": "text"
      },
      "source": [
        "cd into `caffe` directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLF44uu8gzf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/caffe')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqg5F-mZi2CG",
        "colab_type": "text"
      },
      "source": [
        "Download cifar10 data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEJiDqzGhvH1",
        "colab_type": "code",
        "outputId": "b041b0a1-65b8-4860-8b8b-9314f7a96369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "!./data/cifar10/get_cifar10.sh"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "--2020-06-05 09:57:50--  http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170052171 (162M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-binary.tar.gz’\n",
            "\n",
            "cifar-10-binary.tar 100%[===================>] 162.17M  66.9MB/s    in 2.4s    \n",
            "\n",
            "2020-06-05 09:57:53 (66.9 MB/s) - ‘cifar-10-binary.tar.gz’ saved [170052171/170052171]\n",
            "\n",
            "Unzipping...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcpZAUfdi7fP",
        "colab_type": "text"
      },
      "source": [
        "Creating lmdb files out of downloaded `cifar10` data, create train/test folders.\n",
        "The script is slightly modified to work on Google Colab notebook with `caffe` installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPOK7wjUh2Uw",
        "colab_type": "code",
        "outputId": "92bd813f-7b39-41b4-8754-e5dc5f7780d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "source": [
        "!wget https://gist.githubusercontent.com/Tony607/9d152a91237ad78f5137298d12fafd43/raw/create_cifar10_colab.sh -O create_cifar10_colab.sh\n",
        "!chmod +x create_cifar10_colab.sh\n",
        "!./create_cifar10_colab.sh"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-05 09:58:08--  https://gist.githubusercontent.com/Tony607/9d152a91237ad78f5137298d12fafd43/raw/create_cifar10_colab.sh\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 424 [text/plain]\n",
            "Saving to: ‘create_cifar10_colab.sh’\n",
            "\n",
            "\rcreate_cifar10_cola   0%[                    ]       0  --.-KB/s               \rcreate_cifar10_cola 100%[===================>]     424  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-05 09:58:08 (24.3 MB/s) - ‘create_cifar10_colab.sh’ saved [424/424]\n",
            "\n",
            "Creating lmdb...\n",
            "I0605 09:58:12.604720 17953 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_train_lmdb\n",
            "I0605 09:58:12.605083 17953 convert_cifar_data.cpp:52] Writing Training data\n",
            "I0605 09:58:12.605098 17953 convert_cifar_data.cpp:55] Training Batch 1\n",
            "I0605 09:58:12.644629 17953 convert_cifar_data.cpp:55] Training Batch 2\n",
            "I0605 09:58:12.685355 17953 convert_cifar_data.cpp:55] Training Batch 3\n",
            "I0605 09:58:12.733683 17953 convert_cifar_data.cpp:55] Training Batch 4\n",
            "I0605 09:58:12.776293 17953 convert_cifar_data.cpp:55] Training Batch 5\n",
            "I0605 09:58:15.655709 17953 convert_cifar_data.cpp:73] Writing Testing data\n",
            "I0605 09:58:15.656580 17953 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb\n",
            "Computing image mean...\n",
            "I0605 09:58:17.560613 17957 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_train_lmdb\n",
            "I0605 09:58:17.561087 17957 compute_image_mean.cpp:70] Starting iteration\n",
            "I0605 09:58:17.595480 17957 compute_image_mean.cpp:95] Processed 10000 files.\n",
            "I0605 09:58:17.628839 17957 compute_image_mean.cpp:95] Processed 20000 files.\n",
            "I0605 09:58:17.662474 17957 compute_image_mean.cpp:95] Processed 30000 files.\n",
            "I0605 09:58:17.696605 17957 compute_image_mean.cpp:95] Processed 40000 files.\n",
            "I0605 09:58:17.729935 17957 compute_image_mean.cpp:95] Processed 50000 files.\n",
            "I0605 09:58:17.729964 17957 compute_image_mean.cpp:108] Write to examples/cifar10/mean.binaryproto\n",
            "I0605 09:58:17.730163 17957 compute_image_mean.cpp:114] Number of channels: 3\n",
            "I0605 09:58:17.730183 17957 compute_image_mean.cpp:119] mean_value channel [0]: 125.307\n",
            "I0605 09:58:17.730239 17957 compute_image_mean.cpp:119] mean_value channel [1]: 122.95\n",
            "I0605 09:58:17.730255 17957 compute_image_mean.cpp:119] mean_value channel [2]: 113.865\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTNf4ZTsjhgw",
        "colab_type": "text"
      },
      "source": [
        "Get some more files and train the model.\n",
        "- `cifar10_m4_train_test_small.prototxt`  : the model definition file.\n",
        "- `train_small_colab.sh` : runnable script to train the model.\n",
        "- `cifar10_small_solver_lr1.prototxt` : caffe [solver file](http://caffe.berkeleyvision.org/tutorial/solver.html) for the first 4000 training iterations.\n",
        "- `cifar10_small_solver.prototxt` : caffe [solver file](http://caffe.berkeleyvision.org/tutorial/solver.html), learning rate reduced by a factor of 10 for the last 1000 training iterations ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2dL0zS86vzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cifar10_m4_train_test_small.prototxt\n",
        "!wget -q https://gist.githubusercontent.com/Tony607/f3797c737abdedcde20e4d48622f9c95/raw/cifar10_m4_train_test_small.prototxt -O examples/cifar10/cifar10_m4_train_test_small.prototxt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UyAV1JL60Zo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_small_colab.sh\n",
        "!wget -q https://gist.githubusercontent.com/Tony607/5569923d09e1c1ce389f2c0958aa6bc9/raw/train_small_colab.sh -O ./examples/cifar10/train_small_colab.sh\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bCQgeLy7CeQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "41e49903-64e2-4dc6-9aa9-6705ece85070"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "caffe.cloc\t\t data\t     LICENSE\t\t      README.md\n",
            "cmake\t\t\t docker      Makefile\t\t      scripts\n",
            "CMakeLists.txt\t\t docs\t     Makefile.config.example  src\n",
            "CONTRIBUTING.md\t\t examples    matlab\t\t      tools\n",
            "CONTRIBUTORS.md\t\t include     models\n",
            "create_cifar10_colab.sh  INSTALL.md  python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI_9QyUI7gwb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "e057738d-a6d8-46b7-9a9a-c6e6b1db9182"
      },
      "source": [
        "# cifar10_small_solver_lr1.prototxt\n",
        "!wget https://gist.githubusercontent.com/Tony607/5554c02f4f7efc2bde48cc676a5281f4/raw/cifar10_small_solver_lr1.prototxt -O ./examples/cifar10/cifar10_small_solver_lr1.prototxt\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-05 10:02:00--  https://gist.githubusercontent.com/Tony607/5554c02f4f7efc2bde48cc676a5281f4/raw/cifar10_small_solver_lr1.prototxt\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 885 [text/plain]\n",
            "Saving to: ‘./examples/cifar10/cifar10_small_solver_lr1.prototxt’\n",
            "\n",
            "\r          ./example   0%[                    ]       0  --.-KB/s               \r./examples/cifar10/ 100%[===================>]     885  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-05 10:02:00 (46.7 MB/s) - ‘./examples/cifar10/cifar10_small_solver_lr1.prototxt’ saved [885/885]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAs3BxKY7uPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cifar10_small_solver.prototxt\n",
        "!wget -q https://gist.githubusercontent.com/Tony607/79463f2f002768c198a50c05187647ff/raw/cifar10_small_solver.prototxt -O ./examples/cifar10/cifar10_small_solver.prototxt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g5CIUQM7wq4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "2d9cbf76-a823-44a8-c59e-d7c6fe114dbd"
      },
      "source": [
        "# Make the script runnable.\n",
        "!chmod +x ./examples/cifar10/train_small_colab.sh\n",
        "!ls examples/cifar10"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifar10_full.prototxt\t\t\t     cifar10_small_solver_lr1.prototxt\n",
            "cifar10_full_sigmoid_solver_bn.prototxt      cifar10_small_solver.prototxt\n",
            "cifar10_full_sigmoid_solver.prototxt\t     cifar10_test_lmdb\n",
            "cifar10_full_sigmoid_train_test_bn.prototxt  cifar10_train_lmdb\n",
            "cifar10_full_sigmoid_train_test.prototxt     convert_cifar_data.cpp\n",
            "cifar10_full_solver_lr1.prototxt\t     create_cifar10.sh\n",
            "cifar10_full_solver_lr2.prototxt\t     mean.binaryproto\n",
            "cifar10_full_solver.prototxt\t\t     readme.md\n",
            "cifar10_full_train_test.prototxt\t     train_full.sh\n",
            "cifar10_m4_train_test_small.prototxt\t     train_full_sigmoid_bn.sh\n",
            "cifar10_quick.prototxt\t\t\t     train_full_sigmoid.sh\n",
            "cifar10_quick_solver_lr1.prototxt\t     train_quick.sh\n",
            "cifar10_quick_solver.prototxt\t\t     train_small_colab.sh\n",
            "cifar10_quick_train_test.prototxt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDH-hGES76l2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88f4d515-cc56-4ee6-a2e3-82f15944018b"
      },
      "source": [
        "!./examples/cifar10/train_small_colab.sh"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0605 10:03:45.920631 18057 caffe.cpp:218] Using GPUs 0\n",
            "I0605 10:03:45.947270 18057 caffe.cpp:223] GPU 0: Tesla K80\n",
            "I0605 10:03:46.169577 18057 solver.cpp:44] Initializing solver from parameters: \n",
            "test_iter: 100\n",
            "test_interval: 500\n",
            "base_lr: 0.001\n",
            "display: 100\n",
            "max_iter: 4000\n",
            "lr_policy: \"fixed\"\n",
            "momentum: 0.9\n",
            "weight_decay: 0.004\n",
            "snapshot: 4000\n",
            "snapshot_prefix: \"examples/cifar10/cifar10_small\"\n",
            "solver_mode: GPU\n",
            "device_id: 0\n",
            "net: \"examples/cifar10/cifar10_m4_train_test_small.prototxt\"\n",
            "train_state {\n",
            "  level: 0\n",
            "  stage: \"\"\n",
            "}\n",
            "I0605 10:03:46.169790 18057 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_m4_train_test_small.prototxt\n",
            "I0605 10:03:46.170159 18057 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data\n",
            "I0605 10:03:46.170190 18057 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy\n",
            "I0605 10:03:46.170271 18057 net.cpp:51] Initializing net from parameters: \n",
            "name: \"CIFAR10_small\"\n",
            "state {\n",
            "  phase: TRAIN\n",
            "  level: 0\n",
            "  stage: \"\"\n",
            "}\n",
            "layer {\n",
            "  name: \"data\"\n",
            "  type: \"Data\"\n",
            "  top: \"data\"\n",
            "  top: \"label\"\n",
            "  include {\n",
            "    phase: TRAIN\n",
            "  }\n",
            "  transform_param {\n",
            "    mean_file: \"examples/cifar10/mean.binaryproto\"\n",
            "  }\n",
            "  data_param {\n",
            "    source: \"examples/cifar10/cifar10_train_lmdb\"\n",
            "    batch_size: 100\n",
            "    backend: LMDB\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.0001\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu1\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"pool1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv2\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"conv2\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 16\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu2\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"conv2\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool2\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"pool2\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv3\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool2\"\n",
            "  top: \"conv3\"\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu3\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv3\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool3\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"pool3\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"ip1\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"pool3\"\n",
            "  top: \"ip1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 250\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 10\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"loss\"\n",
            "  type: \"SoftmaxWithLoss\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"loss\"\n",
            "}\n",
            "I0605 10:03:46.170358 18057 layer_factory.hpp:77] Creating layer data\n",
            "I0605 10:03:46.170455 18057 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_train_lmdb\n",
            "I0605 10:03:46.170506 18057 net.cpp:84] Creating Layer data\n",
            "I0605 10:03:46.170537 18057 net.cpp:380] data -> data\n",
            "I0605 10:03:46.170562 18057 net.cpp:380] data -> label\n",
            "I0605 10:03:46.170579 18057 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto\n",
            "I0605 10:03:46.171447 18057 data_layer.cpp:45] output data size: 100,3,32,32\n",
            "I0605 10:03:46.175884 18057 net.cpp:122] Setting up data\n",
            "I0605 10:03:46.175906 18057 net.cpp:129] Top shape: 100 3 32 32 (307200)\n",
            "I0605 10:03:46.175921 18057 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:03:46.175932 18057 net.cpp:137] Memory required for data: 1229200\n",
            "I0605 10:03:46.175978 18057 layer_factory.hpp:77] Creating layer conv1\n",
            "I0605 10:03:46.176005 18057 net.cpp:84] Creating Layer conv1\n",
            "I0605 10:03:46.176019 18057 net.cpp:406] conv1 <- data\n",
            "I0605 10:03:46.176033 18057 net.cpp:380] conv1 -> conv1\n",
            "I0605 10:03:46.176496 18057 net.cpp:122] Setting up conv1\n",
            "I0605 10:03:46.176532 18057 net.cpp:129] Top shape: 100 32 32 32 (3276800)\n",
            "I0605 10:03:46.176540 18057 net.cpp:137] Memory required for data: 14336400\n",
            "I0605 10:03:46.176556 18057 layer_factory.hpp:77] Creating layer pool1\n",
            "I0605 10:03:46.176574 18057 net.cpp:84] Creating Layer pool1\n",
            "I0605 10:03:46.176607 18057 net.cpp:406] pool1 <- conv1\n",
            "I0605 10:03:46.176618 18057 net.cpp:380] pool1 -> pool1\n",
            "I0605 10:03:46.176667 18057 net.cpp:122] Setting up pool1\n",
            "I0605 10:03:46.176687 18057 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:03:46.176697 18057 net.cpp:137] Memory required for data: 17613200\n",
            "I0605 10:03:46.176707 18057 layer_factory.hpp:77] Creating layer relu1\n",
            "I0605 10:03:46.176717 18057 net.cpp:84] Creating Layer relu1\n",
            "I0605 10:03:46.176726 18057 net.cpp:406] relu1 <- pool1\n",
            "I0605 10:03:46.176738 18057 net.cpp:367] relu1 -> pool1 (in-place)\n",
            "I0605 10:03:46.176756 18057 net.cpp:122] Setting up relu1\n",
            "I0605 10:03:46.176769 18057 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:03:46.176779 18057 net.cpp:137] Memory required for data: 20890000\n",
            "I0605 10:03:46.176789 18057 layer_factory.hpp:77] Creating layer conv2\n",
            "I0605 10:03:46.176805 18057 net.cpp:84] Creating Layer conv2\n",
            "I0605 10:03:46.176817 18057 net.cpp:406] conv2 <- pool1\n",
            "I0605 10:03:46.176829 18057 net.cpp:380] conv2 -> conv2\n",
            "I0605 10:03:46.177450 18057 net.cpp:122] Setting up conv2\n",
            "I0605 10:03:46.177475 18057 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:03:46.177516 18057 net.cpp:137] Memory required for data: 22528400\n",
            "I0605 10:03:46.177551 18057 layer_factory.hpp:77] Creating layer relu2\n",
            "I0605 10:03:46.177564 18057 net.cpp:84] Creating Layer relu2\n",
            "I0605 10:03:46.177577 18057 net.cpp:406] relu2 <- conv2\n",
            "I0605 10:03:46.177616 18057 net.cpp:367] relu2 -> conv2 (in-place)\n",
            "I0605 10:03:46.177631 18057 net.cpp:122] Setting up relu2\n",
            "I0605 10:03:46.177644 18057 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:03:46.177654 18057 net.cpp:137] Memory required for data: 24166800\n",
            "I0605 10:03:46.177664 18057 layer_factory.hpp:77] Creating layer pool2\n",
            "I0605 10:03:46.177676 18057 net.cpp:84] Creating Layer pool2\n",
            "I0605 10:03:46.177687 18057 net.cpp:406] pool2 <- conv2\n",
            "I0605 10:03:46.177698 18057 net.cpp:380] pool2 -> pool2\n",
            "I0605 10:03:46.177727 18057 net.cpp:122] Setting up pool2\n",
            "I0605 10:03:46.177758 18057 net.cpp:129] Top shape: 100 16 8 8 (102400)\n",
            "I0605 10:03:46.177769 18057 net.cpp:137] Memory required for data: 24576400\n",
            "I0605 10:03:46.177778 18057 layer_factory.hpp:77] Creating layer conv3\n",
            "I0605 10:03:46.177793 18057 net.cpp:84] Creating Layer conv3\n",
            "I0605 10:03:46.177803 18057 net.cpp:406] conv3 <- pool2\n",
            "I0605 10:03:46.177852 18057 net.cpp:380] conv3 -> conv3\n",
            "I0605 10:03:46.178311 18057 net.cpp:122] Setting up conv3\n",
            "I0605 10:03:46.178333 18057 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:03:46.178349 18057 net.cpp:137] Memory required for data: 25395600\n",
            "I0605 10:03:46.178364 18057 layer_factory.hpp:77] Creating layer relu3\n",
            "I0605 10:03:46.178377 18057 net.cpp:84] Creating Layer relu3\n",
            "I0605 10:03:46.178390 18057 net.cpp:406] relu3 <- conv3\n",
            "I0605 10:03:46.178402 18057 net.cpp:367] relu3 -> conv3 (in-place)\n",
            "I0605 10:03:46.178416 18057 net.cpp:122] Setting up relu3\n",
            "I0605 10:03:46.178428 18057 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:03:46.178439 18057 net.cpp:137] Memory required for data: 26214800\n",
            "I0605 10:03:46.178449 18057 layer_factory.hpp:77] Creating layer pool3\n",
            "I0605 10:03:46.178460 18057 net.cpp:84] Creating Layer pool3\n",
            "I0605 10:03:46.178470 18057 net.cpp:406] pool3 <- conv3\n",
            "I0605 10:03:46.178483 18057 net.cpp:380] pool3 -> pool3\n",
            "I0605 10:03:46.178526 18057 net.cpp:122] Setting up pool3\n",
            "I0605 10:03:46.178556 18057 net.cpp:129] Top shape: 100 32 4 4 (51200)\n",
            "I0605 10:03:46.178581 18057 net.cpp:137] Memory required for data: 26419600\n",
            "I0605 10:03:46.178649 18057 layer_factory.hpp:77] Creating layer ip1\n",
            "I0605 10:03:46.178666 18057 net.cpp:84] Creating Layer ip1\n",
            "I0605 10:03:46.178676 18057 net.cpp:406] ip1 <- pool3\n",
            "I0605 10:03:46.178689 18057 net.cpp:380] ip1 -> ip1\n",
            "I0605 10:03:46.178930 18057 net.cpp:122] Setting up ip1\n",
            "I0605 10:03:46.178953 18057 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:03:46.178964 18057 net.cpp:137] Memory required for data: 26423600\n",
            "I0605 10:03:46.178978 18057 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:03:46.178992 18057 net.cpp:84] Creating Layer loss\n",
            "I0605 10:03:46.179000 18057 net.cpp:406] loss <- ip1\n",
            "I0605 10:03:46.179010 18057 net.cpp:406] loss <- label\n",
            "I0605 10:03:46.179020 18057 net.cpp:380] loss -> loss\n",
            "I0605 10:03:46.179041 18057 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:03:46.179280 18057 net.cpp:122] Setting up loss\n",
            "I0605 10:03:46.179309 18057 net.cpp:129] Top shape: (1)\n",
            "I0605 10:03:46.179332 18057 net.cpp:132]     with loss weight 1\n",
            "I0605 10:03:46.179355 18057 net.cpp:137] Memory required for data: 26423604\n",
            "I0605 10:03:46.179365 18057 net.cpp:198] loss needs backward computation.\n",
            "I0605 10:03:46.179378 18057 net.cpp:198] ip1 needs backward computation.\n",
            "I0605 10:03:46.179388 18057 net.cpp:198] pool3 needs backward computation.\n",
            "I0605 10:03:46.179399 18057 net.cpp:198] relu3 needs backward computation.\n",
            "I0605 10:03:46.179409 18057 net.cpp:198] conv3 needs backward computation.\n",
            "I0605 10:03:46.179417 18057 net.cpp:198] pool2 needs backward computation.\n",
            "I0605 10:03:46.179428 18057 net.cpp:198] relu2 needs backward computation.\n",
            "I0605 10:03:46.179440 18057 net.cpp:198] conv2 needs backward computation.\n",
            "I0605 10:03:46.179450 18057 net.cpp:198] relu1 needs backward computation.\n",
            "I0605 10:03:46.179459 18057 net.cpp:198] pool1 needs backward computation.\n",
            "I0605 10:03:46.179468 18057 net.cpp:198] conv1 needs backward computation.\n",
            "I0605 10:03:46.179479 18057 net.cpp:200] data does not need backward computation.\n",
            "I0605 10:03:46.179491 18057 net.cpp:242] This network produces output loss\n",
            "I0605 10:03:46.179505 18057 net.cpp:255] Network initialization done.\n",
            "I0605 10:03:46.179764 18057 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_m4_train_test_small.prototxt\n",
            "I0605 10:03:46.179800 18057 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\n",
            "I0605 10:03:46.179921 18057 net.cpp:51] Initializing net from parameters: \n",
            "name: \"CIFAR10_small\"\n",
            "state {\n",
            "  phase: TEST\n",
            "}\n",
            "layer {\n",
            "  name: \"data\"\n",
            "  type: \"Data\"\n",
            "  top: \"data\"\n",
            "  top: \"label\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "  transform_param {\n",
            "    mean_file: \"examples/cifar10/mean.binaryproto\"\n",
            "  }\n",
            "  data_param {\n",
            "    source: \"examples/cifar10/cifar10_test_lmdb\"\n",
            "    batch_size: 100\n",
            "    backend: LMDB\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.0001\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu1\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"pool1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv2\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"conv2\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 16\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu2\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"conv2\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool2\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"pool2\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv3\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool2\"\n",
            "  top: \"conv3\"\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu3\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv3\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool3\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"pool3\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"ip1\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"pool3\"\n",
            "  top: \"ip1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 250\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 10\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"accuracy\"\n",
            "  type: \"Accuracy\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"accuracy\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"loss\"\n",
            "  type: \"SoftmaxWithLoss\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"loss\"\n",
            "}\n",
            "I0605 10:03:46.180032 18057 layer_factory.hpp:77] Creating layer data\n",
            "I0605 10:03:46.180125 18057 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb\n",
            "I0605 10:03:46.180150 18057 net.cpp:84] Creating Layer data\n",
            "I0605 10:03:46.180163 18057 net.cpp:380] data -> data\n",
            "I0605 10:03:46.180178 18057 net.cpp:380] data -> label\n",
            "I0605 10:03:46.180193 18057 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto\n",
            "I0605 10:03:46.180419 18057 data_layer.cpp:45] output data size: 100,3,32,32\n",
            "I0605 10:03:46.186055 18057 net.cpp:122] Setting up data\n",
            "I0605 10:03:46.186084 18057 net.cpp:129] Top shape: 100 3 32 32 (307200)\n",
            "I0605 10:03:46.186097 18057 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:03:46.186106 18057 net.cpp:137] Memory required for data: 1229200\n",
            "I0605 10:03:46.186116 18057 layer_factory.hpp:77] Creating layer label_data_1_split\n",
            "I0605 10:03:46.186128 18057 net.cpp:84] Creating Layer label_data_1_split\n",
            "I0605 10:03:46.186139 18057 net.cpp:406] label_data_1_split <- label\n",
            "I0605 10:03:46.186152 18057 net.cpp:380] label_data_1_split -> label_data_1_split_0\n",
            "I0605 10:03:46.186167 18057 net.cpp:380] label_data_1_split -> label_data_1_split_1\n",
            "I0605 10:03:46.186429 18057 net.cpp:122] Setting up label_data_1_split\n",
            "I0605 10:03:46.186450 18057 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:03:46.186462 18057 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:03:46.186472 18057 net.cpp:137] Memory required for data: 1230000\n",
            "I0605 10:03:46.186481 18057 layer_factory.hpp:77] Creating layer conv1\n",
            "I0605 10:03:46.186497 18057 net.cpp:84] Creating Layer conv1\n",
            "I0605 10:03:46.186509 18057 net.cpp:406] conv1 <- data\n",
            "I0605 10:03:46.186523 18057 net.cpp:380] conv1 -> conv1\n",
            "I0605 10:03:46.186880 18057 net.cpp:122] Setting up conv1\n",
            "I0605 10:03:46.186905 18057 net.cpp:129] Top shape: 100 32 32 32 (3276800)\n",
            "I0605 10:03:46.186916 18057 net.cpp:137] Memory required for data: 14337200\n",
            "I0605 10:03:46.186933 18057 layer_factory.hpp:77] Creating layer pool1\n",
            "I0605 10:03:46.186946 18057 net.cpp:84] Creating Layer pool1\n",
            "I0605 10:03:46.186957 18057 net.cpp:406] pool1 <- conv1\n",
            "I0605 10:03:46.186969 18057 net.cpp:380] pool1 -> pool1\n",
            "I0605 10:03:46.187009 18057 net.cpp:122] Setting up pool1\n",
            "I0605 10:03:46.187026 18057 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:03:46.187036 18057 net.cpp:137] Memory required for data: 17614000\n",
            "I0605 10:03:46.187045 18057 layer_factory.hpp:77] Creating layer relu1\n",
            "I0605 10:03:46.187058 18057 net.cpp:84] Creating Layer relu1\n",
            "I0605 10:03:46.517422 18057 net.cpp:406] relu1 <- pool1\n",
            "I0605 10:03:46.517472 18057 net.cpp:367] relu1 -> pool1 (in-place)\n",
            "I0605 10:03:46.517830 18057 net.cpp:122] Setting up relu1\n",
            "I0605 10:03:46.517853 18057 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:03:46.517865 18057 net.cpp:137] Memory required for data: 20890800\n",
            "I0605 10:03:46.517877 18057 layer_factory.hpp:77] Creating layer conv2\n",
            "I0605 10:03:46.517896 18057 net.cpp:84] Creating Layer conv2\n",
            "I0605 10:03:46.517910 18057 net.cpp:406] conv2 <- pool1\n",
            "I0605 10:03:46.517923 18057 net.cpp:380] conv2 -> conv2\n",
            "I0605 10:03:46.518934 18057 net.cpp:122] Setting up conv2\n",
            "I0605 10:03:46.518963 18057 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:03:46.518971 18057 net.cpp:137] Memory required for data: 22529200\n",
            "I0605 10:03:46.519037 18057 layer_factory.hpp:77] Creating layer relu2\n",
            "I0605 10:03:46.519053 18057 net.cpp:84] Creating Layer relu2\n",
            "I0605 10:03:46.519065 18057 net.cpp:406] relu2 <- conv2\n",
            "I0605 10:03:46.519074 18057 net.cpp:367] relu2 -> conv2 (in-place)\n",
            "I0605 10:03:46.519084 18057 net.cpp:122] Setting up relu2\n",
            "I0605 10:03:46.519095 18057 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:03:46.519109 18057 net.cpp:137] Memory required for data: 24167600\n",
            "I0605 10:03:46.519119 18057 layer_factory.hpp:77] Creating layer pool2\n",
            "I0605 10:03:46.519130 18057 net.cpp:84] Creating Layer pool2\n",
            "I0605 10:03:46.519137 18057 net.cpp:406] pool2 <- conv2\n",
            "I0605 10:03:46.519145 18057 net.cpp:380] pool2 -> pool2\n",
            "I0605 10:03:46.519176 18057 net.cpp:122] Setting up pool2\n",
            "I0605 10:03:46.519191 18057 net.cpp:129] Top shape: 100 16 8 8 (102400)\n",
            "I0605 10:03:46.519197 18057 net.cpp:137] Memory required for data: 24577200\n",
            "I0605 10:03:46.519204 18057 layer_factory.hpp:77] Creating layer conv3\n",
            "I0605 10:03:46.519217 18057 net.cpp:84] Creating Layer conv3\n",
            "I0605 10:03:46.519227 18057 net.cpp:406] conv3 <- pool2\n",
            "I0605 10:03:46.519237 18057 net.cpp:380] conv3 -> conv3\n",
            "I0605 10:03:46.519562 18057 net.cpp:122] Setting up conv3\n",
            "I0605 10:03:46.519598 18057 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:03:46.519619 18057 net.cpp:137] Memory required for data: 25396400\n",
            "I0605 10:03:46.519631 18057 layer_factory.hpp:77] Creating layer relu3\n",
            "I0605 10:03:46.519644 18057 net.cpp:84] Creating Layer relu3\n",
            "I0605 10:03:46.519654 18057 net.cpp:406] relu3 <- conv3\n",
            "I0605 10:03:46.519662 18057 net.cpp:367] relu3 -> conv3 (in-place)\n",
            "I0605 10:03:46.519672 18057 net.cpp:122] Setting up relu3\n",
            "I0605 10:03:46.519685 18057 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:03:46.519692 18057 net.cpp:137] Memory required for data: 26215600\n",
            "I0605 10:03:46.519697 18057 layer_factory.hpp:77] Creating layer pool3\n",
            "I0605 10:03:46.519706 18057 net.cpp:84] Creating Layer pool3\n",
            "I0605 10:03:46.519712 18057 net.cpp:406] pool3 <- conv3\n",
            "I0605 10:03:46.519721 18057 net.cpp:380] pool3 -> pool3\n",
            "I0605 10:03:46.519752 18057 net.cpp:122] Setting up pool3\n",
            "I0605 10:03:46.519770 18057 net.cpp:129] Top shape: 100 32 4 4 (51200)\n",
            "I0605 10:03:46.519778 18057 net.cpp:137] Memory required for data: 26420400\n",
            "I0605 10:03:46.519783 18057 layer_factory.hpp:77] Creating layer ip1\n",
            "I0605 10:03:46.519793 18057 net.cpp:84] Creating Layer ip1\n",
            "I0605 10:03:46.519804 18057 net.cpp:406] ip1 <- pool3\n",
            "I0605 10:03:46.519814 18057 net.cpp:380] ip1 -> ip1\n",
            "I0605 10:03:46.519959 18057 net.cpp:122] Setting up ip1\n",
            "I0605 10:03:46.519975 18057 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:03:46.519981 18057 net.cpp:137] Memory required for data: 26424400\n",
            "I0605 10:03:46.519989 18057 layer_factory.hpp:77] Creating layer ip1_ip1_0_split\n",
            "I0605 10:03:46.520000 18057 net.cpp:84] Creating Layer ip1_ip1_0_split\n",
            "I0605 10:03:46.520007 18057 net.cpp:406] ip1_ip1_0_split <- ip1\n",
            "I0605 10:03:46.520017 18057 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0\n",
            "I0605 10:03:46.520030 18057 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1\n",
            "I0605 10:03:46.520164 18057 net.cpp:122] Setting up ip1_ip1_0_split\n",
            "I0605 10:03:46.520208 18057 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:03:46.520222 18057 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:03:46.520231 18057 net.cpp:137] Memory required for data: 26432400\n",
            "I0605 10:03:46.520241 18057 layer_factory.hpp:77] Creating layer accuracy\n",
            "I0605 10:03:46.520256 18057 net.cpp:84] Creating Layer accuracy\n",
            "I0605 10:03:46.520272 18057 net.cpp:406] accuracy <- ip1_ip1_0_split_0\n",
            "I0605 10:03:46.520285 18057 net.cpp:406] accuracy <- label_data_1_split_0\n",
            "I0605 10:03:46.520300 18057 net.cpp:380] accuracy -> accuracy\n",
            "I0605 10:03:46.520323 18057 net.cpp:122] Setting up accuracy\n",
            "I0605 10:03:46.520344 18057 net.cpp:129] Top shape: (1)\n",
            "I0605 10:03:46.520357 18057 net.cpp:137] Memory required for data: 26432404\n",
            "I0605 10:03:46.520367 18057 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:03:46.520380 18057 net.cpp:84] Creating Layer loss\n",
            "I0605 10:03:46.520390 18057 net.cpp:406] loss <- ip1_ip1_0_split_1\n",
            "I0605 10:03:46.520439 18057 net.cpp:406] loss <- label_data_1_split_1\n",
            "I0605 10:03:46.520457 18057 net.cpp:380] loss -> loss\n",
            "I0605 10:03:46.520475 18057 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:03:46.520613 18057 net.cpp:122] Setting up loss\n",
            "I0605 10:03:46.520639 18057 net.cpp:129] Top shape: (1)\n",
            "I0605 10:03:46.520656 18057 net.cpp:132]     with loss weight 1\n",
            "I0605 10:03:46.520684 18057 net.cpp:137] Memory required for data: 26432408\n",
            "I0605 10:03:46.520699 18057 net.cpp:198] loss needs backward computation.\n",
            "I0605 10:03:46.520715 18057 net.cpp:200] accuracy does not need backward computation.\n",
            "I0605 10:03:46.520740 18057 net.cpp:198] ip1_ip1_0_split needs backward computation.\n",
            "I0605 10:03:46.520756 18057 net.cpp:198] ip1 needs backward computation.\n",
            "I0605 10:03:46.520789 18057 net.cpp:198] pool3 needs backward computation.\n",
            "I0605 10:03:46.520807 18057 net.cpp:198] relu3 needs backward computation.\n",
            "I0605 10:03:46.520823 18057 net.cpp:198] conv3 needs backward computation.\n",
            "I0605 10:03:46.520835 18057 net.cpp:198] pool2 needs backward computation.\n",
            "I0605 10:03:46.520848 18057 net.cpp:198] relu2 needs backward computation.\n",
            "I0605 10:03:46.520860 18057 net.cpp:198] conv2 needs backward computation.\n",
            "I0605 10:03:46.520872 18057 net.cpp:198] relu1 needs backward computation.\n",
            "I0605 10:03:46.520884 18057 net.cpp:198] pool1 needs backward computation.\n",
            "I0605 10:03:46.520900 18057 net.cpp:198] conv1 needs backward computation.\n",
            "I0605 10:03:46.520910 18057 net.cpp:200] label_data_1_split does not need backward computation.\n",
            "I0605 10:03:46.520925 18057 net.cpp:200] data does not need backward computation.\n",
            "I0605 10:03:46.520937 18057 net.cpp:242] This network produces output accuracy\n",
            "I0605 10:03:46.520951 18057 net.cpp:242] This network produces output loss\n",
            "I0605 10:03:46.520982 18057 net.cpp:255] Network initialization done.\n",
            "I0605 10:03:46.521045 18057 solver.cpp:56] Solver scaffolding done.\n",
            "I0605 10:03:46.521315 18057 caffe.cpp:248] Starting Optimization\n",
            "I0605 10:03:46.521337 18057 solver.cpp:272] Solving CIFAR10_small\n",
            "I0605 10:03:46.521345 18057 solver.cpp:273] Learning Rate Policy: fixed\n",
            "I0605 10:03:46.521463 18057 solver.cpp:330] Iteration 0, Testing net (#0)\n",
            "I0605 10:03:48.814150 18062 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:03:48.900849 18057 solver.cpp:397]     Test net output #0: accuracy = 0.111\n",
            "I0605 10:03:48.900910 18057 solver.cpp:397]     Test net output #1: loss = 2.30258 (* 1 = 2.30258 loss)\n",
            "I0605 10:03:48.960647 18057 solver.cpp:218] Iteration 0 (0 iter/s, 2.43927s/100 iters), loss = 2.30256\n",
            "I0605 10:03:48.960688 18057 solver.cpp:237]     Train net output #0: loss = 2.30256 (* 1 = 2.30256 loss)\n",
            "I0605 10:03:48.960711 18057 sgd_solver.cpp:105] Iteration 0, lr = 0.001\n",
            "I0605 10:03:55.014250 18057 solver.cpp:218] Iteration 100 (16.5192 iter/s, 6.05357s/100 iters), loss = 2.29209\n",
            "I0605 10:03:55.014310 18057 solver.cpp:237]     Train net output #0: loss = 2.29209 (* 1 = 2.29209 loss)\n",
            "I0605 10:03:55.014326 18057 sgd_solver.cpp:105] Iteration 100, lr = 0.001\n",
            "I0605 10:04:01.072968 18057 solver.cpp:218] Iteration 200 (16.5053 iter/s, 6.05867s/100 iters), loss = 2.03545\n",
            "I0605 10:04:01.073035 18057 solver.cpp:237]     Train net output #0: loss = 2.03545 (* 1 = 2.03545 loss)\n",
            "I0605 10:04:01.073060 18057 sgd_solver.cpp:105] Iteration 200, lr = 0.001\n",
            "I0605 10:04:07.134413 18057 solver.cpp:218] Iteration 300 (16.4979 iter/s, 6.06139s/100 iters), loss = 1.71464\n",
            "I0605 10:04:07.134505 18057 solver.cpp:237]     Train net output #0: loss = 1.71464 (* 1 = 1.71464 loss)\n",
            "I0605 10:04:07.134529 18057 sgd_solver.cpp:105] Iteration 300, lr = 0.001\n",
            "I0605 10:04:13.197517 18057 solver.cpp:218] Iteration 400 (16.4935 iter/s, 6.06301s/100 iters), loss = 1.60802\n",
            "I0605 10:04:13.197626 18057 solver.cpp:237]     Train net output #0: loss = 1.60802 (* 1 = 1.60802 loss)\n",
            "I0605 10:04:13.197649 18057 sgd_solver.cpp:105] Iteration 400, lr = 0.001\n",
            "I0605 10:04:18.960597 18061 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:04:19.168691 18057 solver.cpp:330] Iteration 500, Testing net (#0)\n",
            "I0605 10:04:21.323841 18062 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:04:21.410347 18057 solver.cpp:397]     Test net output #0: accuracy = 0.4051\n",
            "I0605 10:04:21.410395 18057 solver.cpp:397]     Test net output #1: loss = 1.65579 (* 1 = 1.65579 loss)\n",
            "I0605 10:04:21.469625 18057 solver.cpp:218] Iteration 500 (12.0889 iter/s, 8.27204s/100 iters), loss = 1.76871\n",
            "I0605 10:04:21.469679 18057 solver.cpp:237]     Train net output #0: loss = 1.76871 (* 1 = 1.76871 loss)\n",
            "I0605 10:04:21.469707 18057 sgd_solver.cpp:105] Iteration 500, lr = 0.001\n",
            "I0605 10:04:27.535740 18057 solver.cpp:218] Iteration 600 (16.4851 iter/s, 6.06608s/100 iters), loss = 1.55454\n",
            "I0605 10:04:27.535806 18057 solver.cpp:237]     Train net output #0: loss = 1.55454 (* 1 = 1.55454 loss)\n",
            "I0605 10:04:27.535827 18057 sgd_solver.cpp:105] Iteration 600, lr = 0.001\n",
            "I0605 10:04:33.606185 18057 solver.cpp:218] Iteration 700 (16.4734 iter/s, 6.0704s/100 iters), loss = 1.60421\n",
            "I0605 10:04:33.606247 18057 solver.cpp:237]     Train net output #0: loss = 1.60421 (* 1 = 1.60421 loss)\n",
            "I0605 10:04:33.606261 18057 sgd_solver.cpp:105] Iteration 700, lr = 0.001\n",
            "I0605 10:04:39.675976 18057 solver.cpp:218] Iteration 800 (16.4752 iter/s, 6.06975s/100 iters), loss = 1.47588\n",
            "I0605 10:04:39.676038 18057 solver.cpp:237]     Train net output #0: loss = 1.47588 (* 1 = 1.47588 loss)\n",
            "I0605 10:04:39.676054 18057 sgd_solver.cpp:105] Iteration 800, lr = 0.001\n",
            "I0605 10:04:45.750893 18057 solver.cpp:218] Iteration 900 (16.4613 iter/s, 6.07487s/100 iters), loss = 1.35419\n",
            "I0605 10:04:45.750955 18057 solver.cpp:237]     Train net output #0: loss = 1.35419 (* 1 = 1.35419 loss)\n",
            "I0605 10:04:45.750972 18057 sgd_solver.cpp:105] Iteration 900, lr = 0.001\n",
            "I0605 10:04:51.521670 18061 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:04:51.730849 18057 solver.cpp:330] Iteration 1000, Testing net (#0)\n",
            "I0605 10:04:53.894366 18062 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:04:53.981326 18057 solver.cpp:397]     Test net output #0: accuracy = 0.5037\n",
            "I0605 10:04:53.981397 18057 solver.cpp:397]     Test net output #1: loss = 1.39323 (* 1 = 1.39323 loss)\n",
            "I0605 10:04:54.040900 18057 solver.cpp:218] Iteration 1000 (12.0628 iter/s, 8.28998s/100 iters), loss = 1.3883\n",
            "I0605 10:04:54.040951 18057 solver.cpp:237]     Train net output #0: loss = 1.3883 (* 1 = 1.3883 loss)\n",
            "I0605 10:04:54.040966 18057 sgd_solver.cpp:105] Iteration 1000, lr = 0.001\n",
            "I0605 10:05:00.121130 18057 solver.cpp:218] Iteration 1100 (16.4468 iter/s, 6.08019s/100 iters), loss = 1.40948\n",
            "I0605 10:05:00.121197 18057 solver.cpp:237]     Train net output #0: loss = 1.40948 (* 1 = 1.40948 loss)\n",
            "I0605 10:05:00.121212 18057 sgd_solver.cpp:105] Iteration 1100, lr = 0.001\n",
            "I0605 10:05:06.204392 18057 solver.cpp:218] Iteration 1200 (16.4387 iter/s, 6.08321s/100 iters), loss = 1.43015\n",
            "I0605 10:05:06.204449 18057 solver.cpp:237]     Train net output #0: loss = 1.43015 (* 1 = 1.43015 loss)\n",
            "I0605 10:05:06.204463 18057 sgd_solver.cpp:105] Iteration 1200, lr = 0.001\n",
            "I0605 10:05:12.282073 18057 solver.cpp:218] Iteration 1300 (16.4538 iter/s, 6.07764s/100 iters), loss = 1.29485\n",
            "I0605 10:05:12.282133 18057 solver.cpp:237]     Train net output #0: loss = 1.29485 (* 1 = 1.29485 loss)\n",
            "I0605 10:05:12.282148 18057 sgd_solver.cpp:105] Iteration 1300, lr = 0.001\n",
            "I0605 10:05:18.361114 18057 solver.cpp:218] Iteration 1400 (16.4501 iter/s, 6.07899s/100 iters), loss = 1.29092\n",
            "I0605 10:05:18.361198 18057 solver.cpp:237]     Train net output #0: loss = 1.29092 (* 1 = 1.29092 loss)\n",
            "I0605 10:05:18.361245 18057 sgd_solver.cpp:105] Iteration 1400, lr = 0.001\n",
            "I0605 10:05:24.145341 18061 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:05:24.354809 18057 solver.cpp:330] Iteration 1500, Testing net (#0)\n",
            "I0605 10:05:26.516863 18062 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:05:26.604157 18057 solver.cpp:397]     Test net output #0: accuracy = 0.5497\n",
            "I0605 10:05:26.604228 18057 solver.cpp:397]     Test net output #1: loss = 1.29021 (* 1 = 1.29021 loss)\n",
            "I0605 10:05:26.663516 18057 solver.cpp:218] Iteration 1500 (12.0448 iter/s, 8.30235s/100 iters), loss = 1.31759\n",
            "I0605 10:05:26.663573 18057 solver.cpp:237]     Train net output #0: loss = 1.31759 (* 1 = 1.31759 loss)\n",
            "I0605 10:05:26.663610 18057 sgd_solver.cpp:105] Iteration 1500, lr = 0.001\n",
            "I0605 10:05:32.749511 18057 solver.cpp:218] Iteration 1600 (16.4313 iter/s, 6.08595s/100 iters), loss = 1.2631\n",
            "I0605 10:05:32.749574 18057 solver.cpp:237]     Train net output #0: loss = 1.2631 (* 1 = 1.2631 loss)\n",
            "I0605 10:05:32.749620 18057 sgd_solver.cpp:105] Iteration 1600, lr = 0.001\n",
            "I0605 10:05:38.845337 18057 solver.cpp:218] Iteration 1700 (16.4048 iter/s, 6.09578s/100 iters), loss = 1.29508\n",
            "I0605 10:05:38.845402 18057 solver.cpp:237]     Train net output #0: loss = 1.29508 (* 1 = 1.29508 loss)\n",
            "I0605 10:05:38.845415 18057 sgd_solver.cpp:105] Iteration 1700, lr = 0.001\n",
            "I0605 10:05:44.931310 18057 solver.cpp:218] Iteration 1800 (16.4314 iter/s, 6.08592s/100 iters), loss = 1.10379\n",
            "I0605 10:05:44.931373 18057 solver.cpp:237]     Train net output #0: loss = 1.10379 (* 1 = 1.10379 loss)\n",
            "I0605 10:05:44.931388 18057 sgd_solver.cpp:105] Iteration 1800, lr = 0.001\n",
            "I0605 10:05:51.016577 18057 solver.cpp:218] Iteration 1900 (16.4333 iter/s, 6.0852s/100 iters), loss = 1.14273\n",
            "I0605 10:05:51.016649 18057 solver.cpp:237]     Train net output #0: loss = 1.14273 (* 1 = 1.14273 loss)\n",
            "I0605 10:05:51.016664 18057 sgd_solver.cpp:105] Iteration 1900, lr = 0.001\n",
            "I0605 10:05:56.801554 18061 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:05:57.010433 18057 solver.cpp:330] Iteration 2000, Testing net (#0)\n",
            "I0605 10:05:59.171885 18062 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:05:59.258703 18057 solver.cpp:397]     Test net output #0: accuracy = 0.5821\n",
            "I0605 10:05:59.258745 18057 solver.cpp:397]     Test net output #1: loss = 1.19034 (* 1 = 1.19034 loss)\n",
            "I0605 10:05:59.318011 18057 solver.cpp:218] Iteration 2000 (12.0462 iter/s, 8.30139s/100 iters), loss = 1.19702\n",
            "I0605 10:05:59.318058 18057 solver.cpp:237]     Train net output #0: loss = 1.19702 (* 1 = 1.19702 loss)\n",
            "I0605 10:05:59.318074 18057 sgd_solver.cpp:105] Iteration 2000, lr = 0.001\n",
            "I0605 10:06:05.404660 18057 solver.cpp:218] Iteration 2100 (16.4295 iter/s, 6.08662s/100 iters), loss = 1.09952\n",
            "I0605 10:06:05.404721 18057 solver.cpp:237]     Train net output #0: loss = 1.09952 (* 1 = 1.09952 loss)\n",
            "I0605 10:06:05.404745 18057 sgd_solver.cpp:105] Iteration 2100, lr = 0.001\n",
            "I0605 10:06:11.500041 18057 solver.cpp:218] Iteration 2200 (16.406 iter/s, 6.09534s/100 iters), loss = 1.25006\n",
            "I0605 10:06:11.500105 18057 solver.cpp:237]     Train net output #0: loss = 1.25006 (* 1 = 1.25006 loss)\n",
            "I0605 10:06:11.500120 18057 sgd_solver.cpp:105] Iteration 2200, lr = 0.001\n",
            "I0605 10:06:17.596808 18057 solver.cpp:218] Iteration 2300 (16.4023 iter/s, 6.09672s/100 iters), loss = 0.983131\n",
            "I0605 10:06:17.596873 18057 solver.cpp:237]     Train net output #0: loss = 0.983131 (* 1 = 0.983131 loss)\n",
            "I0605 10:06:17.596906 18057 sgd_solver.cpp:105] Iteration 2300, lr = 0.001\n",
            "I0605 10:06:23.681327 18057 solver.cpp:218] Iteration 2400 (16.4353 iter/s, 6.08447s/100 iters), loss = 1.10467\n",
            "I0605 10:06:23.681388 18057 solver.cpp:237]     Train net output #0: loss = 1.10467 (* 1 = 1.10467 loss)\n",
            "I0605 10:06:23.681403 18057 sgd_solver.cpp:105] Iteration 2400, lr = 0.001\n",
            "I0605 10:06:29.465471 18061 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:06:29.674017 18057 solver.cpp:330] Iteration 2500, Testing net (#0)\n",
            "I0605 10:06:31.834121 18062 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:06:31.921527 18057 solver.cpp:397]     Test net output #0: accuracy = 0.6035\n",
            "I0605 10:06:31.921594 18057 solver.cpp:397]     Test net output #1: loss = 1.13234 (* 1 = 1.13234 loss)\n",
            "I0605 10:06:31.981165 18057 solver.cpp:218] Iteration 2500 (12.0485 iter/s, 8.29981s/100 iters), loss = 1.13819\n",
            "I0605 10:06:31.981209 18057 solver.cpp:237]     Train net output #0: loss = 1.13819 (* 1 = 1.13819 loss)\n",
            "I0605 10:06:31.981223 18057 sgd_solver.cpp:105] Iteration 2500, lr = 0.001\n",
            "I0605 10:06:38.063647 18057 solver.cpp:218] Iteration 2600 (16.4407 iter/s, 6.08245s/100 iters), loss = 1.01918\n",
            "I0605 10:06:38.063745 18057 solver.cpp:237]     Train net output #0: loss = 1.01918 (* 1 = 1.01918 loss)\n",
            "I0605 10:06:38.063771 18057 sgd_solver.cpp:105] Iteration 2600, lr = 0.001\n",
            "I0605 10:06:44.154187 18057 solver.cpp:218] Iteration 2700 (16.4191 iter/s, 6.09046s/100 iters), loss = 1.16223\n",
            "I0605 10:06:44.154268 18057 solver.cpp:237]     Train net output #0: loss = 1.16223 (* 1 = 1.16223 loss)\n",
            "I0605 10:06:44.154291 18057 sgd_solver.cpp:105] Iteration 2700, lr = 0.001\n",
            "I0605 10:06:50.239423 18057 solver.cpp:218] Iteration 2800 (16.4334 iter/s, 6.08517s/100 iters), loss = 0.916345\n",
            "I0605 10:06:50.239486 18057 solver.cpp:237]     Train net output #0: loss = 0.916345 (* 1 = 0.916345 loss)\n",
            "I0605 10:06:50.239501 18057 sgd_solver.cpp:105] Iteration 2800, lr = 0.001\n",
            "I0605 10:06:56.326395 18057 solver.cpp:218] Iteration 2900 (16.4286 iter/s, 6.08693s/100 iters), loss = 1.08277\n",
            "I0605 10:06:56.326453 18057 solver.cpp:237]     Train net output #0: loss = 1.08277 (* 1 = 1.08277 loss)\n",
            "I0605 10:06:56.326467 18057 sgd_solver.cpp:105] Iteration 2900, lr = 0.001\n",
            "I0605 10:07:02.111805 18061 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:07:02.321393 18057 solver.cpp:330] Iteration 3000, Testing net (#0)\n",
            "I0605 10:07:04.483722 18062 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:07:04.570829 18057 solver.cpp:397]     Test net output #0: accuracy = 0.6282\n",
            "I0605 10:07:04.570894 18057 solver.cpp:397]     Test net output #1: loss = 1.081 (* 1 = 1.081 loss)\n",
            "I0605 10:07:04.630439 18057 solver.cpp:218] Iteration 3000 (12.0424 iter/s, 8.30402s/100 iters), loss = 1.08956\n",
            "I0605 10:07:04.630493 18057 solver.cpp:237]     Train net output #0: loss = 1.08956 (* 1 = 1.08956 loss)\n",
            "I0605 10:07:04.630511 18057 sgd_solver.cpp:105] Iteration 3000, lr = 0.001\n",
            "I0605 10:07:10.715121 18057 solver.cpp:218] Iteration 3100 (16.4348 iter/s, 6.08463s/100 iters), loss = 0.978979\n",
            "I0605 10:07:10.715195 18057 solver.cpp:237]     Train net output #0: loss = 0.978979 (* 1 = 0.978979 loss)\n",
            "I0605 10:07:10.715211 18057 sgd_solver.cpp:105] Iteration 3100, lr = 0.001\n",
            "I0605 10:07:16.801931 18057 solver.cpp:218] Iteration 3200 (16.4291 iter/s, 6.08674s/100 iters), loss = 1.07075\n",
            "I0605 10:07:16.801998 18057 solver.cpp:237]     Train net output #0: loss = 1.07075 (* 1 = 1.07075 loss)\n",
            "I0605 10:07:16.802012 18057 sgd_solver.cpp:105] Iteration 3200, lr = 0.001\n",
            "I0605 10:07:22.886103 18057 solver.cpp:218] Iteration 3300 (16.4362 iter/s, 6.08412s/100 iters), loss = 0.883765\n",
            "I0605 10:07:22.886194 18057 solver.cpp:237]     Train net output #0: loss = 0.883765 (* 1 = 0.883765 loss)\n",
            "I0605 10:07:22.886210 18057 sgd_solver.cpp:105] Iteration 3300, lr = 0.001\n",
            "I0605 10:07:28.973780 18057 solver.cpp:218] Iteration 3400 (16.4268 iter/s, 6.08761s/100 iters), loss = 1.00562\n",
            "I0605 10:07:28.973845 18057 solver.cpp:237]     Train net output #0: loss = 1.00562 (* 1 = 1.00562 loss)\n",
            "I0605 10:07:28.973860 18057 sgd_solver.cpp:105] Iteration 3400, lr = 0.001\n",
            "I0605 10:07:34.762298 18061 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:07:34.975487 18057 solver.cpp:330] Iteration 3500, Testing net (#0)\n",
            "I0605 10:07:37.131533 18062 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:07:37.218351 18057 solver.cpp:397]     Test net output #0: accuracy = 0.6402\n",
            "I0605 10:07:37.218430 18057 solver.cpp:397]     Test net output #1: loss = 1.04251 (* 1 = 1.04251 loss)\n",
            "I0605 10:07:37.278049 18057 solver.cpp:218] Iteration 3500 (12.042 iter/s, 8.30425s/100 iters), loss = 1.04679\n",
            "I0605 10:07:37.278095 18057 solver.cpp:237]     Train net output #0: loss = 1.04679 (* 1 = 1.04679 loss)\n",
            "I0605 10:07:37.278110 18057 sgd_solver.cpp:105] Iteration 3500, lr = 0.001\n",
            "I0605 10:07:43.363891 18057 solver.cpp:218] Iteration 3600 (16.4316 iter/s, 6.08582s/100 iters), loss = 0.936589\n",
            "I0605 10:07:43.363960 18057 solver.cpp:237]     Train net output #0: loss = 0.936589 (* 1 = 0.936589 loss)\n",
            "I0605 10:07:43.363976 18057 sgd_solver.cpp:105] Iteration 3600, lr = 0.001\n",
            "I0605 10:07:49.448019 18057 solver.cpp:218] Iteration 3700 (16.4363 iter/s, 6.08408s/100 iters), loss = 1.0263\n",
            "I0605 10:07:49.448078 18057 solver.cpp:237]     Train net output #0: loss = 1.0263 (* 1 = 1.0263 loss)\n",
            "I0605 10:07:49.448102 18057 sgd_solver.cpp:105] Iteration 3700, lr = 0.001\n",
            "I0605 10:07:55.534907 18057 solver.cpp:218] Iteration 3800 (16.4289 iter/s, 6.08685s/100 iters), loss = 0.86625\n",
            "I0605 10:07:55.534971 18057 solver.cpp:237]     Train net output #0: loss = 0.86625 (* 1 = 0.86625 loss)\n",
            "I0605 10:07:55.534987 18057 sgd_solver.cpp:105] Iteration 3800, lr = 0.001\n",
            "I0605 10:08:01.623692 18057 solver.cpp:218] Iteration 3900 (16.4237 iter/s, 6.08874s/100 iters), loss = 0.963366\n",
            "I0605 10:08:01.623751 18057 solver.cpp:237]     Train net output #0: loss = 0.963366 (* 1 = 0.963366 loss)\n",
            "I0605 10:08:01.623776 18057 sgd_solver.cpp:105] Iteration 3900, lr = 0.001\n",
            "I0605 10:08:07.406071 18061 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:08:07.616485 18057 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/cifar10_small_iter_4000.caffemodel\n",
            "I0605 10:08:07.648767 18057 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/cifar10_small_iter_4000.solverstate\n",
            "I0605 10:08:07.671272 18057 solver.cpp:310] Iteration 4000, loss = 0.997653\n",
            "I0605 10:08:07.671303 18057 solver.cpp:330] Iteration 4000, Testing net (#0)\n",
            "I0605 10:08:09.802170 18062 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:08:09.889354 18057 solver.cpp:397]     Test net output #0: accuracy = 0.6519\n",
            "I0605 10:08:09.889415 18057 solver.cpp:397]     Test net output #1: loss = 1.00938 (* 1 = 1.00938 loss)\n",
            "I0605 10:08:09.889441 18057 solver.cpp:315] Optimization Done.\n",
            "I0605 10:08:09.889449 18057 caffe.cpp:259] Optimization Done.\n",
            "I0605 10:08:10.041055 18090 caffe.cpp:218] Using GPUs 0\n",
            "I0605 10:08:10.064822 18090 caffe.cpp:223] GPU 0: Tesla K80\n",
            "I0605 10:08:10.284175 18090 solver.cpp:44] Initializing solver from parameters: \n",
            "test_iter: 100\n",
            "test_interval: 500\n",
            "base_lr: 0.0001\n",
            "display: 100\n",
            "max_iter: 5000\n",
            "lr_policy: \"fixed\"\n",
            "momentum: 0.9\n",
            "weight_decay: 0.004\n",
            "snapshot: 5000\n",
            "snapshot_prefix: \"examples/cifar10/cifar10_small\"\n",
            "solver_mode: GPU\n",
            "device_id: 0\n",
            "net: \"examples/cifar10/cifar10_m4_train_test_small.prototxt\"\n",
            "train_state {\n",
            "  level: 0\n",
            "  stage: \"\"\n",
            "}\n",
            "snapshot_format: HDF5\n",
            "I0605 10:08:10.284379 18090 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_m4_train_test_small.prototxt\n",
            "I0605 10:08:10.284673 18090 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data\n",
            "I0605 10:08:10.284710 18090 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy\n",
            "I0605 10:08:10.284819 18090 net.cpp:51] Initializing net from parameters: \n",
            "name: \"CIFAR10_small\"\n",
            "state {\n",
            "  phase: TRAIN\n",
            "  level: 0\n",
            "  stage: \"\"\n",
            "}\n",
            "layer {\n",
            "  name: \"data\"\n",
            "  type: \"Data\"\n",
            "  top: \"data\"\n",
            "  top: \"label\"\n",
            "  include {\n",
            "    phase: TRAIN\n",
            "  }\n",
            "  transform_param {\n",
            "    mean_file: \"examples/cifar10/mean.binaryproto\"\n",
            "  }\n",
            "  data_param {\n",
            "    source: \"examples/cifar10/cifar10_train_lmdb\"\n",
            "    batch_size: 100\n",
            "    backend: LMDB\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.0001\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu1\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"pool1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv2\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"conv2\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 16\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu2\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"conv2\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool2\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"pool2\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv3\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool2\"\n",
            "  top: \"conv3\"\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu3\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv3\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool3\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"pool3\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"ip1\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"pool3\"\n",
            "  top: \"ip1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 250\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 10\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"loss\"\n",
            "  type: \"SoftmaxWithLoss\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"loss\"\n",
            "}\n",
            "I0605 10:08:10.284907 18090 layer_factory.hpp:77] Creating layer data\n",
            "I0605 10:08:10.285043 18090 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_train_lmdb\n",
            "I0605 10:08:10.285086 18090 net.cpp:84] Creating Layer data\n",
            "I0605 10:08:10.285109 18090 net.cpp:380] data -> data\n",
            "I0605 10:08:10.285137 18090 net.cpp:380] data -> label\n",
            "I0605 10:08:10.285158 18090 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto\n",
            "I0605 10:08:10.286031 18090 data_layer.cpp:45] output data size: 100,3,32,32\n",
            "I0605 10:08:10.290652 18090 net.cpp:122] Setting up data\n",
            "I0605 10:08:10.290680 18090 net.cpp:129] Top shape: 100 3 32 32 (307200)\n",
            "I0605 10:08:10.290700 18090 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:08:10.290714 18090 net.cpp:137] Memory required for data: 1229200\n",
            "I0605 10:08:10.290771 18090 layer_factory.hpp:77] Creating layer conv1\n",
            "I0605 10:08:10.290814 18090 net.cpp:84] Creating Layer conv1\n",
            "I0605 10:08:10.290834 18090 net.cpp:406] conv1 <- data\n",
            "I0605 10:08:10.290854 18090 net.cpp:380] conv1 -> conv1\n",
            "I0605 10:08:10.291328 18090 net.cpp:122] Setting up conv1\n",
            "I0605 10:08:10.291359 18090 net.cpp:129] Top shape: 100 32 32 32 (3276800)\n",
            "I0605 10:08:10.291375 18090 net.cpp:137] Memory required for data: 14336400\n",
            "I0605 10:08:10.291395 18090 layer_factory.hpp:77] Creating layer pool1\n",
            "I0605 10:08:10.291415 18090 net.cpp:84] Creating Layer pool1\n",
            "I0605 10:08:10.291430 18090 net.cpp:406] pool1 <- conv1\n",
            "I0605 10:08:10.291446 18090 net.cpp:380] pool1 -> pool1\n",
            "I0605 10:08:10.291494 18090 net.cpp:122] Setting up pool1\n",
            "I0605 10:08:10.291517 18090 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:08:10.291527 18090 net.cpp:137] Memory required for data: 17613200\n",
            "I0605 10:08:10.291535 18090 layer_factory.hpp:77] Creating layer relu1\n",
            "I0605 10:08:10.291546 18090 net.cpp:84] Creating Layer relu1\n",
            "I0605 10:08:10.291555 18090 net.cpp:406] relu1 <- pool1\n",
            "I0605 10:08:10.291565 18090 net.cpp:367] relu1 -> pool1 (in-place)\n",
            "I0605 10:08:10.291581 18090 net.cpp:122] Setting up relu1\n",
            "I0605 10:08:10.291622 18090 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:08:10.291631 18090 net.cpp:137] Memory required for data: 20890000\n",
            "I0605 10:08:10.291640 18090 layer_factory.hpp:77] Creating layer conv2\n",
            "I0605 10:08:10.291668 18090 net.cpp:84] Creating Layer conv2\n",
            "I0605 10:08:10.291679 18090 net.cpp:406] conv2 <- pool1\n",
            "I0605 10:08:10.291690 18090 net.cpp:380] conv2 -> conv2\n",
            "I0605 10:08:10.292431 18090 net.cpp:122] Setting up conv2\n",
            "I0605 10:08:10.292465 18090 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:08:10.292481 18090 net.cpp:137] Memory required for data: 22528400\n",
            "I0605 10:08:10.292516 18090 layer_factory.hpp:77] Creating layer relu2\n",
            "I0605 10:08:10.292537 18090 net.cpp:84] Creating Layer relu2\n",
            "I0605 10:08:10.292553 18090 net.cpp:406] relu2 <- conv2\n",
            "I0605 10:08:10.292613 18090 net.cpp:367] relu2 -> conv2 (in-place)\n",
            "I0605 10:08:10.292639 18090 net.cpp:122] Setting up relu2\n",
            "I0605 10:08:10.292656 18090 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:08:10.292670 18090 net.cpp:137] Memory required for data: 24166800\n",
            "I0605 10:08:10.292683 18090 layer_factory.hpp:77] Creating layer pool2\n",
            "I0605 10:08:10.292701 18090 net.cpp:84] Creating Layer pool2\n",
            "I0605 10:08:10.292716 18090 net.cpp:406] pool2 <- conv2\n",
            "I0605 10:08:10.292733 18090 net.cpp:380] pool2 -> pool2\n",
            "I0605 10:08:10.292770 18090 net.cpp:122] Setting up pool2\n",
            "I0605 10:08:10.292804 18090 net.cpp:129] Top shape: 100 16 8 8 (102400)\n",
            "I0605 10:08:10.292834 18090 net.cpp:137] Memory required for data: 24576400\n",
            "I0605 10:08:10.292857 18090 layer_factory.hpp:77] Creating layer conv3\n",
            "I0605 10:08:10.292883 18090 net.cpp:84] Creating Layer conv3\n",
            "I0605 10:08:10.292901 18090 net.cpp:406] conv3 <- pool2\n",
            "I0605 10:08:10.292918 18090 net.cpp:380] conv3 -> conv3\n",
            "I0605 10:08:10.293375 18090 net.cpp:122] Setting up conv3\n",
            "I0605 10:08:10.293399 18090 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:08:10.293416 18090 net.cpp:137] Memory required for data: 25395600\n",
            "I0605 10:08:10.293434 18090 layer_factory.hpp:77] Creating layer relu3\n",
            "I0605 10:08:10.293450 18090 net.cpp:84] Creating Layer relu3\n",
            "I0605 10:08:10.293463 18090 net.cpp:406] relu3 <- conv3\n",
            "I0605 10:08:10.293478 18090 net.cpp:367] relu3 -> conv3 (in-place)\n",
            "I0605 10:08:10.293493 18090 net.cpp:122] Setting up relu3\n",
            "I0605 10:08:10.293538 18090 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:08:10.293551 18090 net.cpp:137] Memory required for data: 26214800\n",
            "I0605 10:08:10.293566 18090 layer_factory.hpp:77] Creating layer pool3\n",
            "I0605 10:08:10.293610 18090 net.cpp:84] Creating Layer pool3\n",
            "I0605 10:08:10.293632 18090 net.cpp:406] pool3 <- conv3\n",
            "I0605 10:08:10.293648 18090 net.cpp:380] pool3 -> pool3\n",
            "I0605 10:08:10.293723 18090 net.cpp:122] Setting up pool3\n",
            "I0605 10:08:10.293747 18090 net.cpp:129] Top shape: 100 32 4 4 (51200)\n",
            "I0605 10:08:10.293763 18090 net.cpp:137] Memory required for data: 26419600\n",
            "I0605 10:08:10.293821 18090 layer_factory.hpp:77] Creating layer ip1\n",
            "I0605 10:08:10.293850 18090 net.cpp:84] Creating Layer ip1\n",
            "I0605 10:08:10.293866 18090 net.cpp:406] ip1 <- pool3\n",
            "I0605 10:08:10.293893 18090 net.cpp:380] ip1 -> ip1\n",
            "I0605 10:08:10.294111 18090 net.cpp:122] Setting up ip1\n",
            "I0605 10:08:10.294134 18090 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:08:10.294157 18090 net.cpp:137] Memory required for data: 26423600\n",
            "I0605 10:08:10.294175 18090 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:08:10.294193 18090 net.cpp:84] Creating Layer loss\n",
            "I0605 10:08:10.294209 18090 net.cpp:406] loss <- ip1\n",
            "I0605 10:08:10.294225 18090 net.cpp:406] loss <- label\n",
            "I0605 10:08:10.294241 18090 net.cpp:380] loss -> loss\n",
            "I0605 10:08:10.294270 18090 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:08:10.294402 18090 net.cpp:122] Setting up loss\n",
            "I0605 10:08:10.294425 18090 net.cpp:129] Top shape: (1)\n",
            "I0605 10:08:10.294440 18090 net.cpp:132]     with loss weight 1\n",
            "I0605 10:08:10.294471 18090 net.cpp:137] Memory required for data: 26423604\n",
            "I0605 10:08:10.294486 18090 net.cpp:198] loss needs backward computation.\n",
            "I0605 10:08:10.294503 18090 net.cpp:198] ip1 needs backward computation.\n",
            "I0605 10:08:10.294517 18090 net.cpp:198] pool3 needs backward computation.\n",
            "I0605 10:08:10.294531 18090 net.cpp:198] relu3 needs backward computation.\n",
            "I0605 10:08:10.294545 18090 net.cpp:198] conv3 needs backward computation.\n",
            "I0605 10:08:10.294560 18090 net.cpp:198] pool2 needs backward computation.\n",
            "I0605 10:08:10.294625 18090 net.cpp:198] relu2 needs backward computation.\n",
            "I0605 10:08:10.294642 18090 net.cpp:198] conv2 needs backward computation.\n",
            "I0605 10:08:10.294658 18090 net.cpp:198] relu1 needs backward computation.\n",
            "I0605 10:08:10.294672 18090 net.cpp:198] pool1 needs backward computation.\n",
            "I0605 10:08:10.294685 18090 net.cpp:198] conv1 needs backward computation.\n",
            "I0605 10:08:10.294713 18090 net.cpp:200] data does not need backward computation.\n",
            "I0605 10:08:10.294751 18090 net.cpp:242] This network produces output loss\n",
            "I0605 10:08:10.294771 18090 net.cpp:255] Network initialization done.\n",
            "I0605 10:08:10.295053 18090 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_m4_train_test_small.prototxt\n",
            "I0605 10:08:10.295096 18090 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\n",
            "I0605 10:08:10.295224 18090 net.cpp:51] Initializing net from parameters: \n",
            "name: \"CIFAR10_small\"\n",
            "state {\n",
            "  phase: TEST\n",
            "}\n",
            "layer {\n",
            "  name: \"data\"\n",
            "  type: \"Data\"\n",
            "  top: \"data\"\n",
            "  top: \"label\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "  transform_param {\n",
            "    mean_file: \"examples/cifar10/mean.binaryproto\"\n",
            "  }\n",
            "  data_param {\n",
            "    source: \"examples/cifar10/cifar10_test_lmdb\"\n",
            "    batch_size: 100\n",
            "    backend: LMDB\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.0001\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu1\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"pool1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv2\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"conv2\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 16\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu2\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"conv2\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool2\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"pool2\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv3\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool2\"\n",
            "  top: \"conv3\"\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu3\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv3\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool3\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"pool3\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"ip1\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"pool3\"\n",
            "  top: \"ip1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 250\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 10\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"accuracy\"\n",
            "  type: \"Accuracy\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"accuracy\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"loss\"\n",
            "  type: \"SoftmaxWithLoss\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"loss\"\n",
            "}\n",
            "I0605 10:08:10.295346 18090 layer_factory.hpp:77] Creating layer data\n",
            "I0605 10:08:10.295450 18090 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb\n",
            "I0605 10:08:10.295485 18090 net.cpp:84] Creating Layer data\n",
            "I0605 10:08:10.295505 18090 net.cpp:380] data -> data\n",
            "I0605 10:08:10.295524 18090 net.cpp:380] data -> label\n",
            "I0605 10:08:10.295544 18090 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto\n",
            "I0605 10:08:10.295780 18090 data_layer.cpp:45] output data size: 100,3,32,32\n",
            "I0605 10:08:10.301700 18090 net.cpp:122] Setting up data\n",
            "I0605 10:08:10.301733 18090 net.cpp:129] Top shape: 100 3 32 32 (307200)\n",
            "I0605 10:08:10.301761 18090 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:08:10.301776 18090 net.cpp:137] Memory required for data: 1229200\n",
            "I0605 10:08:10.301806 18090 layer_factory.hpp:77] Creating layer label_data_1_split\n",
            "I0605 10:08:10.301826 18090 net.cpp:84] Creating Layer label_data_1_split\n",
            "I0605 10:08:10.301843 18090 net.cpp:406] label_data_1_split <- label\n",
            "I0605 10:08:10.301860 18090 net.cpp:380] label_data_1_split -> label_data_1_split_0\n",
            "I0605 10:08:10.301900 18090 net.cpp:380] label_data_1_split -> label_data_1_split_1\n",
            "I0605 10:08:10.301978 18090 net.cpp:122] Setting up label_data_1_split\n",
            "I0605 10:08:10.302003 18090 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:08:10.302019 18090 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:08:10.302031 18090 net.cpp:137] Memory required for data: 1230000\n",
            "I0605 10:08:10.302044 18090 layer_factory.hpp:77] Creating layer conv1\n",
            "I0605 10:08:10.302062 18090 net.cpp:84] Creating Layer conv1\n",
            "I0605 10:08:10.302075 18090 net.cpp:406] conv1 <- data\n",
            "I0605 10:08:10.302091 18090 net.cpp:380] conv1 -> conv1\n",
            "I0605 10:08:10.302428 18090 net.cpp:122] Setting up conv1\n",
            "I0605 10:08:10.302456 18090 net.cpp:129] Top shape: 100 32 32 32 (3276800)\n",
            "I0605 10:08:10.302472 18090 net.cpp:137] Memory required for data: 14337200\n",
            "I0605 10:08:10.302491 18090 layer_factory.hpp:77] Creating layer pool1\n",
            "I0605 10:08:10.302507 18090 net.cpp:84] Creating Layer pool1\n",
            "I0605 10:08:10.302521 18090 net.cpp:406] pool1 <- conv1\n",
            "I0605 10:08:10.302537 18090 net.cpp:380] pool1 -> pool1\n",
            "I0605 10:08:10.302666 18090 net.cpp:122] Setting up pool1\n",
            "I0605 10:08:10.302692 18090 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:08:10.302707 18090 net.cpp:137] Memory required for data: 17614000\n",
            "I0605 10:08:10.302722 18090 layer_factory.hpp:77] Creating layer relu1\n",
            "I0605 10:08:10.302738 18090 net.cpp:84] Creating Layer relu1\n",
            "I0605 10:08:10.324230 18090 net.cpp:406] relu1 <- pool1\n",
            "I0605 10:08:10.324272 18090 net.cpp:367] relu1 -> pool1 (in-place)\n",
            "I0605 10:08:10.324321 18090 net.cpp:122] Setting up relu1\n",
            "I0605 10:08:10.324342 18090 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:08:10.324357 18090 net.cpp:137] Memory required for data: 20890800\n",
            "I0605 10:08:10.324371 18090 layer_factory.hpp:77] Creating layer conv2\n",
            "I0605 10:08:10.324389 18090 net.cpp:84] Creating Layer conv2\n",
            "I0605 10:08:10.324404 18090 net.cpp:406] conv2 <- pool1\n",
            "I0605 10:08:10.324420 18090 net.cpp:380] conv2 -> conv2\n",
            "I0605 10:08:10.324898 18090 net.cpp:122] Setting up conv2\n",
            "I0605 10:08:10.324931 18090 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:08:10.324980 18090 net.cpp:137] Memory required for data: 22529200\n",
            "I0605 10:08:10.324998 18090 layer_factory.hpp:77] Creating layer relu2\n",
            "I0605 10:08:10.325019 18090 net.cpp:84] Creating Layer relu2\n",
            "I0605 10:08:10.325035 18090 net.cpp:406] relu2 <- conv2\n",
            "I0605 10:08:10.325053 18090 net.cpp:367] relu2 -> conv2 (in-place)\n",
            "I0605 10:08:10.325070 18090 net.cpp:122] Setting up relu2\n",
            "I0605 10:08:10.325085 18090 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:08:10.326493 18090 net.cpp:137] Memory required for data: 24167600\n",
            "I0605 10:08:10.326516 18090 layer_factory.hpp:77] Creating layer pool2\n",
            "I0605 10:08:10.326536 18090 net.cpp:84] Creating Layer pool2\n",
            "I0605 10:08:10.326553 18090 net.cpp:406] pool2 <- conv2\n",
            "I0605 10:08:10.326572 18090 net.cpp:380] pool2 -> pool2\n",
            "I0605 10:08:10.326661 18090 net.cpp:122] Setting up pool2\n",
            "I0605 10:08:10.326687 18090 net.cpp:129] Top shape: 100 16 8 8 (102400)\n",
            "I0605 10:08:10.326704 18090 net.cpp:137] Memory required for data: 24577200\n",
            "I0605 10:08:10.326719 18090 layer_factory.hpp:77] Creating layer conv3\n",
            "I0605 10:08:10.326741 18090 net.cpp:84] Creating Layer conv3\n",
            "I0605 10:08:10.326759 18090 net.cpp:406] conv3 <- pool2\n",
            "I0605 10:08:10.326779 18090 net.cpp:380] conv3 -> conv3\n",
            "I0605 10:08:10.327322 18090 net.cpp:122] Setting up conv3\n",
            "I0605 10:08:10.327358 18090 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:08:10.327378 18090 net.cpp:137] Memory required for data: 25396400\n",
            "I0605 10:08:10.327399 18090 layer_factory.hpp:77] Creating layer relu3\n",
            "I0605 10:08:10.327420 18090 net.cpp:84] Creating Layer relu3\n",
            "I0605 10:08:10.327440 18090 net.cpp:406] relu3 <- conv3\n",
            "I0605 10:08:10.327458 18090 net.cpp:367] relu3 -> conv3 (in-place)\n",
            "I0605 10:08:10.327478 18090 net.cpp:122] Setting up relu3\n",
            "I0605 10:08:10.327497 18090 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:08:10.327510 18090 net.cpp:137] Memory required for data: 26215600\n",
            "I0605 10:08:10.327522 18090 layer_factory.hpp:77] Creating layer pool3\n",
            "I0605 10:08:10.327539 18090 net.cpp:84] Creating Layer pool3\n",
            "I0605 10:08:10.327554 18090 net.cpp:406] pool3 <- conv3\n",
            "I0605 10:08:10.327570 18090 net.cpp:380] pool3 -> pool3\n",
            "I0605 10:08:10.327667 18090 net.cpp:122] Setting up pool3\n",
            "I0605 10:08:10.327695 18090 net.cpp:129] Top shape: 100 32 4 4 (51200)\n",
            "I0605 10:08:10.327713 18090 net.cpp:137] Memory required for data: 26420400\n",
            "I0605 10:08:10.327742 18090 layer_factory.hpp:77] Creating layer ip1\n",
            "I0605 10:08:10.327764 18090 net.cpp:84] Creating Layer ip1\n",
            "I0605 10:08:10.327780 18090 net.cpp:406] ip1 <- pool3\n",
            "I0605 10:08:10.327811 18090 net.cpp:380] ip1 -> ip1\n",
            "I0605 10:08:10.328054 18090 net.cpp:122] Setting up ip1\n",
            "I0605 10:08:10.328081 18090 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:08:10.328096 18090 net.cpp:137] Memory required for data: 26424400\n",
            "I0605 10:08:10.328114 18090 layer_factory.hpp:77] Creating layer ip1_ip1_0_split\n",
            "I0605 10:08:10.328131 18090 net.cpp:84] Creating Layer ip1_ip1_0_split\n",
            "I0605 10:08:10.328146 18090 net.cpp:406] ip1_ip1_0_split <- ip1\n",
            "I0605 10:08:10.328171 18090 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0\n",
            "I0605 10:08:10.328189 18090 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1\n",
            "I0605 10:08:10.328243 18090 net.cpp:122] Setting up ip1_ip1_0_split\n",
            "I0605 10:08:10.328266 18090 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:08:10.328280 18090 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:08:10.328292 18090 net.cpp:137] Memory required for data: 26432400\n",
            "I0605 10:08:10.328306 18090 layer_factory.hpp:77] Creating layer accuracy\n",
            "I0605 10:08:10.328325 18090 net.cpp:84] Creating Layer accuracy\n",
            "I0605 10:08:10.328338 18090 net.cpp:406] accuracy <- ip1_ip1_0_split_0\n",
            "I0605 10:08:10.328351 18090 net.cpp:406] accuracy <- label_data_1_split_0\n",
            "I0605 10:08:10.328366 18090 net.cpp:380] accuracy -> accuracy\n",
            "I0605 10:08:10.328385 18090 net.cpp:122] Setting up accuracy\n",
            "I0605 10:08:10.328402 18090 net.cpp:129] Top shape: (1)\n",
            "I0605 10:08:10.328413 18090 net.cpp:137] Memory required for data: 26432404\n",
            "I0605 10:08:10.328425 18090 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:08:10.328441 18090 net.cpp:84] Creating Layer loss\n",
            "I0605 10:08:10.328485 18090 net.cpp:406] loss <- ip1_ip1_0_split_1\n",
            "I0605 10:08:10.328500 18090 net.cpp:406] loss <- label_data_1_split_1\n",
            "I0605 10:08:10.328531 18090 net.cpp:380] loss -> loss\n",
            "I0605 10:08:10.328548 18090 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:08:10.328704 18090 net.cpp:122] Setting up loss\n",
            "I0605 10:08:10.328743 18090 net.cpp:129] Top shape: (1)\n",
            "I0605 10:08:10.328756 18090 net.cpp:132]     with loss weight 1\n",
            "I0605 10:08:10.328776 18090 net.cpp:137] Memory required for data: 26432408\n",
            "I0605 10:08:10.328819 18090 net.cpp:198] loss needs backward computation.\n",
            "I0605 10:08:10.328850 18090 net.cpp:200] accuracy does not need backward computation.\n",
            "I0605 10:08:10.328864 18090 net.cpp:198] ip1_ip1_0_split needs backward computation.\n",
            "I0605 10:08:10.328876 18090 net.cpp:198] ip1 needs backward computation.\n",
            "I0605 10:08:10.328888 18090 net.cpp:198] pool3 needs backward computation.\n",
            "I0605 10:08:10.328900 18090 net.cpp:198] relu3 needs backward computation.\n",
            "I0605 10:08:10.328912 18090 net.cpp:198] conv3 needs backward computation.\n",
            "I0605 10:08:10.328929 18090 net.cpp:198] pool2 needs backward computation.\n",
            "I0605 10:08:10.328944 18090 net.cpp:198] relu2 needs backward computation.\n",
            "I0605 10:08:10.328956 18090 net.cpp:198] conv2 needs backward computation.\n",
            "I0605 10:08:10.328969 18090 net.cpp:198] relu1 needs backward computation.\n",
            "I0605 10:08:10.328979 18090 net.cpp:198] pool1 needs backward computation.\n",
            "I0605 10:08:10.328992 18090 net.cpp:198] conv1 needs backward computation.\n",
            "I0605 10:08:10.329005 18090 net.cpp:200] label_data_1_split does not need backward computation.\n",
            "I0605 10:08:10.329020 18090 net.cpp:200] data does not need backward computation.\n",
            "I0605 10:08:10.329033 18090 net.cpp:242] This network produces output accuracy\n",
            "I0605 10:08:10.329053 18090 net.cpp:242] This network produces output loss\n",
            "I0605 10:08:10.329077 18090 net.cpp:255] Network initialization done.\n",
            "I0605 10:08:10.329147 18090 solver.cpp:56] Solver scaffolding done.\n",
            "I0605 10:08:10.329494 18090 caffe.cpp:242] Resuming from examples/cifar10/cifar10_small_iter_4000.solverstate\n",
            "I0605 10:08:10.330127 18090 sgd_solver.cpp:318] SGDSolver: restoring history\n",
            "I0605 10:08:10.330258 18090 caffe.cpp:248] Starting Optimization\n",
            "I0605 10:08:10.330283 18090 solver.cpp:272] Solving CIFAR10_small\n",
            "I0605 10:08:10.330293 18090 solver.cpp:273] Learning Rate Policy: fixed\n",
            "I0605 10:08:10.330432 18090 solver.cpp:330] Iteration 4000, Testing net (#0)\n",
            "I0605 10:08:12.469384 18095 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:08:12.556619 18090 solver.cpp:397]     Test net output #0: accuracy = 0.6519\n",
            "I0605 10:08:12.556665 18090 solver.cpp:397]     Test net output #1: loss = 1.00938 (* 1 = 1.00938 loss)\n",
            "I0605 10:08:12.617116 18090 solver.cpp:218] Iteration 4000 (1749.17 iter/s, 2.28679s/100 iters), loss = 0.997653\n",
            "I0605 10:08:12.617172 18090 solver.cpp:237]     Train net output #0: loss = 0.997653 (* 1 = 0.997653 loss)\n",
            "I0605 10:08:12.617198 18090 sgd_solver.cpp:105] Iteration 4000, lr = 0.0001\n",
            "I0605 10:08:18.727363 18090 solver.cpp:218] Iteration 4100 (16.366 iter/s, 6.11021s/100 iters), loss = 0.891166\n",
            "I0605 10:08:18.727432 18090 solver.cpp:237]     Train net output #0: loss = 0.891166 (* 1 = 0.891166 loss)\n",
            "I0605 10:08:18.727460 18090 sgd_solver.cpp:105] Iteration 4100, lr = 0.0001\n",
            "I0605 10:08:24.831641 18090 solver.cpp:218] Iteration 4200 (16.3821 iter/s, 6.10422s/100 iters), loss = 0.828646\n",
            "I0605 10:08:24.831734 18090 solver.cpp:237]     Train net output #0: loss = 0.828646 (* 1 = 0.828646 loss)\n",
            "I0605 10:08:24.831749 18090 sgd_solver.cpp:105] Iteration 4200, lr = 0.0001\n",
            "I0605 10:08:30.940570 18090 solver.cpp:218] Iteration 4300 (16.3696 iter/s, 6.10887s/100 iters), loss = 0.71384\n",
            "I0605 10:08:30.940659 18090 solver.cpp:237]     Train net output #0: loss = 0.71384 (* 1 = 0.71384 loss)\n",
            "I0605 10:08:30.940683 18090 sgd_solver.cpp:105] Iteration 4300, lr = 0.0001\n",
            "I0605 10:08:37.045944 18090 solver.cpp:218] Iteration 4400 (16.3792 iter/s, 6.10531s/100 iters), loss = 0.803994\n",
            "I0605 10:08:37.046028 18090 solver.cpp:237]     Train net output #0: loss = 0.803994 (* 1 = 0.803994 loss)\n",
            "I0605 10:08:37.046130 18090 sgd_solver.cpp:105] Iteration 4400, lr = 0.0001\n",
            "I0605 10:08:42.848060 18094 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:08:43.060359 18090 solver.cpp:330] Iteration 4500, Testing net (#0)\n",
            "I0605 10:08:45.225428 18095 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:08:45.313078 18090 solver.cpp:397]     Test net output #0: accuracy = 0.6879\n",
            "I0605 10:08:45.313122 18090 solver.cpp:397]     Test net output #1: loss = 0.912443 (* 1 = 0.912443 loss)\n",
            "I0605 10:08:45.372828 18090 solver.cpp:218] Iteration 4500 (12.0094 iter/s, 8.32684s/100 iters), loss = 0.870693\n",
            "I0605 10:08:45.372901 18090 solver.cpp:237]     Train net output #0: loss = 0.870693 (* 1 = 0.870693 loss)\n",
            "I0605 10:08:45.372922 18090 sgd_solver.cpp:105] Iteration 4500, lr = 0.0001\n",
            "I0605 10:08:51.478031 18090 solver.cpp:218] Iteration 4600 (16.3796 iter/s, 6.10514s/100 iters), loss = 0.826748\n",
            "I0605 10:08:51.478112 18090 solver.cpp:237]     Train net output #0: loss = 0.826748 (* 1 = 0.826748 loss)\n",
            "I0605 10:08:51.478132 18090 sgd_solver.cpp:105] Iteration 4600, lr = 0.0001\n",
            "I0605 10:08:57.582046 18090 solver.cpp:218] Iteration 4700 (16.3829 iter/s, 6.10393s/100 iters), loss = 0.775642\n",
            "I0605 10:08:57.582126 18090 solver.cpp:237]     Train net output #0: loss = 0.775642 (* 1 = 0.775642 loss)\n",
            "I0605 10:08:57.582150 18090 sgd_solver.cpp:105] Iteration 4700, lr = 0.0001\n",
            "I0605 10:09:03.698173 18090 solver.cpp:218] Iteration 4800 (16.3504 iter/s, 6.11607s/100 iters), loss = 0.710789\n",
            "I0605 10:09:03.698249 18090 solver.cpp:237]     Train net output #0: loss = 0.710789 (* 1 = 0.710789 loss)\n",
            "I0605 10:09:03.698274 18090 sgd_solver.cpp:105] Iteration 4800, lr = 0.0001\n",
            "I0605 10:09:09.801451 18090 solver.cpp:218] Iteration 4900 (16.3848 iter/s, 6.10322s/100 iters), loss = 0.805324\n",
            "I0605 10:09:09.801529 18090 solver.cpp:237]     Train net output #0: loss = 0.805324 (* 1 = 0.805324 loss)\n",
            "I0605 10:09:09.801555 18090 sgd_solver.cpp:105] Iteration 4900, lr = 0.0001\n",
            "I0605 10:09:15.603479 18094 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:09:15.813112 18090 solver.cpp:457] Snapshotting to HDF5 file examples/cifar10/cifar10_small_iter_5000.caffemodel.h5\n",
            "I0605 10:09:15.851384 18090 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file examples/cifar10/cifar10_small_iter_5000.solverstate.h5\n",
            "I0605 10:09:15.875517 18090 solver.cpp:310] Iteration 5000, loss = 0.873893\n",
            "I0605 10:09:15.875560 18090 solver.cpp:330] Iteration 5000, Testing net (#0)\n",
            "I0605 10:09:18.012373 18095 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "I0605 10:09:18.099253 18090 solver.cpp:397]     Test net output #0: accuracy = 0.6874\n",
            "I0605 10:09:18.099303 18090 solver.cpp:397]     Test net output #1: loss = 0.910798 (* 1 = 0.910798 loss)\n",
            "I0605 10:09:18.099313 18090 solver.cpp:315] Optimization Done.\n",
            "I0605 10:09:18.099323 18090 caffe.cpp:259] Optimization Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Svz5cDhipEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"# cifar10_m4_train_test_small.prototxt\n",
        "!wget -q https://gist.githubusercontent.com/Tony607/f3797c737abdedcde20e4d48622f9c95/raw/cifar10_m4_train_test_small.prototxt -O examples/cifar10/cifar10_m4_train_test_small.prototxt\n",
        "# train_small_colab.sh\n",
        "!wget -q https://gist.githubusercontent.com/Tony607/5569923d09e1c1ce389f2c0958aa6bc9/raw/train_small_colab.sh -O ./examples/cifar10/train_small_colab.sh\n",
        "# cifar10_small_solver_lr1.prototxt\n",
        "!wget https://gist.githubusercontent.com/Tony607/5554c02f4f7efc2bde48cc676a5281f4/raw/cifar10_small_solver_lr1.prototxt -O ./examples/cifar10/cifar10_small_solver_lr1.prototxt\n",
        "# cifar10_small_solver.prototxt\n",
        "!wget -q https://gist.githubusercontent.com/Tony607/79463f2f002768c198a50c05187647ff/raw/cifar10_small_solver.prototxt -O ./examples/cifar10/cifar10_small_solver.prototxt\n",
        "# Make the script runnable.\n",
        "!chmod +x ./examples/cifar10/train_small_colab.sh\n",
        "!ls examples/cifar10\n",
        "!./examples/cifar10/train_small_colab.sh\"\"\" \n",
        "# Run each command separetely to see changes in directory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih4ExaLoi2nk",
        "colab_type": "code",
        "outputId": "1898ef4e-57e0-4163-de06-97026f5f1da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "!ls -alh ./examples/cifar10/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 684K\n",
            "drwxr-xr-x  4 root root 4.0K Jun  5 10:09 .\n",
            "drwxr-xr-x 15 root root 4.0K Jun  5 09:57 ..\n",
            "-rw-r--r--  1 root root 2.2K Jun  5 09:57 cifar10_full.prototxt\n",
            "-rw-r--r--  1 root root  959 Jun  5 09:57 cifar10_full_sigmoid_solver_bn.prototxt\n",
            "-rw-r--r--  1 root root  953 Jun  5 09:57 cifar10_full_sigmoid_solver.prototxt\n",
            "-rw-r--r--  1 root root 3.2K Jun  5 09:57 cifar10_full_sigmoid_train_test_bn.prototxt\n",
            "-rw-r--r--  1 root root 2.9K Jun  5 09:57 cifar10_full_sigmoid_train_test.prototxt\n",
            "-rw-r--r--  1 root root  944 Jun  5 09:57 cifar10_full_solver_lr1.prototxt\n",
            "-rw-r--r--  1 root root  945 Jun  5 09:57 cifar10_full_solver_lr2.prototxt\n",
            "-rw-r--r--  1 root root  944 Jun  5 09:57 cifar10_full_solver.prototxt\n",
            "-rw-r--r--  1 root root 3.1K Jun  5 09:57 cifar10_full_train_test.prototxt\n",
            "-rw-r--r--  1 root root 2.8K Jun  5 09:58 cifar10_m4_train_test_small.prototxt\n",
            "-rw-r--r--  1 root root 1.9K Jun  5 09:57 cifar10_quick.prototxt\n",
            "-rw-r--r--  1 root root  882 Jun  5 09:57 cifar10_quick_solver_lr1.prototxt\n",
            "-rw-r--r--  1 root root  859 Jun  5 09:57 cifar10_quick_solver.prototxt\n",
            "-rw-r--r--  1 root root 3.1K Jun  5 09:57 cifar10_quick_train_test.prototxt\n",
            "-rw-r--r--  1 root root 131K Jun  5 10:08 cifar10_small_iter_4000.caffemodel\n",
            "-rw-r--r--  1 root root 130K Jun  5 10:08 cifar10_small_iter_4000.solverstate\n",
            "-rw-r--r--  1 root root 146K Jun  5 10:09 cifar10_small_iter_5000.caffemodel.h5\n",
            "-rw-r--r--  1 root root 138K Jun  5 10:09 cifar10_small_iter_5000.solverstate.h5\n",
            "-rw-r--r--  1 root root  885 Jun  5 10:02 cifar10_small_solver_lr1.prototxt\n",
            "-rw-r--r--  1 root root  862 Jun  5 10:02 cifar10_small_solver.prototxt\n",
            "drwxr--r--  2 root root 4.0K Jun  5 09:58 cifar10_test_lmdb\n",
            "drwxr--r--  2 root root 4.0K Jun  5 09:58 cifar10_train_lmdb\n",
            "-rw-r--r--  1 root root 3.6K Jun  5 09:57 convert_cifar_data.cpp\n",
            "-rwxr-xr-x  1 root root  467 Jun  5 09:57 create_cifar10.sh\n",
            "-rw-r--r--  1 root root  13K Jun  5 09:58 mean.binaryproto\n",
            "-rw-r--r--  1 root root 5.2K Jun  5 09:57 readme.md\n",
            "-rwxr-xr-x  1 root root  524 Jun  5 09:57 train_full.sh\n",
            "-rwxr-xr-x  1 root root  142 Jun  5 09:57 train_full_sigmoid_bn.sh\n",
            "-rwxr-xr-x  1 root root  139 Jun  5 09:57 train_full_sigmoid.sh\n",
            "-rwxr-xr-x  1 root root  338 Jun  5 09:57 train_quick.sh\n",
            "-rwxr-xr-x  1 root root  302 Jun  5 09:59 train_small_colab.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcc9zhq5mE1k",
        "colab_type": "text"
      },
      "source": [
        "Optionally download the trained model weights file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJCcTByb-0HY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('./examples/cifar10/cifar10_small_iter_5000.caffemodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk1hcRahrtB2",
        "colab_type": "text"
      },
      "source": [
        "## Download quantizer scripts\n",
        "Adopted from [ML-examples/cmsisnn-cifar10/](https://github.com/ARM-software/ML-examples/tree/master/cmsisnn-cifar10) with minor modification to be able to tackle models with more variations. And some renamed header definition names.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4myVwwLHrrcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/caffe')\n",
        "!mkdir quant\n",
        "# nn_quantizer.py\n",
        "!wget -q https://gist.githubusercontent.com/Tony607/3b7ba419609cb7918394299c5a4a68da/raw/nn_quantizer.py -O ./quant/nn_quantizer.py\n",
        "# code_gen.py\n",
        "!wget -q https://gist.githubusercontent.com/Tony607/79fd5e86a2eee6eff7271c9b69b3b3d2/raw/code_gen.py -O ./quant/code_gen.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EdZOwqBqfxF",
        "colab_type": "text"
      },
      "source": [
        "## Run the quantizer\n",
        "Quantization to 8-bit weights and activations.\n",
        "\n",
        "`nn_quantizer.py`: Needs Caffe model definition (.prototxt) used for training/testing the model that consists of valid paths to datasets (lmdb) and trained model file (.caffemodel). It parses the network graph connectivity, quantize the caffemodel to 8-bit weights/activations layer-by-layer incrementally with minimal loss in accuracy on the test dataset. It dumps the network graph connectivity, quantization parameters into a pickle file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqMgqYeAqu1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure in 'caffe' directory first\n",
        "import os\n",
        "os.chdir('/content/caffe')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xeDsKPQqfxG",
        "colab_type": "code",
        "outputId": "9651f7b4-202a-46b4-b283-c351fcf0e506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python ./quant/nn_quantizer.py \\\n",
        "--model examples/cifar10/cifar10_m4_train_test_small.prototxt \\\n",
        "--weights examples/cifar10/cifar10_small_iter_5000.caffemodel.h5 \\\n",
        "--save examples/cifar10/cifar10_m4_small.pkl \\\n",
        "--gpu"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
            "W0605 10:39:52.794220 18143 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface\n",
            "W0605 10:39:52.794292 18143 _caffe.cpp:140] Use this instead (with the named \"weights\" parameter):\n",
            "W0605 10:39:52.794302 18143 _caffe.cpp:142] Net('examples/cifar10/cifar10_m4_train_test_small.prototxt', 1, weights='examples/cifar10/cifar10_small_iter_5000.caffemodel.h5')\n",
            "I0605 10:39:53.025558 18143 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\n",
            "I0605 10:39:53.025805 18143 net.cpp:51] Initializing net from parameters: \n",
            "name: \"CIFAR10_small\"\n",
            "state {\n",
            "  phase: TEST\n",
            "  level: 0\n",
            "}\n",
            "layer {\n",
            "  name: \"data\"\n",
            "  type: \"Data\"\n",
            "  top: \"data\"\n",
            "  top: \"label\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "  transform_param {\n",
            "    mean_file: \"examples/cifar10/mean.binaryproto\"\n",
            "  }\n",
            "  data_param {\n",
            "    source: \"examples/cifar10/cifar10_test_lmdb\"\n",
            "    batch_size: 100\n",
            "    backend: LMDB\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.0001\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu1\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"pool1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv2\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"conv2\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 16\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu2\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"conv2\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool2\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"pool2\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv3\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool2\"\n",
            "  top: \"conv3\"\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu3\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv3\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool3\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"pool3\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"ip1\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"pool3\"\n",
            "  top: \"ip1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 250\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 10\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"accuracy\"\n",
            "  type: \"Accuracy\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"accuracy\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"loss\"\n",
            "  type: \"SoftmaxWithLoss\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"loss\"\n",
            "}\n",
            "I0605 10:39:53.025928 18143 layer_factory.hpp:77] Creating layer data\n",
            "I0605 10:39:53.026094 18143 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb\n",
            "I0605 10:39:53.026124 18143 net.cpp:84] Creating Layer data\n",
            "I0605 10:39:53.026134 18143 net.cpp:380] data -> data\n",
            "I0605 10:39:53.026211 18143 net.cpp:380] data -> label\n",
            "I0605 10:39:53.026232 18143 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto\n",
            "I0605 10:39:53.026413 18143 data_layer.cpp:45] output data size: 100,3,32,32\n",
            "I0605 10:39:53.030126 18143 net.cpp:122] Setting up data\n",
            "I0605 10:39:53.030160 18143 net.cpp:129] Top shape: 100 3 32 32 (307200)\n",
            "I0605 10:39:53.030177 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:39:53.030190 18143 net.cpp:137] Memory required for data: 1229200\n",
            "I0605 10:39:53.030216 18143 layer_factory.hpp:77] Creating layer label_data_1_split\n",
            "I0605 10:39:53.030236 18143 net.cpp:84] Creating Layer label_data_1_split\n",
            "I0605 10:39:53.030248 18143 net.cpp:406] label_data_1_split <- label\n",
            "I0605 10:39:53.030261 18143 net.cpp:380] label_data_1_split -> label_data_1_split_0\n",
            "I0605 10:39:53.030274 18143 net.cpp:380] label_data_1_split -> label_data_1_split_1\n",
            "I0605 10:39:53.030289 18143 net.cpp:122] Setting up label_data_1_split\n",
            "I0605 10:39:53.030300 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:39:53.030311 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:39:53.030321 18143 net.cpp:137] Memory required for data: 1230000\n",
            "I0605 10:39:53.030331 18143 layer_factory.hpp:77] Creating layer conv1\n",
            "I0605 10:39:53.030346 18143 net.cpp:84] Creating Layer conv1\n",
            "I0605 10:39:53.030359 18143 net.cpp:406] conv1 <- data\n",
            "I0605 10:39:53.030370 18143 net.cpp:380] conv1 -> conv1\n",
            "I0605 10:39:53.030437 18143 net.cpp:122] Setting up conv1\n",
            "I0605 10:39:53.030458 18143 net.cpp:129] Top shape: 100 32 32 32 (3276800)\n",
            "I0605 10:39:53.030469 18143 net.cpp:137] Memory required for data: 14337200\n",
            "I0605 10:39:53.030484 18143 layer_factory.hpp:77] Creating layer pool1\n",
            "I0605 10:39:53.030499 18143 net.cpp:84] Creating Layer pool1\n",
            "I0605 10:39:53.030505 18143 net.cpp:406] pool1 <- conv1\n",
            "I0605 10:39:53.030516 18143 net.cpp:380] pool1 -> pool1\n",
            "I0605 10:39:53.030532 18143 net.cpp:122] Setting up pool1\n",
            "I0605 10:39:53.030545 18143 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:39:53.030555 18143 net.cpp:137] Memory required for data: 17614000\n",
            "I0605 10:39:53.030560 18143 layer_factory.hpp:77] Creating layer relu1\n",
            "I0605 10:39:53.030570 18143 net.cpp:84] Creating Layer relu1\n",
            "I0605 10:39:53.030580 18143 net.cpp:406] relu1 <- pool1\n",
            "I0605 10:39:53.030601 18143 net.cpp:367] relu1 -> pool1 (in-place)\n",
            "I0605 10:39:53.030611 18143 net.cpp:122] Setting up relu1\n",
            "I0605 10:39:53.030622 18143 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:39:53.030628 18143 net.cpp:137] Memory required for data: 20890800\n",
            "I0605 10:39:53.030633 18143 layer_factory.hpp:77] Creating layer conv2\n",
            "I0605 10:39:53.030645 18143 net.cpp:84] Creating Layer conv2\n",
            "I0605 10:39:53.030652 18143 net.cpp:406] conv2 <- pool1\n",
            "I0605 10:39:53.030663 18143 net.cpp:380] conv2 -> conv2\n",
            "I0605 10:39:53.030881 18143 net.cpp:122] Setting up conv2\n",
            "I0605 10:39:53.030901 18143 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:39:53.030913 18143 net.cpp:137] Memory required for data: 22529200\n",
            "I0605 10:39:53.030927 18143 layer_factory.hpp:77] Creating layer relu2\n",
            "I0605 10:39:53.030939 18143 net.cpp:84] Creating Layer relu2\n",
            "I0605 10:39:53.030948 18143 net.cpp:406] relu2 <- conv2\n",
            "I0605 10:39:53.030959 18143 net.cpp:367] relu2 -> conv2 (in-place)\n",
            "I0605 10:39:53.030969 18143 net.cpp:122] Setting up relu2\n",
            "I0605 10:39:53.030980 18143 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:39:53.030990 18143 net.cpp:137] Memory required for data: 24167600\n",
            "I0605 10:39:53.030999 18143 layer_factory.hpp:77] Creating layer pool2\n",
            "I0605 10:39:53.031011 18143 net.cpp:84] Creating Layer pool2\n",
            "I0605 10:39:53.031021 18143 net.cpp:406] pool2 <- conv2\n",
            "I0605 10:39:53.031064 18143 net.cpp:380] pool2 -> pool2\n",
            "I0605 10:39:53.031077 18143 net.cpp:122] Setting up pool2\n",
            "I0605 10:39:53.031090 18143 net.cpp:129] Top shape: 100 16 8 8 (102400)\n",
            "I0605 10:39:53.031100 18143 net.cpp:137] Memory required for data: 24577200\n",
            "I0605 10:39:53.031109 18143 layer_factory.hpp:77] Creating layer conv3\n",
            "I0605 10:39:53.031134 18143 net.cpp:84] Creating Layer conv3\n",
            "I0605 10:39:53.031147 18143 net.cpp:406] conv3 <- pool2\n",
            "I0605 10:39:53.031159 18143 net.cpp:380] conv3 -> conv3\n",
            "I0605 10:39:53.031433 18143 net.cpp:122] Setting up conv3\n",
            "I0605 10:39:53.031451 18143 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:39:53.031461 18143 net.cpp:137] Memory required for data: 25396400\n",
            "I0605 10:39:53.031476 18143 layer_factory.hpp:77] Creating layer relu3\n",
            "I0605 10:39:53.031492 18143 net.cpp:84] Creating Layer relu3\n",
            "I0605 10:39:53.031503 18143 net.cpp:406] relu3 <- conv3\n",
            "I0605 10:39:53.031514 18143 net.cpp:367] relu3 -> conv3 (in-place)\n",
            "I0605 10:39:53.031527 18143 net.cpp:122] Setting up relu3\n",
            "I0605 10:39:53.031540 18143 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:39:53.031551 18143 net.cpp:137] Memory required for data: 26215600\n",
            "I0605 10:39:53.031560 18143 layer_factory.hpp:77] Creating layer pool3\n",
            "I0605 10:39:53.031574 18143 net.cpp:84] Creating Layer pool3\n",
            "I0605 10:39:53.031605 18143 net.cpp:406] pool3 <- conv3\n",
            "I0605 10:39:53.031620 18143 net.cpp:380] pool3 -> pool3\n",
            "I0605 10:39:53.031633 18143 net.cpp:122] Setting up pool3\n",
            "I0605 10:39:53.031646 18143 net.cpp:129] Top shape: 100 32 4 4 (51200)\n",
            "I0605 10:39:53.031656 18143 net.cpp:137] Memory required for data: 26420400\n",
            "I0605 10:39:53.031666 18143 layer_factory.hpp:77] Creating layer ip1\n",
            "I0605 10:39:53.031679 18143 net.cpp:84] Creating Layer ip1\n",
            "I0605 10:39:53.031692 18143 net.cpp:406] ip1 <- pool3\n",
            "I0605 10:39:53.031702 18143 net.cpp:380] ip1 -> ip1\n",
            "I0605 10:39:53.031796 18143 net.cpp:122] Setting up ip1\n",
            "I0605 10:39:53.031811 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:39:53.031822 18143 net.cpp:137] Memory required for data: 26424400\n",
            "I0605 10:39:53.031836 18143 layer_factory.hpp:77] Creating layer ip1_ip1_0_split\n",
            "I0605 10:39:53.031847 18143 net.cpp:84] Creating Layer ip1_ip1_0_split\n",
            "I0605 10:39:53.031884 18143 net.cpp:406] ip1_ip1_0_split <- ip1\n",
            "I0605 10:39:53.031894 18143 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0\n",
            "I0605 10:39:53.031909 18143 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1\n",
            "I0605 10:39:53.031924 18143 net.cpp:122] Setting up ip1_ip1_0_split\n",
            "I0605 10:39:53.031935 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:39:53.031946 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:39:53.031956 18143 net.cpp:137] Memory required for data: 26432400\n",
            "I0605 10:39:53.031966 18143 layer_factory.hpp:77] Creating layer accuracy\n",
            "I0605 10:39:53.031980 18143 net.cpp:84] Creating Layer accuracy\n",
            "I0605 10:39:53.031991 18143 net.cpp:406] accuracy <- ip1_ip1_0_split_0\n",
            "I0605 10:39:53.032002 18143 net.cpp:406] accuracy <- label_data_1_split_0\n",
            "I0605 10:39:53.032016 18143 net.cpp:380] accuracy -> accuracy\n",
            "I0605 10:39:53.032030 18143 net.cpp:122] Setting up accuracy\n",
            "I0605 10:39:53.032042 18143 net.cpp:129] Top shape: (1)\n",
            "I0605 10:39:53.032052 18143 net.cpp:137] Memory required for data: 26432404\n",
            "I0605 10:39:53.032076 18143 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:39:53.032088 18143 net.cpp:84] Creating Layer loss\n",
            "I0605 10:39:53.032099 18143 net.cpp:406] loss <- ip1_ip1_0_split_1\n",
            "I0605 10:39:53.032110 18143 net.cpp:406] loss <- label_data_1_split_1\n",
            "I0605 10:39:53.032122 18143 net.cpp:380] loss -> loss\n",
            "I0605 10:39:53.032137 18143 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:39:53.032156 18143 net.cpp:122] Setting up loss\n",
            "I0605 10:39:53.032169 18143 net.cpp:129] Top shape: (1)\n",
            "I0605 10:39:53.032181 18143 net.cpp:132]     with loss weight 1\n",
            "I0605 10:39:53.032204 18143 net.cpp:137] Memory required for data: 26432408\n",
            "I0605 10:39:53.032215 18143 net.cpp:198] loss needs backward computation.\n",
            "I0605 10:39:53.032230 18143 net.cpp:200] accuracy does not need backward computation.\n",
            "I0605 10:39:53.032243 18143 net.cpp:198] ip1_ip1_0_split needs backward computation.\n",
            "I0605 10:39:53.032253 18143 net.cpp:198] ip1 needs backward computation.\n",
            "I0605 10:39:53.032263 18143 net.cpp:198] pool3 needs backward computation.\n",
            "I0605 10:39:53.032274 18143 net.cpp:198] relu3 needs backward computation.\n",
            "I0605 10:39:53.032284 18143 net.cpp:198] conv3 needs backward computation.\n",
            "I0605 10:39:53.032305 18143 net.cpp:198] pool2 needs backward computation.\n",
            "I0605 10:39:53.032315 18143 net.cpp:198] relu2 needs backward computation.\n",
            "I0605 10:39:53.032325 18143 net.cpp:198] conv2 needs backward computation.\n",
            "I0605 10:39:53.032335 18143 net.cpp:198] relu1 needs backward computation.\n",
            "I0605 10:39:53.032346 18143 net.cpp:198] pool1 needs backward computation.\n",
            "I0605 10:39:53.032356 18143 net.cpp:198] conv1 needs backward computation.\n",
            "I0605 10:39:53.032368 18143 net.cpp:200] label_data_1_split does not need backward computation.\n",
            "I0605 10:39:53.032392 18143 net.cpp:200] data does not need backward computation.\n",
            "I0605 10:39:53.032404 18143 net.cpp:242] This network produces output accuracy\n",
            "I0605 10:39:53.032421 18143 net.cpp:242] This network produces output loss\n",
            "I0605 10:39:53.032439 18143 net.cpp:255] Network initialization done.\n",
            "I0605 10:39:53.042660 18143 hdf5.cpp:32] Datatype class: H5T_FLOAT\n",
            "['', 'conv1', 'pool1', 'relu2', 'conv3', 'relu3', 'ip1', 'accuracy']\n",
            "['data', 'conv1', 'conv2', 'pool2', 'conv3', 'pool3', 'ip1', 'accuracy']\n",
            "W0605 10:39:53.060288 18143 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface\n",
            "W0605 10:39:53.060323 18143 _caffe.cpp:140] Use this instead (with the named \"weights\" parameter):\n",
            "W0605 10:39:53.060329 18143 _caffe.cpp:142] Net('examples/cifar10/cifar10_m4_train_test_small.prototxt', 1, weights='examples/cifar10/cifar10_small_iter_5000.caffemodel.h5')\n",
            "I0605 10:39:53.060519 18143 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\n",
            "I0605 10:39:53.060667 18143 net.cpp:51] Initializing net from parameters: \n",
            "name: \"CIFAR10_small\"\n",
            "state {\n",
            "  phase: TEST\n",
            "  level: 0\n",
            "}\n",
            "layer {\n",
            "  name: \"data\"\n",
            "  type: \"Data\"\n",
            "  top: \"data\"\n",
            "  top: \"label\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "  transform_param {\n",
            "    mean_file: \"examples/cifar10/mean.binaryproto\"\n",
            "  }\n",
            "  data_param {\n",
            "    source: \"examples/cifar10/cifar10_test_lmdb\"\n",
            "    batch_size: 100\n",
            "    backend: LMDB\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.0001\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu1\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"pool1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv2\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"conv2\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 16\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu2\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"conv2\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool2\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"pool2\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv3\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool2\"\n",
            "  top: \"conv3\"\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu3\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv3\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool3\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"pool3\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"ip1\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"pool3\"\n",
            "  top: \"ip1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 250\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 10\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"accuracy\"\n",
            "  type: \"Accuracy\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"accuracy\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"loss\"\n",
            "  type: \"SoftmaxWithLoss\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"loss\"\n",
            "}\n",
            "I0605 10:39:53.215260 18143 layer_factory.hpp:77] Creating layer data\n",
            "I0605 10:39:53.215386 18143 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb\n",
            "I0605 10:39:53.215425 18143 net.cpp:84] Creating Layer data\n",
            "I0605 10:39:53.215447 18143 net.cpp:380] data -> data\n",
            "I0605 10:39:53.215472 18143 net.cpp:380] data -> label\n",
            "I0605 10:39:53.215500 18143 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto\n",
            "I0605 10:39:53.225550 18143 data_layer.cpp:45] output data size: 100,3,32,32\n",
            "I0605 10:39:53.230340 18143 net.cpp:122] Setting up data\n",
            "I0605 10:39:53.230370 18143 net.cpp:129] Top shape: 100 3 32 32 (307200)\n",
            "I0605 10:39:53.230388 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:39:53.230402 18143 net.cpp:137] Memory required for data: 1229200\n",
            "I0605 10:39:53.230418 18143 layer_factory.hpp:77] Creating layer label_data_1_split\n",
            "I0605 10:39:53.230437 18143 net.cpp:84] Creating Layer label_data_1_split\n",
            "I0605 10:39:53.230453 18143 net.cpp:406] label_data_1_split <- label\n",
            "I0605 10:39:53.230470 18143 net.cpp:380] label_data_1_split -> label_data_1_split_0\n",
            "I0605 10:39:53.230507 18143 net.cpp:380] label_data_1_split -> label_data_1_split_1\n",
            "I0605 10:39:53.230690 18143 net.cpp:122] Setting up label_data_1_split\n",
            "I0605 10:39:53.230715 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:39:53.230731 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:39:53.230742 18143 net.cpp:137] Memory required for data: 1230000\n",
            "I0605 10:39:53.230756 18143 layer_factory.hpp:77] Creating layer conv1\n",
            "I0605 10:39:53.230770 18143 net.cpp:84] Creating Layer conv1\n",
            "I0605 10:39:53.230778 18143 net.cpp:406] conv1 <- data\n",
            "I0605 10:39:53.230796 18143 net.cpp:380] conv1 -> conv1\n",
            "I0605 10:39:53.231074 18143 net.cpp:122] Setting up conv1\n",
            "I0605 10:39:53.231101 18143 net.cpp:129] Top shape: 100 32 32 32 (3276800)\n",
            "I0605 10:39:53.231110 18143 net.cpp:137] Memory required for data: 14337200\n",
            "I0605 10:39:53.231123 18143 layer_factory.hpp:77] Creating layer pool1\n",
            "I0605 10:39:53.231135 18143 net.cpp:84] Creating Layer pool1\n",
            "I0605 10:39:53.231143 18143 net.cpp:406] pool1 <- conv1\n",
            "I0605 10:39:53.231151 18143 net.cpp:380] pool1 -> pool1\n",
            "I0605 10:39:53.231194 18143 net.cpp:122] Setting up pool1\n",
            "I0605 10:39:53.231216 18143 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:39:53.231231 18143 net.cpp:137] Memory required for data: 17614000\n",
            "I0605 10:39:53.231245 18143 layer_factory.hpp:77] Creating layer relu1\n",
            "I0605 10:39:53.231259 18143 net.cpp:84] Creating Layer relu1\n",
            "I0605 10:39:53.231271 18143 net.cpp:406] relu1 <- pool1\n",
            "I0605 10:39:53.231284 18143 net.cpp:367] relu1 -> pool1 (in-place)\n",
            "I0605 10:39:53.231299 18143 net.cpp:122] Setting up relu1\n",
            "I0605 10:39:53.231315 18143 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:39:53.231328 18143 net.cpp:137] Memory required for data: 20890800\n",
            "I0605 10:39:53.231340 18143 layer_factory.hpp:77] Creating layer conv2\n",
            "I0605 10:39:53.231361 18143 net.cpp:84] Creating Layer conv2\n",
            "I0605 10:39:53.231375 18143 net.cpp:406] conv2 <- pool1\n",
            "I0605 10:39:53.231391 18143 net.cpp:380] conv2 -> conv2\n",
            "I0605 10:39:53.232122 18143 net.cpp:122] Setting up conv2\n",
            "I0605 10:39:53.232156 18143 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:39:53.232172 18143 net.cpp:137] Memory required for data: 22529200\n",
            "I0605 10:39:53.232221 18143 layer_factory.hpp:77] Creating layer relu2\n",
            "I0605 10:39:53.232239 18143 net.cpp:84] Creating Layer relu2\n",
            "I0605 10:39:53.232270 18143 net.cpp:406] relu2 <- conv2\n",
            "I0605 10:39:53.232301 18143 net.cpp:367] relu2 -> conv2 (in-place)\n",
            "I0605 10:39:53.232318 18143 net.cpp:122] Setting up relu2\n",
            "I0605 10:39:53.232336 18143 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:39:53.232348 18143 net.cpp:137] Memory required for data: 24167600\n",
            "I0605 10:39:53.232363 18143 layer_factory.hpp:77] Creating layer pool2\n",
            "I0605 10:39:53.232378 18143 net.cpp:84] Creating Layer pool2\n",
            "I0605 10:39:53.232406 18143 net.cpp:406] pool2 <- conv2\n",
            "I0605 10:39:53.232422 18143 net.cpp:380] pool2 -> pool2\n",
            "I0605 10:39:53.232455 18143 net.cpp:122] Setting up pool2\n",
            "I0605 10:39:53.232508 18143 net.cpp:129] Top shape: 100 16 8 8 (102400)\n",
            "I0605 10:39:53.232522 18143 net.cpp:137] Memory required for data: 24577200\n",
            "I0605 10:39:53.232543 18143 layer_factory.hpp:77] Creating layer conv3\n",
            "I0605 10:39:53.232563 18143 net.cpp:84] Creating Layer conv3\n",
            "I0605 10:39:53.232607 18143 net.cpp:406] conv3 <- pool2\n",
            "I0605 10:39:53.232630 18143 net.cpp:380] conv3 -> conv3\n",
            "I0605 10:39:53.233106 18143 net.cpp:122] Setting up conv3\n",
            "I0605 10:39:53.233131 18143 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:39:53.233146 18143 net.cpp:137] Memory required for data: 25396400\n",
            "I0605 10:39:53.233165 18143 layer_factory.hpp:77] Creating layer relu3\n",
            "I0605 10:39:53.233183 18143 net.cpp:84] Creating Layer relu3\n",
            "I0605 10:39:53.233197 18143 net.cpp:406] relu3 <- conv3\n",
            "I0605 10:39:53.233217 18143 net.cpp:367] relu3 -> conv3 (in-place)\n",
            "I0605 10:39:53.233232 18143 net.cpp:122] Setting up relu3\n",
            "I0605 10:39:53.233248 18143 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:39:53.233263 18143 net.cpp:137] Memory required for data: 26215600\n",
            "I0605 10:39:53.233274 18143 layer_factory.hpp:77] Creating layer pool3\n",
            "I0605 10:39:53.233290 18143 net.cpp:84] Creating Layer pool3\n",
            "I0605 10:39:53.233302 18143 net.cpp:406] pool3 <- conv3\n",
            "I0605 10:39:53.233316 18143 net.cpp:380] pool3 -> pool3\n",
            "I0605 10:39:53.233357 18143 net.cpp:122] Setting up pool3\n",
            "I0605 10:39:53.233377 18143 net.cpp:129] Top shape: 100 32 4 4 (51200)\n",
            "I0605 10:39:53.233392 18143 net.cpp:137] Memory required for data: 26420400\n",
            "I0605 10:39:53.233403 18143 layer_factory.hpp:77] Creating layer ip1\n",
            "I0605 10:39:53.233419 18143 net.cpp:84] Creating Layer ip1\n",
            "I0605 10:39:53.233434 18143 net.cpp:406] ip1 <- pool3\n",
            "I0605 10:39:53.233449 18143 net.cpp:380] ip1 -> ip1\n",
            "I0605 10:39:53.233853 18143 net.cpp:122] Setting up ip1\n",
            "I0605 10:39:53.233880 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:39:53.233894 18143 net.cpp:137] Memory required for data: 26424400\n",
            "I0605 10:39:53.233912 18143 layer_factory.hpp:77] Creating layer ip1_ip1_0_split\n",
            "I0605 10:39:53.233930 18143 net.cpp:84] Creating Layer ip1_ip1_0_split\n",
            "I0605 10:39:53.233944 18143 net.cpp:406] ip1_ip1_0_split <- ip1\n",
            "I0605 10:39:53.233960 18143 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0\n",
            "I0605 10:39:53.233978 18143 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1\n",
            "I0605 10:39:53.234026 18143 net.cpp:122] Setting up ip1_ip1_0_split\n",
            "I0605 10:39:53.234071 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:39:53.234087 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:39:53.234099 18143 net.cpp:137] Memory required for data: 26432400\n",
            "I0605 10:39:53.234113 18143 layer_factory.hpp:77] Creating layer accuracy\n",
            "I0605 10:39:53.234131 18143 net.cpp:84] Creating Layer accuracy\n",
            "I0605 10:39:53.234145 18143 net.cpp:406] accuracy <- ip1_ip1_0_split_0\n",
            "I0605 10:39:53.234160 18143 net.cpp:406] accuracy <- label_data_1_split_0\n",
            "I0605 10:39:53.234194 18143 net.cpp:380] accuracy -> accuracy\n",
            "I0605 10:39:53.234215 18143 net.cpp:122] Setting up accuracy\n",
            "I0605 10:39:53.234232 18143 net.cpp:129] Top shape: (1)\n",
            "I0605 10:39:53.234247 18143 net.cpp:137] Memory required for data: 26432404\n",
            "I0605 10:39:53.234261 18143 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:39:53.234277 18143 net.cpp:84] Creating Layer loss\n",
            "I0605 10:39:53.234297 18143 net.cpp:406] loss <- ip1_ip1_0_split_1\n",
            "I0605 10:39:53.234310 18143 net.cpp:406] loss <- label_data_1_split_1\n",
            "I0605 10:39:53.234328 18143 net.cpp:380] loss -> loss\n",
            "I0605 10:39:53.234352 18143 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:39:53.234473 18143 net.cpp:122] Setting up loss\n",
            "I0605 10:39:53.234493 18143 net.cpp:129] Top shape: (1)\n",
            "I0605 10:39:53.234508 18143 net.cpp:132]     with loss weight 1\n",
            "I0605 10:39:53.234530 18143 net.cpp:137] Memory required for data: 26432408\n",
            "I0605 10:39:53.234545 18143 net.cpp:198] loss needs backward computation.\n",
            "I0605 10:39:53.234561 18143 net.cpp:200] accuracy does not need backward computation.\n",
            "I0605 10:39:53.234608 18143 net.cpp:198] ip1_ip1_0_split needs backward computation.\n",
            "I0605 10:39:53.234627 18143 net.cpp:198] ip1 needs backward computation.\n",
            "I0605 10:39:53.234640 18143 net.cpp:198] pool3 needs backward computation.\n",
            "I0605 10:39:53.234654 18143 net.cpp:198] relu3 needs backward computation.\n",
            "I0605 10:39:53.234707 18143 net.cpp:198] conv3 needs backward computation.\n",
            "I0605 10:39:53.234722 18143 net.cpp:198] pool2 needs backward computation.\n",
            "I0605 10:39:53.234743 18143 net.cpp:198] relu2 needs backward computation.\n",
            "I0605 10:39:53.234772 18143 net.cpp:198] conv2 needs backward computation.\n",
            "I0605 10:39:53.234800 18143 net.cpp:198] relu1 needs backward computation.\n",
            "I0605 10:39:53.234814 18143 net.cpp:198] pool1 needs backward computation.\n",
            "I0605 10:39:53.234828 18143 net.cpp:198] conv1 needs backward computation.\n",
            "I0605 10:39:53.234843 18143 net.cpp:200] label_data_1_split does not need backward computation.\n",
            "I0605 10:39:53.234858 18143 net.cpp:200] data does not need backward computation.\n",
            "I0605 10:39:53.234872 18143 net.cpp:242] This network produces output accuracy\n",
            "I0605 10:39:53.234887 18143 net.cpp:242] This network produces output loss\n",
            "I0605 10:39:53.234916 18143 net.cpp:255] Network initialization done.\n",
            "I0605 10:39:55.516259 18154 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Full precision accuracy: 68.74%\n",
            "W0605 10:39:55.609340 18143 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface\n",
            "W0605 10:39:55.609372 18143 _caffe.cpp:140] Use this instead (with the named \"weights\" parameter):\n",
            "W0605 10:39:55.609380 18143 _caffe.cpp:142] Net('examples/cifar10/cifar10_m4_train_test_small.prototxt', 1, weights='examples/cifar10/cifar10_small_iter_5000.caffemodel.h5')\n",
            "I0605 10:39:55.609623 18143 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\n",
            "I0605 10:39:55.609740 18143 net.cpp:51] Initializing net from parameters: \n",
            "name: \"CIFAR10_small\"\n",
            "state {\n",
            "  phase: TEST\n",
            "  level: 0\n",
            "}\n",
            "layer {\n",
            "  name: \"data\"\n",
            "  type: \"Data\"\n",
            "  top: \"data\"\n",
            "  top: \"label\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "  transform_param {\n",
            "    mean_file: \"examples/cifar10/mean.binaryproto\"\n",
            "  }\n",
            "  data_param {\n",
            "    source: \"examples/cifar10/cifar10_test_lmdb\"\n",
            "    batch_size: 100\n",
            "    backend: LMDB\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.0001\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu1\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"pool1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv2\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"conv2\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 16\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu2\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"conv2\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool2\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"pool2\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv3\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool2\"\n",
            "  top: \"conv3\"\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu3\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv3\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool3\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"pool3\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"ip1\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"pool3\"\n",
            "  top: \"ip1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 250\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 10\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"accuracy\"\n",
            "  type: \"Accuracy\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"accuracy\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"loss\"\n",
            "  type: \"SoftmaxWithLoss\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"loss\"\n",
            "}\n",
            "I0605 10:39:55.609823 18143 layer_factory.hpp:77] Creating layer data\n",
            "I0605 10:39:55.609926 18143 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb\n",
            "I0605 10:39:55.609954 18143 net.cpp:84] Creating Layer data\n",
            "I0605 10:39:55.609966 18143 net.cpp:380] data -> data\n",
            "I0605 10:39:55.609982 18143 net.cpp:380] data -> label\n",
            "I0605 10:39:55.609997 18143 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto\n",
            "I0605 10:39:55.610940 18143 data_layer.cpp:45] output data size: 100,3,32,32\n",
            "I0605 10:39:55.615164 18143 net.cpp:122] Setting up data\n",
            "I0605 10:39:55.615187 18143 net.cpp:129] Top shape: 100 3 32 32 (307200)\n",
            "I0605 10:39:55.615203 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:39:55.615228 18143 net.cpp:137] Memory required for data: 1229200\n",
            "I0605 10:39:55.615238 18143 layer_factory.hpp:77] Creating layer label_data_1_split\n",
            "I0605 10:39:55.615270 18143 net.cpp:84] Creating Layer label_data_1_split\n",
            "I0605 10:39:55.615283 18143 net.cpp:406] label_data_1_split <- label\n",
            "I0605 10:39:55.615295 18143 net.cpp:380] label_data_1_split -> label_data_1_split_0\n",
            "I0605 10:39:55.615310 18143 net.cpp:380] label_data_1_split -> label_data_1_split_1\n",
            "I0605 10:39:55.615381 18143 net.cpp:122] Setting up label_data_1_split\n",
            "I0605 10:39:55.615398 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:39:55.615411 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:39:55.615422 18143 net.cpp:137] Memory required for data: 1230000\n",
            "I0605 10:39:55.615430 18143 layer_factory.hpp:77] Creating layer conv1\n",
            "I0605 10:39:55.615466 18143 net.cpp:84] Creating Layer conv1\n",
            "I0605 10:39:55.615479 18143 net.cpp:406] conv1 <- data\n",
            "I0605 10:39:55.615492 18143 net.cpp:380] conv1 -> conv1\n",
            "I0605 10:39:55.615805 18143 net.cpp:122] Setting up conv1\n",
            "I0605 10:39:55.615830 18143 net.cpp:129] Top shape: 100 32 32 32 (3276800)\n",
            "I0605 10:39:55.615837 18143 net.cpp:137] Memory required for data: 14337200\n",
            "I0605 10:39:55.615859 18143 layer_factory.hpp:77] Creating layer pool1\n",
            "I0605 10:39:55.615869 18143 net.cpp:84] Creating Layer pool1\n",
            "I0605 10:39:55.615873 18143 net.cpp:406] pool1 <- conv1\n",
            "I0605 10:39:55.615880 18143 net.cpp:380] pool1 -> pool1\n",
            "I0605 10:39:55.615916 18143 net.cpp:122] Setting up pool1\n",
            "I0605 10:39:55.615926 18143 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:39:55.615931 18143 net.cpp:137] Memory required for data: 17614000\n",
            "I0605 10:39:55.615936 18143 layer_factory.hpp:77] Creating layer relu1\n",
            "I0605 10:39:55.615943 18143 net.cpp:84] Creating Layer relu1\n",
            "I0605 10:39:55.615949 18143 net.cpp:406] relu1 <- pool1\n",
            "I0605 10:39:55.615954 18143 net.cpp:367] relu1 -> pool1 (in-place)\n",
            "I0605 10:39:55.615962 18143 net.cpp:122] Setting up relu1\n",
            "I0605 10:39:55.615967 18143 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:39:55.615972 18143 net.cpp:137] Memory required for data: 20890800\n",
            "I0605 10:39:55.615976 18143 layer_factory.hpp:77] Creating layer conv2\n",
            "I0605 10:39:55.615993 18143 net.cpp:84] Creating Layer conv2\n",
            "I0605 10:39:55.616004 18143 net.cpp:406] conv2 <- pool1\n",
            "I0605 10:39:55.616017 18143 net.cpp:380] conv2 -> conv2\n",
            "I0605 10:39:55.616556 18143 net.cpp:122] Setting up conv2\n",
            "I0605 10:39:55.616605 18143 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:39:55.616621 18143 net.cpp:137] Memory required for data: 22529200\n",
            "I0605 10:39:55.616636 18143 layer_factory.hpp:77] Creating layer relu2\n",
            "I0605 10:39:55.616650 18143 net.cpp:84] Creating Layer relu2\n",
            "I0605 10:39:55.616662 18143 net.cpp:406] relu2 <- conv2\n",
            "I0605 10:39:55.616674 18143 net.cpp:367] relu2 -> conv2 (in-place)\n",
            "I0605 10:39:55.616688 18143 net.cpp:122] Setting up relu2\n",
            "I0605 10:39:55.616703 18143 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:39:55.616713 18143 net.cpp:137] Memory required for data: 24167600\n",
            "I0605 10:39:55.616722 18143 layer_factory.hpp:77] Creating layer pool2\n",
            "I0605 10:39:55.616734 18143 net.cpp:84] Creating Layer pool2\n",
            "I0605 10:39:55.616745 18143 net.cpp:406] pool2 <- conv2\n",
            "I0605 10:39:55.616756 18143 net.cpp:380] pool2 -> pool2\n",
            "I0605 10:39:55.616786 18143 net.cpp:122] Setting up pool2\n",
            "I0605 10:39:55.616801 18143 net.cpp:129] Top shape: 100 16 8 8 (102400)\n",
            "I0605 10:39:55.616812 18143 net.cpp:137] Memory required for data: 24577200\n",
            "I0605 10:39:55.616822 18143 layer_factory.hpp:77] Creating layer conv3\n",
            "I0605 10:39:55.616845 18143 net.cpp:84] Creating Layer conv3\n",
            "I0605 10:39:55.616858 18143 net.cpp:406] conv3 <- pool2\n",
            "I0605 10:39:55.616871 18143 net.cpp:380] conv3 -> conv3\n",
            "I0605 10:39:55.617302 18143 net.cpp:122] Setting up conv3\n",
            "I0605 10:39:55.617323 18143 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:39:55.617336 18143 net.cpp:137] Memory required for data: 25396400\n",
            "I0605 10:39:55.617348 18143 layer_factory.hpp:77] Creating layer relu3\n",
            "I0605 10:39:55.617362 18143 net.cpp:84] Creating Layer relu3\n",
            "I0605 10:39:55.617373 18143 net.cpp:406] relu3 <- conv3\n",
            "I0605 10:39:55.617384 18143 net.cpp:367] relu3 -> conv3 (in-place)\n",
            "I0605 10:39:55.617398 18143 net.cpp:122] Setting up relu3\n",
            "I0605 10:39:55.617409 18143 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:39:55.617419 18143 net.cpp:137] Memory required for data: 26215600\n",
            "I0605 10:39:55.617429 18143 layer_factory.hpp:77] Creating layer pool3\n",
            "I0605 10:39:55.617442 18143 net.cpp:84] Creating Layer pool3\n",
            "I0605 10:39:55.617452 18143 net.cpp:406] pool3 <- conv3\n",
            "I0605 10:39:55.617463 18143 net.cpp:380] pool3 -> pool3\n",
            "I0605 10:39:55.617501 18143 net.cpp:122] Setting up pool3\n",
            "I0605 10:39:55.617518 18143 net.cpp:129] Top shape: 100 32 4 4 (51200)\n",
            "I0605 10:39:55.617528 18143 net.cpp:137] Memory required for data: 26420400\n",
            "I0605 10:39:55.617538 18143 layer_factory.hpp:77] Creating layer ip1\n",
            "I0605 10:39:55.617553 18143 net.cpp:84] Creating Layer ip1\n",
            "I0605 10:39:55.617565 18143 net.cpp:406] ip1 <- pool3\n",
            "I0605 10:39:55.617578 18143 net.cpp:380] ip1 -> ip1\n",
            "I0605 10:39:55.617781 18143 net.cpp:122] Setting up ip1\n",
            "I0605 10:39:55.617800 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:39:55.617810 18143 net.cpp:137] Memory required for data: 26424400\n",
            "I0605 10:39:55.617823 18143 layer_factory.hpp:77] Creating layer ip1_ip1_0_split\n",
            "I0605 10:39:55.617836 18143 net.cpp:84] Creating Layer ip1_ip1_0_split\n",
            "I0605 10:39:55.617856 18143 net.cpp:406] ip1_ip1_0_split <- ip1\n",
            "I0605 10:39:55.617869 18143 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0\n",
            "I0605 10:39:55.617882 18143 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1\n",
            "I0605 10:39:55.617956 18143 net.cpp:122] Setting up ip1_ip1_0_split\n",
            "I0605 10:39:55.617970 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:39:55.617996 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:39:55.618006 18143 net.cpp:137] Memory required for data: 26432400\n",
            "I0605 10:39:55.618016 18143 layer_factory.hpp:77] Creating layer accuracy\n",
            "I0605 10:39:55.618029 18143 net.cpp:84] Creating Layer accuracy\n",
            "I0605 10:39:55.618041 18143 net.cpp:406] accuracy <- ip1_ip1_0_split_0\n",
            "I0605 10:39:55.618052 18143 net.cpp:406] accuracy <- label_data_1_split_0\n",
            "I0605 10:39:55.618062 18143 net.cpp:380] accuracy -> accuracy\n",
            "I0605 10:39:55.618077 18143 net.cpp:122] Setting up accuracy\n",
            "I0605 10:39:55.618088 18143 net.cpp:129] Top shape: (1)\n",
            "I0605 10:39:55.618098 18143 net.cpp:137] Memory required for data: 26432404\n",
            "I0605 10:39:55.618105 18143 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:39:55.618116 18143 net.cpp:84] Creating Layer loss\n",
            "I0605 10:39:55.618141 18143 net.cpp:406] loss <- ip1_ip1_0_split_1\n",
            "I0605 10:39:55.618150 18143 net.cpp:406] loss <- label_data_1_split_1\n",
            "I0605 10:39:55.618176 18143 net.cpp:380] loss -> loss\n",
            "I0605 10:39:55.618191 18143 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:39:55.618309 18143 net.cpp:122] Setting up loss\n",
            "I0605 10:39:55.618327 18143 net.cpp:129] Top shape: (1)\n",
            "I0605 10:39:55.618337 18143 net.cpp:132]     with loss weight 1\n",
            "I0605 10:39:55.618355 18143 net.cpp:137] Memory required for data: 26432408\n",
            "I0605 10:39:55.618366 18143 net.cpp:198] loss needs backward computation.\n",
            "I0605 10:39:55.618377 18143 net.cpp:200] accuracy does not need backward computation.\n",
            "I0605 10:39:55.618391 18143 net.cpp:198] ip1_ip1_0_split needs backward computation.\n",
            "I0605 10:39:55.618408 18143 net.cpp:198] ip1 needs backward computation.\n",
            "I0605 10:39:55.618420 18143 net.cpp:198] pool3 needs backward computation.\n",
            "I0605 10:39:55.618430 18143 net.cpp:198] relu3 needs backward computation.\n",
            "I0605 10:39:55.618440 18143 net.cpp:198] conv3 needs backward computation.\n",
            "I0605 10:39:55.618451 18143 net.cpp:198] pool2 needs backward computation.\n",
            "I0605 10:39:55.618461 18143 net.cpp:198] relu2 needs backward computation.\n",
            "I0605 10:39:55.618474 18143 net.cpp:198] conv2 needs backward computation.\n",
            "I0605 10:39:55.618484 18143 net.cpp:198] relu1 needs backward computation.\n",
            "I0605 10:39:55.618494 18143 net.cpp:198] pool1 needs backward computation.\n",
            "I0605 10:39:55.618505 18143 net.cpp:198] conv1 needs backward computation.\n",
            "I0605 10:39:55.618516 18143 net.cpp:200] label_data_1_split does not need backward computation.\n",
            "I0605 10:39:55.618527 18143 net.cpp:200] data does not need backward computation.\n",
            "I0605 10:39:55.618537 18143 net.cpp:242] This network produces output accuracy\n",
            "I0605 10:39:55.618548 18143 net.cpp:242] This network produces output loss\n",
            "I0605 10:39:55.618571 18143 net.cpp:255] Network initialization done.\n",
            "I0605 10:39:57.757900 18155 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Full precision accuracy: 68.74%\n",
            "Layer: conv1 weights max: 0.17743845 min: -0.27587354 Format: Q-1.8\n",
            "I0605 10:39:59.976969 18155 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Accuracy: 68.91%\n",
            "Final conv1 weights format Q-1.8 Accuracy: 68.91%\n",
            "Layer: conv2 weights max: 0.116181515 min: -0.13148828 Format: Q-2.9\n",
            "I0605 10:40:02.198225 18155 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Accuracy: 68.95%\n",
            "Final conv2 weights format Q-2.9 Accuracy: 68.95%\n",
            "Layer: conv3 weights max: 0.11048868 min: -0.13098657 Format: Q-2.9\n",
            "I0605 10:40:04.415501 18155 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Accuracy: 68.86%\n",
            "Final conv3 weights format Q-2.9 Accuracy: 68.86%\n",
            "Layer: ip1 weights max: 0.033395994 min: -0.01806195 Format: Q-4.11\n",
            "I0605 10:40:06.632151 18155 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Accuracy: 68.84%\n",
            "Final ip1 weights format Q-4.11 Accuracy: 68.84%\n",
            "W0605 10:40:06.727424 18143 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface\n",
            "W0605 10:40:06.727459 18143 _caffe.cpp:140] Use this instead (with the named \"weights\" parameter):\n",
            "W0605 10:40:06.727466 18143 _caffe.cpp:142] Net('examples/cifar10/cifar10_m4_train_test_small.prototxt', 1, weights='examples/cifar10/quantized_cifar10_small_iter_5000.caffemodel')\n",
            "I0605 10:40:06.727697 18143 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\n",
            "I0605 10:40:06.727844 18143 net.cpp:51] Initializing net from parameters: \n",
            "name: \"CIFAR10_small\"\n",
            "state {\n",
            "  phase: TEST\n",
            "  level: 0\n",
            "}\n",
            "layer {\n",
            "  name: \"data\"\n",
            "  type: \"Data\"\n",
            "  top: \"data\"\n",
            "  top: \"label\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "  transform_param {\n",
            "    mean_file: \"examples/cifar10/mean.binaryproto\"\n",
            "  }\n",
            "  data_param {\n",
            "    source: \"examples/cifar10/cifar10_test_lmdb\"\n",
            "    batch_size: 100\n",
            "    backend: LMDB\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.0001\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu1\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"pool1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv2\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"conv2\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 16\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu2\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"conv2\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool2\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"pool2\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv3\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool2\"\n",
            "  top: \"conv3\"\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu3\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv3\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool3\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"pool3\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"ip1\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"pool3\"\n",
            "  top: \"ip1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 250\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 10\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"accuracy\"\n",
            "  type: \"Accuracy\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"accuracy\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"loss\"\n",
            "  type: \"SoftmaxWithLoss\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"loss\"\n",
            "}\n",
            "I0605 10:40:06.727950 18143 layer_factory.hpp:77] Creating layer data\n",
            "I0605 10:40:06.728049 18143 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb\n",
            "I0605 10:40:06.728076 18143 net.cpp:84] Creating Layer data\n",
            "I0605 10:40:06.728087 18143 net.cpp:380] data -> data\n",
            "I0605 10:40:06.728104 18143 net.cpp:380] data -> label\n",
            "I0605 10:40:06.728119 18143 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto\n",
            "I0605 10:40:06.728924 18143 data_layer.cpp:45] output data size: 100,3,32,32\n",
            "I0605 10:40:06.733399 18143 net.cpp:122] Setting up data\n",
            "I0605 10:40:06.733423 18143 net.cpp:129] Top shape: 100 3 32 32 (307200)\n",
            "I0605 10:40:06.733440 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:40:06.733450 18143 net.cpp:137] Memory required for data: 1229200\n",
            "I0605 10:40:06.733460 18143 layer_factory.hpp:77] Creating layer label_data_1_split\n",
            "I0605 10:40:06.733476 18143 net.cpp:84] Creating Layer label_data_1_split\n",
            "I0605 10:40:06.733489 18143 net.cpp:406] label_data_1_split <- label\n",
            "I0605 10:40:06.733516 18143 net.cpp:380] label_data_1_split -> label_data_1_split_0\n",
            "I0605 10:40:06.733531 18143 net.cpp:380] label_data_1_split -> label_data_1_split_1\n",
            "I0605 10:40:06.733639 18143 net.cpp:122] Setting up label_data_1_split\n",
            "I0605 10:40:06.733673 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:40:06.733685 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:40:06.733695 18143 net.cpp:137] Memory required for data: 1230000\n",
            "I0605 10:40:06.733705 18143 layer_factory.hpp:77] Creating layer conv1\n",
            "I0605 10:40:06.733719 18143 net.cpp:84] Creating Layer conv1\n",
            "I0605 10:40:06.733731 18143 net.cpp:406] conv1 <- data\n",
            "I0605 10:40:06.733743 18143 net.cpp:380] conv1 -> conv1\n",
            "I0605 10:40:06.734058 18143 net.cpp:122] Setting up conv1\n",
            "I0605 10:40:06.734082 18143 net.cpp:129] Top shape: 100 32 32 32 (3276800)\n",
            "I0605 10:40:06.734089 18143 net.cpp:137] Memory required for data: 14337200\n",
            "I0605 10:40:06.734100 18143 layer_factory.hpp:77] Creating layer pool1\n",
            "I0605 10:40:06.734110 18143 net.cpp:84] Creating Layer pool1\n",
            "I0605 10:40:06.734115 18143 net.cpp:406] pool1 <- conv1\n",
            "I0605 10:40:06.734122 18143 net.cpp:380] pool1 -> pool1\n",
            "I0605 10:40:06.734158 18143 net.cpp:122] Setting up pool1\n",
            "I0605 10:40:06.734169 18143 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:40:06.734174 18143 net.cpp:137] Memory required for data: 17614000\n",
            "I0605 10:40:06.734179 18143 layer_factory.hpp:77] Creating layer relu1\n",
            "I0605 10:40:06.734186 18143 net.cpp:84] Creating Layer relu1\n",
            "I0605 10:40:06.734192 18143 net.cpp:406] relu1 <- pool1\n",
            "I0605 10:40:06.734199 18143 net.cpp:367] relu1 -> pool1 (in-place)\n",
            "I0605 10:40:06.734205 18143 net.cpp:122] Setting up relu1\n",
            "I0605 10:40:06.734211 18143 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:40:06.734216 18143 net.cpp:137] Memory required for data: 20890800\n",
            "I0605 10:40:06.734221 18143 layer_factory.hpp:77] Creating layer conv2\n",
            "I0605 10:40:06.734238 18143 net.cpp:84] Creating Layer conv2\n",
            "I0605 10:40:06.734249 18143 net.cpp:406] conv2 <- pool1\n",
            "I0605 10:40:06.734262 18143 net.cpp:380] conv2 -> conv2\n",
            "I0605 10:40:06.734899 18143 net.cpp:122] Setting up conv2\n",
            "I0605 10:40:06.734925 18143 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:40:06.734943 18143 net.cpp:137] Memory required for data: 22529200\n",
            "I0605 10:40:06.734959 18143 layer_factory.hpp:77] Creating layer relu2\n",
            "I0605 10:40:06.734974 18143 net.cpp:84] Creating Layer relu2\n",
            "I0605 10:40:06.734987 18143 net.cpp:406] relu2 <- conv2\n",
            "I0605 10:40:06.734999 18143 net.cpp:367] relu2 -> conv2 (in-place)\n",
            "I0605 10:40:06.735013 18143 net.cpp:122] Setting up relu2\n",
            "I0605 10:40:06.735025 18143 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:40:06.735035 18143 net.cpp:137] Memory required for data: 24167600\n",
            "I0605 10:40:06.735045 18143 layer_factory.hpp:77] Creating layer pool2\n",
            "I0605 10:40:06.735057 18143 net.cpp:84] Creating Layer pool2\n",
            "I0605 10:40:06.735069 18143 net.cpp:406] pool2 <- conv2\n",
            "I0605 10:40:06.735080 18143 net.cpp:380] pool2 -> pool2\n",
            "I0605 10:40:06.735111 18143 net.cpp:122] Setting up pool2\n",
            "I0605 10:40:06.735127 18143 net.cpp:129] Top shape: 100 16 8 8 (102400)\n",
            "I0605 10:40:06.735137 18143 net.cpp:137] Memory required for data: 24577200\n",
            "I0605 10:40:06.735147 18143 layer_factory.hpp:77] Creating layer conv3\n",
            "I0605 10:40:06.735163 18143 net.cpp:84] Creating Layer conv3\n",
            "I0605 10:40:06.735174 18143 net.cpp:406] conv3 <- pool2\n",
            "I0605 10:40:06.735186 18143 net.cpp:380] conv3 -> conv3\n",
            "I0605 10:40:06.735679 18143 net.cpp:122] Setting up conv3\n",
            "I0605 10:40:06.735714 18143 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:40:06.735726 18143 net.cpp:137] Memory required for data: 25396400\n",
            "I0605 10:40:06.735743 18143 layer_factory.hpp:77] Creating layer relu3\n",
            "I0605 10:40:06.735756 18143 net.cpp:84] Creating Layer relu3\n",
            "I0605 10:40:06.735766 18143 net.cpp:406] relu3 <- conv3\n",
            "I0605 10:40:06.735800 18143 net.cpp:367] relu3 -> conv3 (in-place)\n",
            "I0605 10:40:06.735812 18143 net.cpp:122] Setting up relu3\n",
            "I0605 10:40:06.735824 18143 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:40:06.735842 18143 net.cpp:137] Memory required for data: 26215600\n",
            "I0605 10:40:06.735854 18143 layer_factory.hpp:77] Creating layer pool3\n",
            "I0605 10:40:06.735867 18143 net.cpp:84] Creating Layer pool3\n",
            "I0605 10:40:06.735877 18143 net.cpp:406] pool3 <- conv3\n",
            "I0605 10:40:06.735889 18143 net.cpp:380] pool3 -> pool3\n",
            "I0605 10:40:06.735956 18143 net.cpp:122] Setting up pool3\n",
            "I0605 10:40:06.735975 18143 net.cpp:129] Top shape: 100 32 4 4 (51200)\n",
            "I0605 10:40:06.735985 18143 net.cpp:137] Memory required for data: 26420400\n",
            "I0605 10:40:06.735996 18143 layer_factory.hpp:77] Creating layer ip1\n",
            "I0605 10:40:06.736009 18143 net.cpp:84] Creating Layer ip1\n",
            "I0605 10:40:06.736021 18143 net.cpp:406] ip1 <- pool3\n",
            "I0605 10:40:06.736032 18143 net.cpp:380] ip1 -> ip1\n",
            "I0605 10:40:06.736269 18143 net.cpp:122] Setting up ip1\n",
            "I0605 10:40:06.736299 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:40:06.736307 18143 net.cpp:137] Memory required for data: 26424400\n",
            "I0605 10:40:06.736335 18143 layer_factory.hpp:77] Creating layer ip1_ip1_0_split\n",
            "I0605 10:40:06.736348 18143 net.cpp:84] Creating Layer ip1_ip1_0_split\n",
            "I0605 10:40:06.736374 18143 net.cpp:406] ip1_ip1_0_split <- ip1\n",
            "I0605 10:40:06.736385 18143 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0\n",
            "I0605 10:40:06.736397 18143 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1\n",
            "I0605 10:40:06.736495 18143 net.cpp:122] Setting up ip1_ip1_0_split\n",
            "I0605 10:40:06.736510 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:40:06.736523 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:40:06.736533 18143 net.cpp:137] Memory required for data: 26432400\n",
            "I0605 10:40:06.736543 18143 layer_factory.hpp:77] Creating layer accuracy\n",
            "I0605 10:40:06.736557 18143 net.cpp:84] Creating Layer accuracy\n",
            "I0605 10:40:06.736567 18143 net.cpp:406] accuracy <- ip1_ip1_0_split_0\n",
            "I0605 10:40:06.736577 18143 net.cpp:406] accuracy <- label_data_1_split_0\n",
            "I0605 10:40:06.736608 18143 net.cpp:380] accuracy -> accuracy\n",
            "I0605 10:40:06.736627 18143 net.cpp:122] Setting up accuracy\n",
            "I0605 10:40:06.736639 18143 net.cpp:129] Top shape: (1)\n",
            "I0605 10:40:06.736649 18143 net.cpp:137] Memory required for data: 26432404\n",
            "I0605 10:40:06.736660 18143 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:40:06.736672 18143 net.cpp:84] Creating Layer loss\n",
            "I0605 10:40:06.736683 18143 net.cpp:406] loss <- ip1_ip1_0_split_1\n",
            "I0605 10:40:06.736694 18143 net.cpp:406] loss <- label_data_1_split_1\n",
            "I0605 10:40:06.736706 18143 net.cpp:380] loss -> loss\n",
            "I0605 10:40:06.736732 18143 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:40:06.736848 18143 net.cpp:122] Setting up loss\n",
            "I0605 10:40:06.736865 18143 net.cpp:129] Top shape: (1)\n",
            "I0605 10:40:06.736877 18143 net.cpp:132]     with loss weight 1\n",
            "I0605 10:40:06.736896 18143 net.cpp:137] Memory required for data: 26432408\n",
            "I0605 10:40:06.736907 18143 net.cpp:198] loss needs backward computation.\n",
            "I0605 10:40:06.736919 18143 net.cpp:200] accuracy does not need backward computation.\n",
            "I0605 10:40:06.736932 18143 net.cpp:198] ip1_ip1_0_split needs backward computation.\n",
            "I0605 10:40:06.736943 18143 net.cpp:198] ip1 needs backward computation.\n",
            "I0605 10:40:06.736955 18143 net.cpp:198] pool3 needs backward computation.\n",
            "I0605 10:40:06.736965 18143 net.cpp:198] relu3 needs backward computation.\n",
            "I0605 10:40:06.736975 18143 net.cpp:198] conv3 needs backward computation.\n",
            "I0605 10:40:06.736986 18143 net.cpp:198] pool2 needs backward computation.\n",
            "I0605 10:40:06.736997 18143 net.cpp:198] relu2 needs backward computation.\n",
            "I0605 10:40:06.737007 18143 net.cpp:198] conv2 needs backward computation.\n",
            "I0605 10:40:06.737018 18143 net.cpp:198] relu1 needs backward computation.\n",
            "I0605 10:40:06.737028 18143 net.cpp:198] pool1 needs backward computation.\n",
            "I0605 10:40:06.737038 18143 net.cpp:198] conv1 needs backward computation.\n",
            "I0605 10:40:06.737051 18143 net.cpp:200] label_data_1_split does not need backward computation.\n",
            "I0605 10:40:06.737061 18143 net.cpp:200] data does not need backward computation.\n",
            "I0605 10:40:06.737073 18143 net.cpp:242] This network produces output accuracy\n",
            "I0605 10:40:06.737084 18143 net.cpp:242] This network produces output loss\n",
            "I0605 10:40:06.737107 18143 net.cpp:255] Network initialization done.\n",
            "I0605 10:40:08.871146 18159 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Accuracy with quantized weights: 68.84%\n",
            "I0605 10:40:11.666949 18159 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Layer: data max: 155.00494 min: -140.26881 Format: Q8.-1\n",
            "Layer: conv1 max: 467.47873 min: -453.62726 Format: Q9.-2\n",
            "Layer: conv2 max: 567.71533 min: -503.36627 Format: Q10.-3\n",
            "Layer: pool2 max: 488.556 min: 0.0 Format: Q9.-2\n",
            "Layer: conv3 max: 221.58858 min: -370.36026 Format: Q9.-2\n",
            "Layer: pool3 max: 162.81271 min: 0.0 Format: Q8.-1\n",
            "Layer: ip1 max: 15.891103 min: -11.120478 Format: Q4.3\n",
            "Layer: accuracy max: 0.76 min: 0.55 Format: Q0.7\n",
            "I0605 10:40:14.658804 18159 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Layer-data max: 154.0 min: -142.0 format: Q8.-1 accuracy: 68.63%\n",
            "I0605 10:40:17.715914 18159 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Layer-data max: 127.0min: -128.0 format: Q7.0 accuracy: 68.84%\n",
            "Layer-data final format: Q7.0 accuracy: 68.84%\n",
            "I0605 10:40:22.187247 18159 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Layer-conv1 max: 464.0 min: -456.0 format: Q9.-2 accuracy: 68.77%\n",
            "I0605 10:40:27.323608 18159 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Layer-conv1 max: 254.0min: -256.0 format: Q8.-1 accuracy: 68.90%\n",
            "Layer-conv1 final format: Q8.-1 accuracy: 68.90%\n",
            "I0605 10:40:32.429678 18159 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Layer-conv2 max: 565.6529 min: -512.0 format: Q10.-3 accuracy: 68.92%\n",
            "Layer-conv2 final format: Q10.-3 accuracy: 68.92%\n",
            "I0605 10:40:37.660725 18159 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Layer-conv3 max: 221.03755 min: -363.54083 format: Q9.-2 accuracy: 68.91%\n",
            "Layer-conv3 final format: Q9.-2 accuracy: 68.91%\n",
            "I0605 10:40:43.260798 18159 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Layer-ip1 max: 15.627361 min: -11.077917 format: Q4.3 accuracy: 67.36%\n",
            "I0605 10:40:49.543851 18159 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Layer-ip1 max: 7.9375min: -8.0 format: Q3.4 accuracy: 67.55%\n",
            "I0605 10:40:55.822580 18159 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Layer-ip1 max: 3.96875min: -4.0 format: Q2.5 accuracy: 58.53%\n",
            "I0605 10:41:02.193133 18159 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Layer-ip1 max: 1.984375min: -2.0 format: Q1.6 accuracy: 30.44%\n",
            "Layer-ip1 final format: Q3.4 accuracy: 67.55%\n",
            "W0605 10:41:02.458420 18143 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface\n",
            "W0605 10:41:02.458465 18143 _caffe.cpp:140] Use this instead (with the named \"weights\" parameter):\n",
            "W0605 10:41:02.458472 18143 _caffe.cpp:142] Net('examples/cifar10/cifar10_m4_train_test_small.prototxt', 1, weights='examples/cifar10/quantized_cifar10_small_iter_5000.caffemodel')\n",
            "I0605 10:41:02.458750 18143 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\n",
            "I0605 10:41:02.458873 18143 net.cpp:51] Initializing net from parameters: \n",
            "name: \"CIFAR10_small\"\n",
            "state {\n",
            "  phase: TEST\n",
            "  level: 0\n",
            "}\n",
            "layer {\n",
            "  name: \"data\"\n",
            "  type: \"Data\"\n",
            "  top: \"data\"\n",
            "  top: \"label\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "  transform_param {\n",
            "    mean_file: \"examples/cifar10/mean.binaryproto\"\n",
            "  }\n",
            "  data_param {\n",
            "    source: \"examples/cifar10/cifar10_test_lmdb\"\n",
            "    batch_size: 100\n",
            "    backend: LMDB\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.0001\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu1\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"pool1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv2\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"conv2\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 16\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu2\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"conv2\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool2\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"pool2\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv3\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool2\"\n",
            "  top: \"conv3\"\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu3\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv3\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool3\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"pool3\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"ip1\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"pool3\"\n",
            "  top: \"ip1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 250\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 10\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"accuracy\"\n",
            "  type: \"Accuracy\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"accuracy\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"loss\"\n",
            "  type: \"SoftmaxWithLoss\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"loss\"\n",
            "}\n",
            "I0605 10:41:02.458963 18143 layer_factory.hpp:77] Creating layer data\n",
            "I0605 10:41:02.459058 18143 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb\n",
            "I0605 10:41:02.459084 18143 net.cpp:84] Creating Layer data\n",
            "I0605 10:41:02.459095 18143 net.cpp:380] data -> data\n",
            "I0605 10:41:02.459113 18143 net.cpp:380] data -> label\n",
            "I0605 10:41:02.459128 18143 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto\n",
            "I0605 10:41:02.459998 18143 data_layer.cpp:45] output data size: 100,3,32,32\n",
            "I0605 10:41:02.464705 18143 net.cpp:122] Setting up data\n",
            "I0605 10:41:02.464733 18143 net.cpp:129] Top shape: 100 3 32 32 (307200)\n",
            "I0605 10:41:02.464747 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:41:02.464756 18143 net.cpp:137] Memory required for data: 1229200\n",
            "I0605 10:41:02.464767 18143 layer_factory.hpp:77] Creating layer label_data_1_split\n",
            "I0605 10:41:02.464783 18143 net.cpp:84] Creating Layer label_data_1_split\n",
            "I0605 10:41:02.464793 18143 net.cpp:406] label_data_1_split <- label\n",
            "I0605 10:41:02.464807 18143 net.cpp:380] label_data_1_split -> label_data_1_split_0\n",
            "I0605 10:41:02.464821 18143 net.cpp:380] label_data_1_split -> label_data_1_split_1\n",
            "I0605 10:41:02.464962 18143 net.cpp:122] Setting up label_data_1_split\n",
            "I0605 10:41:02.464982 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:41:02.464993 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:41:02.464998 18143 net.cpp:137] Memory required for data: 1230000\n",
            "I0605 10:41:02.465003 18143 layer_factory.hpp:77] Creating layer conv1\n",
            "I0605 10:41:02.465014 18143 net.cpp:84] Creating Layer conv1\n",
            "I0605 10:41:02.465026 18143 net.cpp:406] conv1 <- data\n",
            "I0605 10:41:02.465035 18143 net.cpp:380] conv1 -> conv1\n",
            "I0605 10:41:02.465309 18143 net.cpp:122] Setting up conv1\n",
            "I0605 10:41:02.465332 18143 net.cpp:129] Top shape: 100 32 32 32 (3276800)\n",
            "I0605 10:41:02.465339 18143 net.cpp:137] Memory required for data: 14337200\n",
            "I0605 10:41:02.465351 18143 layer_factory.hpp:77] Creating layer pool1\n",
            "I0605 10:41:02.465361 18143 net.cpp:84] Creating Layer pool1\n",
            "I0605 10:41:02.465366 18143 net.cpp:406] pool1 <- conv1\n",
            "I0605 10:41:02.465373 18143 net.cpp:380] pool1 -> pool1\n",
            "I0605 10:41:02.465409 18143 net.cpp:122] Setting up pool1\n",
            "I0605 10:41:02.465418 18143 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:41:02.465423 18143 net.cpp:137] Memory required for data: 17614000\n",
            "I0605 10:41:02.465427 18143 layer_factory.hpp:77] Creating layer relu1\n",
            "I0605 10:41:02.465435 18143 net.cpp:84] Creating Layer relu1\n",
            "I0605 10:41:02.465440 18143 net.cpp:406] relu1 <- pool1\n",
            "I0605 10:41:02.465456 18143 net.cpp:367] relu1 -> pool1 (in-place)\n",
            "I0605 10:41:02.465468 18143 net.cpp:122] Setting up relu1\n",
            "I0605 10:41:02.465481 18143 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:41:02.465490 18143 net.cpp:137] Memory required for data: 20890800\n",
            "I0605 10:41:02.465499 18143 layer_factory.hpp:77] Creating layer conv2\n",
            "I0605 10:41:02.465512 18143 net.cpp:84] Creating Layer conv2\n",
            "I0605 10:41:02.465520 18143 net.cpp:406] conv2 <- pool1\n",
            "I0605 10:41:02.465531 18143 net.cpp:380] conv2 -> conv2\n",
            "I0605 10:41:02.466183 18143 net.cpp:122] Setting up conv2\n",
            "I0605 10:41:02.466207 18143 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:41:02.466219 18143 net.cpp:137] Memory required for data: 22529200\n",
            "I0605 10:41:02.466234 18143 layer_factory.hpp:77] Creating layer relu2\n",
            "I0605 10:41:02.466248 18143 net.cpp:84] Creating Layer relu2\n",
            "I0605 10:41:02.466257 18143 net.cpp:406] relu2 <- conv2\n",
            "I0605 10:41:02.466269 18143 net.cpp:367] relu2 -> conv2 (in-place)\n",
            "I0605 10:41:02.466282 18143 net.cpp:122] Setting up relu2\n",
            "I0605 10:41:02.466295 18143 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:41:02.466305 18143 net.cpp:137] Memory required for data: 24167600\n",
            "I0605 10:41:02.466326 18143 layer_factory.hpp:77] Creating layer pool2\n",
            "I0605 10:41:02.466339 18143 net.cpp:84] Creating Layer pool2\n",
            "I0605 10:41:02.466349 18143 net.cpp:406] pool2 <- conv2\n",
            "I0605 10:41:02.466361 18143 net.cpp:380] pool2 -> pool2\n",
            "I0605 10:41:02.466389 18143 net.cpp:122] Setting up pool2\n",
            "I0605 10:41:02.466411 18143 net.cpp:129] Top shape: 100 16 8 8 (102400)\n",
            "I0605 10:41:02.466421 18143 net.cpp:137] Memory required for data: 24577200\n",
            "I0605 10:41:02.466430 18143 layer_factory.hpp:77] Creating layer conv3\n",
            "I0605 10:41:02.466444 18143 net.cpp:84] Creating Layer conv3\n",
            "I0605 10:41:02.466455 18143 net.cpp:406] conv3 <- pool2\n",
            "I0605 10:41:02.466468 18143 net.cpp:380] conv3 -> conv3\n",
            "I0605 10:41:02.466956 18143 net.cpp:122] Setting up conv3\n",
            "I0605 10:41:02.466977 18143 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:41:02.466989 18143 net.cpp:137] Memory required for data: 25396400\n",
            "I0605 10:41:02.467005 18143 layer_factory.hpp:77] Creating layer relu3\n",
            "I0605 10:41:02.467026 18143 net.cpp:84] Creating Layer relu3\n",
            "I0605 10:41:02.467036 18143 net.cpp:406] relu3 <- conv3\n",
            "I0605 10:41:02.467051 18143 net.cpp:367] relu3 -> conv3 (in-place)\n",
            "I0605 10:41:02.467063 18143 net.cpp:122] Setting up relu3\n",
            "I0605 10:41:02.467080 18143 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:41:02.467090 18143 net.cpp:137] Memory required for data: 26215600\n",
            "I0605 10:41:02.467099 18143 layer_factory.hpp:77] Creating layer pool3\n",
            "I0605 10:41:02.467113 18143 net.cpp:84] Creating Layer pool3\n",
            "I0605 10:41:02.467136 18143 net.cpp:406] pool3 <- conv3\n",
            "I0605 10:41:02.467149 18143 net.cpp:380] pool3 -> pool3\n",
            "I0605 10:41:02.467180 18143 net.cpp:122] Setting up pool3\n",
            "I0605 10:41:02.467196 18143 net.cpp:129] Top shape: 100 32 4 4 (51200)\n",
            "I0605 10:41:02.467206 18143 net.cpp:137] Memory required for data: 26420400\n",
            "I0605 10:41:02.467218 18143 layer_factory.hpp:77] Creating layer ip1\n",
            "I0605 10:41:02.467232 18143 net.cpp:84] Creating Layer ip1\n",
            "I0605 10:41:02.467243 18143 net.cpp:406] ip1 <- pool3\n",
            "I0605 10:41:02.467255 18143 net.cpp:380] ip1 -> ip1\n",
            "I0605 10:41:02.467447 18143 net.cpp:122] Setting up ip1\n",
            "I0605 10:41:02.467473 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:41:02.467484 18143 net.cpp:137] Memory required for data: 26424400\n",
            "I0605 10:41:02.467499 18143 layer_factory.hpp:77] Creating layer ip1_ip1_0_split\n",
            "I0605 10:41:02.467512 18143 net.cpp:84] Creating Layer ip1_ip1_0_split\n",
            "I0605 10:41:02.467523 18143 net.cpp:406] ip1_ip1_0_split <- ip1\n",
            "I0605 10:41:02.467535 18143 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0\n",
            "I0605 10:41:02.467548 18143 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1\n",
            "I0605 10:41:02.467640 18143 net.cpp:122] Setting up ip1_ip1_0_split\n",
            "I0605 10:41:02.467656 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:41:02.467675 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:41:02.467685 18143 net.cpp:137] Memory required for data: 26432400\n",
            "I0605 10:41:02.467705 18143 layer_factory.hpp:77] Creating layer accuracy\n",
            "I0605 10:41:02.467717 18143 net.cpp:84] Creating Layer accuracy\n",
            "I0605 10:41:02.467727 18143 net.cpp:406] accuracy <- ip1_ip1_0_split_0\n",
            "I0605 10:41:02.467739 18143 net.cpp:406] accuracy <- label_data_1_split_0\n",
            "I0605 10:41:02.467751 18143 net.cpp:380] accuracy -> accuracy\n",
            "I0605 10:41:02.467766 18143 net.cpp:122] Setting up accuracy\n",
            "I0605 10:41:02.467777 18143 net.cpp:129] Top shape: (1)\n",
            "I0605 10:41:02.467793 18143 net.cpp:137] Memory required for data: 26432404\n",
            "I0605 10:41:02.467803 18143 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:41:02.467814 18143 net.cpp:84] Creating Layer loss\n",
            "I0605 10:41:02.467823 18143 net.cpp:406] loss <- ip1_ip1_0_split_1\n",
            "I0605 10:41:02.467833 18143 net.cpp:406] loss <- label_data_1_split_1\n",
            "I0605 10:41:02.467844 18143 net.cpp:380] loss -> loss\n",
            "I0605 10:41:02.467856 18143 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:41:02.468199 18143 net.cpp:122] Setting up loss\n",
            "I0605 10:41:02.468221 18143 net.cpp:129] Top shape: (1)\n",
            "I0605 10:41:02.468232 18143 net.cpp:132]     with loss weight 1\n",
            "I0605 10:41:02.468250 18143 net.cpp:137] Memory required for data: 26432408\n",
            "I0605 10:41:02.468261 18143 net.cpp:198] loss needs backward computation.\n",
            "I0605 10:41:02.468276 18143 net.cpp:200] accuracy does not need backward computation.\n",
            "I0605 10:41:02.468289 18143 net.cpp:198] ip1_ip1_0_split needs backward computation.\n",
            "I0605 10:41:02.468304 18143 net.cpp:198] ip1 needs backward computation.\n",
            "I0605 10:41:02.468315 18143 net.cpp:198] pool3 needs backward computation.\n",
            "I0605 10:41:02.468325 18143 net.cpp:198] relu3 needs backward computation.\n",
            "I0605 10:41:02.468335 18143 net.cpp:198] conv3 needs backward computation.\n",
            "I0605 10:41:02.468346 18143 net.cpp:198] pool2 needs backward computation.\n",
            "I0605 10:41:02.468356 18143 net.cpp:198] relu2 needs backward computation.\n",
            "I0605 10:41:02.468386 18143 net.cpp:198] conv2 needs backward computation.\n",
            "I0605 10:41:02.468397 18143 net.cpp:198] relu1 needs backward computation.\n",
            "I0605 10:41:02.468408 18143 net.cpp:198] pool1 needs backward computation.\n",
            "I0605 10:41:02.468418 18143 net.cpp:198] conv1 needs backward computation.\n",
            "I0605 10:41:02.468430 18143 net.cpp:200] label_data_1_split does not need backward computation.\n",
            "I0605 10:41:02.468441 18143 net.cpp:200] data does not need backward computation.\n",
            "I0605 10:41:02.468452 18143 net.cpp:242] This network produces output accuracy\n",
            "I0605 10:41:02.468463 18143 net.cpp:242] This network produces output loss\n",
            "I0605 10:41:02.468484 18143 net.cpp:255] Network initialization done.\n",
            "I0605 10:41:04.739706 18160 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Accuracy with quantized weights: 68.84%\n",
            "I0605 10:41:09.860435 18160 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Accuracy with quantized weights and activations: 67.55%\n",
            "Layer: conv1 biases max: 0.047492217 min: -0.023894053 Format: Q-1.8\n",
            "I0605 10:41:15.129550 18160 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Accuracy: 67.51%\n",
            "Final conv1 biases format Q-1.8 Accuracy: 67.51%\n",
            "Layer: conv2 biases max: 0.031793397 min: -0.02079631 Format: Q-1.8\n",
            "I0605 10:41:20.328207 18160 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Accuracy: 67.53%\n",
            "Final conv2 biases format Q-1.8 Accuracy: 67.53%\n",
            "Layer: conv3 biases max: 0.022730144 min: -0.01993962 Format: Q1.6\n",
            "I0605 10:41:25.449013 18160 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Accuracy: 67.57%\n",
            "Final conv3 biases format Q1.6 Accuracy: 67.57%\n",
            "Layer: ip1 biases max: 0.5514027 min: -0.44420913 Format: Q0.7\n",
            "I0605 10:41:30.601075 18160 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Accuracy: 67.59%\n",
            "Final ip1 biases format Q0.7 Accuracy: 67.59%\n",
            "W0605 10:41:30.819834 18143 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface\n",
            "W0605 10:41:30.819866 18143 _caffe.cpp:140] Use this instead (with the named \"weights\" parameter):\n",
            "W0605 10:41:30.819887 18143 _caffe.cpp:142] Net('examples/cifar10/cifar10_m4_train_test_small.prototxt', 1, weights='examples/cifar10/quantized_cifar10_small_iter_5000.caffemodel')\n",
            "I0605 10:41:30.820096 18143 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\n",
            "I0605 10:41:30.820205 18143 net.cpp:51] Initializing net from parameters: \n",
            "name: \"CIFAR10_small\"\n",
            "state {\n",
            "  phase: TEST\n",
            "  level: 0\n",
            "}\n",
            "layer {\n",
            "  name: \"data\"\n",
            "  type: \"Data\"\n",
            "  top: \"data\"\n",
            "  top: \"label\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "  transform_param {\n",
            "    mean_file: \"examples/cifar10/mean.binaryproto\"\n",
            "  }\n",
            "  data_param {\n",
            "    source: \"examples/cifar10/cifar10_test_lmdb\"\n",
            "    batch_size: 100\n",
            "    backend: LMDB\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.0001\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu1\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"pool1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv2\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"conv2\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 16\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu2\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"conv2\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool2\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"pool2\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv3\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool2\"\n",
            "  top: \"conv3\"\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu3\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv3\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool3\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"pool3\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"ip1\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"pool3\"\n",
            "  top: \"ip1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 250\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 10\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"accuracy\"\n",
            "  type: \"Accuracy\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"accuracy\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"loss\"\n",
            "  type: \"SoftmaxWithLoss\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"loss\"\n",
            "}\n",
            "I0605 10:41:30.820302 18143 layer_factory.hpp:77] Creating layer data\n",
            "I0605 10:41:30.820386 18143 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb\n",
            "I0605 10:41:30.820426 18143 net.cpp:84] Creating Layer data\n",
            "I0605 10:41:30.820441 18143 net.cpp:380] data -> data\n",
            "I0605 10:41:30.820456 18143 net.cpp:380] data -> label\n",
            "I0605 10:41:30.820470 18143 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto\n",
            "I0605 10:41:30.821250 18143 data_layer.cpp:45] output data size: 100,3,32,32\n",
            "I0605 10:41:30.825505 18143 net.cpp:122] Setting up data\n",
            "I0605 10:41:30.825528 18143 net.cpp:129] Top shape: 100 3 32 32 (307200)\n",
            "I0605 10:41:30.825543 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:41:30.825552 18143 net.cpp:137] Memory required for data: 1229200\n",
            "I0605 10:41:30.825563 18143 layer_factory.hpp:77] Creating layer label_data_1_split\n",
            "I0605 10:41:30.825598 18143 net.cpp:84] Creating Layer label_data_1_split\n",
            "I0605 10:41:30.825613 18143 net.cpp:406] label_data_1_split <- label\n",
            "I0605 10:41:30.825626 18143 net.cpp:380] label_data_1_split -> label_data_1_split_0\n",
            "I0605 10:41:30.825654 18143 net.cpp:380] label_data_1_split -> label_data_1_split_1\n",
            "I0605 10:41:30.825743 18143 net.cpp:122] Setting up label_data_1_split\n",
            "I0605 10:41:30.825762 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:41:30.825774 18143 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:41:30.825784 18143 net.cpp:137] Memory required for data: 1230000\n",
            "I0605 10:41:30.825794 18143 layer_factory.hpp:77] Creating layer conv1\n",
            "I0605 10:41:30.825810 18143 net.cpp:84] Creating Layer conv1\n",
            "I0605 10:41:30.825821 18143 net.cpp:406] conv1 <- data\n",
            "I0605 10:41:30.825835 18143 net.cpp:380] conv1 -> conv1\n",
            "I0605 10:41:30.826092 18143 net.cpp:122] Setting up conv1\n",
            "I0605 10:41:30.826113 18143 net.cpp:129] Top shape: 100 32 32 32 (3276800)\n",
            "I0605 10:41:30.826119 18143 net.cpp:137] Memory required for data: 14337200\n",
            "I0605 10:41:30.826130 18143 layer_factory.hpp:77] Creating layer pool1\n",
            "I0605 10:41:30.826139 18143 net.cpp:84] Creating Layer pool1\n",
            "I0605 10:41:30.826144 18143 net.cpp:406] pool1 <- conv1\n",
            "I0605 10:41:30.826151 18143 net.cpp:380] pool1 -> pool1\n",
            "I0605 10:41:30.826185 18143 net.cpp:122] Setting up pool1\n",
            "I0605 10:41:30.826195 18143 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:41:30.826200 18143 net.cpp:137] Memory required for data: 17614000\n",
            "I0605 10:41:30.826205 18143 layer_factory.hpp:77] Creating layer relu1\n",
            "I0605 10:41:30.826213 18143 net.cpp:84] Creating Layer relu1\n",
            "I0605 10:41:30.826218 18143 net.cpp:406] relu1 <- pool1\n",
            "I0605 10:41:30.826225 18143 net.cpp:367] relu1 -> pool1 (in-place)\n",
            "I0605 10:41:30.826232 18143 net.cpp:122] Setting up relu1\n",
            "I0605 10:41:30.826239 18143 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:41:30.826244 18143 net.cpp:137] Memory required for data: 20890800\n",
            "I0605 10:41:30.826248 18143 layer_factory.hpp:77] Creating layer conv2\n",
            "I0605 10:41:30.826264 18143 net.cpp:84] Creating Layer conv2\n",
            "I0605 10:41:30.826274 18143 net.cpp:406] conv2 <- pool1\n",
            "I0605 10:41:30.826288 18143 net.cpp:380] conv2 -> conv2\n",
            "I0605 10:41:30.826838 18143 net.cpp:122] Setting up conv2\n",
            "I0605 10:41:30.826862 18143 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:41:30.826875 18143 net.cpp:137] Memory required for data: 22529200\n",
            "I0605 10:41:30.826890 18143 layer_factory.hpp:77] Creating layer relu2\n",
            "I0605 10:41:30.826905 18143 net.cpp:84] Creating Layer relu2\n",
            "I0605 10:41:30.826915 18143 net.cpp:406] relu2 <- conv2\n",
            "I0605 10:41:30.826926 18143 net.cpp:367] relu2 -> conv2 (in-place)\n",
            "I0605 10:41:30.826941 18143 net.cpp:122] Setting up relu2\n",
            "I0605 10:41:30.826959 18143 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:41:30.826969 18143 net.cpp:137] Memory required for data: 24167600\n",
            "I0605 10:41:30.826978 18143 layer_factory.hpp:77] Creating layer pool2\n",
            "I0605 10:41:30.826990 18143 net.cpp:84] Creating Layer pool2\n",
            "I0605 10:41:30.827003 18143 net.cpp:406] pool2 <- conv2\n",
            "I0605 10:41:30.827013 18143 net.cpp:380] pool2 -> pool2\n",
            "I0605 10:41:30.827039 18143 net.cpp:122] Setting up pool2\n",
            "I0605 10:41:30.827055 18143 net.cpp:129] Top shape: 100 16 8 8 (102400)\n",
            "I0605 10:41:30.827065 18143 net.cpp:137] Memory required for data: 24577200\n",
            "I0605 10:41:30.827075 18143 layer_factory.hpp:77] Creating layer conv3\n",
            "I0605 10:41:30.827090 18143 net.cpp:84] Creating Layer conv3\n",
            "I0605 10:41:30.827100 18143 net.cpp:406] conv3 <- pool2\n",
            "I0605 10:41:30.827112 18143 net.cpp:380] conv3 -> conv3\n",
            "I0605 10:41:30.827535 18143 net.cpp:122] Setting up conv3\n",
            "I0605 10:41:30.827555 18143 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:41:30.827566 18143 net.cpp:137] Memory required for data: 25396400\n",
            "I0605 10:41:30.827580 18143 layer_factory.hpp:77] Creating layer relu3\n",
            "I0605 10:41:30.827620 18143 net.cpp:84] Creating Layer relu3\n",
            "I0605 10:41:30.827632 18143 net.cpp:406] relu3 <- conv3\n",
            "I0605 10:41:30.827643 18143 net.cpp:367] relu3 -> conv3 (in-place)\n",
            "I0605 10:41:30.827656 18143 net.cpp:122] Setting up relu3\n",
            "I0605 10:41:30.827669 18143 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:41:30.827679 18143 net.cpp:137] Memory required for data: 26215600\n",
            "I0605 10:41:30.827688 18143 layer_factory.hpp:77] Creating layer pool3\n",
            "I0605 10:41:30.827709 18143 net.cpp:84] Creating Layer pool3\n",
            "I0605 10:41:30.827728 18143 net.cpp:406] pool3 <- conv3\n",
            "I0605 10:41:30.827739 18143 net.cpp:380] pool3 -> pool3\n",
            "I0605 10:41:30.827775 18143 net.cpp:122] Setting up pool3\n",
            "I0605 10:41:30.827791 18143 net.cpp:129] Top shape: 100 32 4 4 (51200)\n",
            "I0605 10:41:30.827802 18143 net.cpp:137] Memory required for data: 26420400\n",
            "I0605 10:41:30.827811 18143 layer_factory.hpp:77] Creating layer ip1\n",
            "I0605 10:41:30.827826 18143 net.cpp:84] Creating Layer ip1\n",
            "I0605 10:41:30.827836 18143 net.cpp:406] ip1 <- pool3\n",
            "I0605 10:41:30.827848 18143 net.cpp:380] ip1 -> ip1\n",
            "I0605 10:41:30.828035 18143 net.cpp:122] Setting up ip1\n",
            "I0605 10:41:30.828052 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:41:30.828063 18143 net.cpp:137] Memory required for data: 26424400\n",
            "I0605 10:41:30.828074 18143 layer_factory.hpp:77] Creating layer ip1_ip1_0_split\n",
            "I0605 10:41:30.828088 18143 net.cpp:84] Creating Layer ip1_ip1_0_split\n",
            "I0605 10:41:30.828097 18143 net.cpp:406] ip1_ip1_0_split <- ip1\n",
            "I0605 10:41:30.828109 18143 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0\n",
            "I0605 10:41:30.828124 18143 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1\n",
            "I0605 10:41:30.828169 18143 net.cpp:122] Setting up ip1_ip1_0_split\n",
            "I0605 10:41:30.828197 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:41:30.828204 18143 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:41:30.828213 18143 net.cpp:137] Memory required for data: 26432400\n",
            "I0605 10:41:30.828222 18143 layer_factory.hpp:77] Creating layer accuracy\n",
            "I0605 10:41:30.828234 18143 net.cpp:84] Creating Layer accuracy\n",
            "I0605 10:41:30.828244 18143 net.cpp:406] accuracy <- ip1_ip1_0_split_0\n",
            "I0605 10:41:30.828255 18143 net.cpp:406] accuracy <- label_data_1_split_0\n",
            "I0605 10:41:30.828267 18143 net.cpp:380] accuracy -> accuracy\n",
            "I0605 10:41:30.828281 18143 net.cpp:122] Setting up accuracy\n",
            "I0605 10:41:30.828308 18143 net.cpp:129] Top shape: (1)\n",
            "I0605 10:41:30.828317 18143 net.cpp:137] Memory required for data: 26432404\n",
            "I0605 10:41:30.828326 18143 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:41:30.828338 18143 net.cpp:84] Creating Layer loss\n",
            "I0605 10:41:30.828347 18143 net.cpp:406] loss <- ip1_ip1_0_split_1\n",
            "I0605 10:41:30.828357 18143 net.cpp:406] loss <- label_data_1_split_1\n",
            "I0605 10:41:30.828368 18143 net.cpp:380] loss -> loss\n",
            "I0605 10:41:30.828382 18143 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:41:30.828532 18143 net.cpp:122] Setting up loss\n",
            "I0605 10:41:30.828554 18143 net.cpp:129] Top shape: (1)\n",
            "I0605 10:41:30.828565 18143 net.cpp:132]     with loss weight 1\n",
            "I0605 10:41:30.828604 18143 net.cpp:137] Memory required for data: 26432408\n",
            "I0605 10:41:30.828634 18143 net.cpp:198] loss needs backward computation.\n",
            "I0605 10:41:30.828647 18143 net.cpp:200] accuracy does not need backward computation.\n",
            "I0605 10:41:30.828658 18143 net.cpp:198] ip1_ip1_0_split needs backward computation.\n",
            "I0605 10:41:30.828670 18143 net.cpp:198] ip1 needs backward computation.\n",
            "I0605 10:41:30.828680 18143 net.cpp:198] pool3 needs backward computation.\n",
            "I0605 10:41:30.828697 18143 net.cpp:198] relu3 needs backward computation.\n",
            "I0605 10:41:30.828711 18143 net.cpp:198] conv3 needs backward computation.\n",
            "I0605 10:41:30.828722 18143 net.cpp:198] pool2 needs backward computation.\n",
            "I0605 10:41:30.828748 18143 net.cpp:198] relu2 needs backward computation.\n",
            "I0605 10:41:30.828759 18143 net.cpp:198] conv2 needs backward computation.\n",
            "I0605 10:41:30.828769 18143 net.cpp:198] relu1 needs backward computation.\n",
            "I0605 10:41:30.828780 18143 net.cpp:198] pool1 needs backward computation.\n",
            "I0605 10:41:30.828789 18143 net.cpp:198] conv1 needs backward computation.\n",
            "I0605 10:41:30.828801 18143 net.cpp:200] label_data_1_split does not need backward computation.\n",
            "I0605 10:41:30.828812 18143 net.cpp:200] data does not need backward computation.\n",
            "I0605 10:41:30.828822 18143 net.cpp:242] This network produces output accuracy\n",
            "I0605 10:41:30.828833 18143 net.cpp:242] This network produces output loss\n",
            "I0605 10:41:30.828851 18143 net.cpp:255] Network initialization done.\n",
            "I0605 10:41:32.968153 18161 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Accuracy with quantized weights/biases: 68.85%\n",
            "I0605 10:41:38.006065 18161 data_layer.cpp:73] Restarting data prefetching from start.\n",
            "Accuracy with quantized weights/biases and activations: 67.59%\n",
            "Input: data Q7.0(scaling factor:1)\n",
            "Layer: conv1 Q8.-1 (scaling factor:0.5) Wts: Q-1.8 (scaling factor:256) Biases: Q-1.8(scaling factor:256)\n",
            "Layer: conv2 Q10.-3 (scaling factor:0.125) Wts: Q-2.9 (scaling factor:512) Biases: Q-1.8(scaling factor:256)\n",
            "Layer: conv3 Q9.-2 (scaling factor:0.25) Wts: Q-2.9 (scaling factor:512) Biases: Q1.6(scaling factor:64)\n",
            "Layer: ip1 Q3.4 (scaling factor:16) Wts: Q-4.11 (scaling factor:2048) Biases: Q0.7(scaling factor:128)\n",
            "Layer: conv1 bias left shift: 0 act_rshift: 9\n",
            "Layer: conv2 bias left shift: 0 act_rshift: 11\n",
            "Layer: conv3 bias left shift: 0 act_rshift: 8\n",
            "Layer: ip1 bias left shift: 2 act_rshift: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dEPa1oeoPBM",
        "colab_type": "text"
      },
      "source": [
        "## Run the code generation\n",
        "`code_gen.py`: Gets the quantization parameters and network graph connectivity from previous step and generates the code consisting of NN function calls. Supported layers: convolution, innerproduct, pooling (max/average) and relu. It generates (a) weights.h (b) parameter.h: consisting of quantization ranges and (c) main.cpp: the network code.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FT4BAjjqfxO",
        "colab_type": "code",
        "outputId": "91a350c0-339e-4530-cf0c-6ebdacd96a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!mkdir examples/cifar10/code\n",
        "!python quant/code_gen.py \\\n",
        "--model examples/cifar10/cifar10_m4_small.pkl \\\n",
        "--out_dir examples/cifar10/code/m4_small"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating weights file: examples/cifar10/code/m4_small/weights.h\n",
            "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
            "W0605 10:43:39.020635 18166 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface\n",
            "W0605 10:43:39.020689 18166 _caffe.cpp:140] Use this instead (with the named \"weights\" parameter):\n",
            "W0605 10:43:39.020711 18166 _caffe.cpp:142] Net('examples/cifar10/cifar10_m4_train_test_small.prototxt', 1, weights='examples/cifar10/quantized_cifar10_small_iter_5000.caffemodel')\n",
            "I0605 10:43:39.255107 18166 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\n",
            "I0605 10:43:39.255368 18166 net.cpp:51] Initializing net from parameters: \n",
            "name: \"CIFAR10_small\"\n",
            "state {\n",
            "  phase: TEST\n",
            "  level: 0\n",
            "}\n",
            "layer {\n",
            "  name: \"data\"\n",
            "  type: \"Data\"\n",
            "  top: \"data\"\n",
            "  top: \"label\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "  transform_param {\n",
            "    mean_file: \"examples/cifar10/mean.binaryproto\"\n",
            "  }\n",
            "  data_param {\n",
            "    source: \"examples/cifar10/cifar10_test_lmdb\"\n",
            "    batch_size: 100\n",
            "    backend: LMDB\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.0001\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu1\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"pool1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv2\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"conv2\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 16\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu2\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"conv2\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool2\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"pool2\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv3\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool2\"\n",
            "  top: \"conv3\"\n",
            "  convolution_param {\n",
            "    num_output: 32\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    stride: 1\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu3\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv3\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool3\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"pool3\"\n",
            "  pooling_param {\n",
            "    pool: AVE\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"ip1\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"pool3\"\n",
            "  top: \"ip1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 250\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 10\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"accuracy\"\n",
            "  type: \"Accuracy\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"accuracy\"\n",
            "  include {\n",
            "    phase: TEST\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"loss\"\n",
            "  type: \"SoftmaxWithLoss\"\n",
            "  bottom: \"ip1\"\n",
            "  bottom: \"label\"\n",
            "  top: \"loss\"\n",
            "}\n",
            "I0605 10:43:39.255620 18166 layer_factory.hpp:77] Creating layer data\n",
            "I0605 10:43:39.255784 18166 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb\n",
            "I0605 10:43:39.255817 18166 net.cpp:84] Creating Layer data\n",
            "I0605 10:43:39.255837 18166 net.cpp:380] data -> data\n",
            "I0605 10:43:39.255892 18166 net.cpp:380] data -> label\n",
            "I0605 10:43:39.255921 18166 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto\n",
            "I0605 10:43:39.256085 18166 data_layer.cpp:45] output data size: 100,3,32,32\n",
            "I0605 10:43:39.260335 18166 net.cpp:122] Setting up data\n",
            "I0605 10:43:39.260512 18166 net.cpp:129] Top shape: 100 3 32 32 (307200)\n",
            "I0605 10:43:39.260529 18166 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:43:39.260541 18166 net.cpp:137] Memory required for data: 1229200\n",
            "I0605 10:43:39.260553 18166 layer_factory.hpp:77] Creating layer label_data_1_split\n",
            "I0605 10:43:39.260574 18166 net.cpp:84] Creating Layer label_data_1_split\n",
            "I0605 10:43:39.260604 18166 net.cpp:406] label_data_1_split <- label\n",
            "I0605 10:43:39.260623 18166 net.cpp:380] label_data_1_split -> label_data_1_split_0\n",
            "I0605 10:43:39.260640 18166 net.cpp:380] label_data_1_split -> label_data_1_split_1\n",
            "I0605 10:43:39.260658 18166 net.cpp:122] Setting up label_data_1_split\n",
            "I0605 10:43:39.260671 18166 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:43:39.260684 18166 net.cpp:129] Top shape: 100 (100)\n",
            "I0605 10:43:39.260694 18166 net.cpp:137] Memory required for data: 1230000\n",
            "I0605 10:43:39.260704 18166 layer_factory.hpp:77] Creating layer conv1\n",
            "I0605 10:43:39.260720 18166 net.cpp:84] Creating Layer conv1\n",
            "I0605 10:43:39.260731 18166 net.cpp:406] conv1 <- data\n",
            "I0605 10:43:39.260743 18166 net.cpp:380] conv1 -> conv1\n",
            "I0605 10:43:39.260824 18166 net.cpp:122] Setting up conv1\n",
            "I0605 10:43:39.260841 18166 net.cpp:129] Top shape: 100 32 32 32 (3276800)\n",
            "I0605 10:43:39.260851 18166 net.cpp:137] Memory required for data: 14337200\n",
            "I0605 10:43:39.260869 18166 layer_factory.hpp:77] Creating layer pool1\n",
            "I0605 10:43:39.260884 18166 net.cpp:84] Creating Layer pool1\n",
            "I0605 10:43:39.260895 18166 net.cpp:406] pool1 <- conv1\n",
            "I0605 10:43:39.260906 18166 net.cpp:380] pool1 -> pool1\n",
            "I0605 10:43:39.260928 18166 net.cpp:122] Setting up pool1\n",
            "I0605 10:43:39.260943 18166 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:43:39.260953 18166 net.cpp:137] Memory required for data: 17614000\n",
            "I0605 10:43:39.260963 18166 layer_factory.hpp:77] Creating layer relu1\n",
            "I0605 10:43:39.260975 18166 net.cpp:84] Creating Layer relu1\n",
            "I0605 10:43:39.260987 18166 net.cpp:406] relu1 <- pool1\n",
            "I0605 10:43:39.260998 18166 net.cpp:367] relu1 -> pool1 (in-place)\n",
            "I0605 10:43:39.261010 18166 net.cpp:122] Setting up relu1\n",
            "I0605 10:43:39.261023 18166 net.cpp:129] Top shape: 100 32 16 16 (819200)\n",
            "I0605 10:43:39.261032 18166 net.cpp:137] Memory required for data: 20890800\n",
            "I0605 10:43:39.261042 18166 layer_factory.hpp:77] Creating layer conv2\n",
            "I0605 10:43:39.261055 18166 net.cpp:84] Creating Layer conv2\n",
            "I0605 10:43:39.261067 18166 net.cpp:406] conv2 <- pool1\n",
            "I0605 10:43:39.261080 18166 net.cpp:380] conv2 -> conv2\n",
            "I0605 10:43:39.261339 18166 net.cpp:122] Setting up conv2\n",
            "I0605 10:43:39.261363 18166 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:43:39.261373 18166 net.cpp:137] Memory required for data: 22529200\n",
            "I0605 10:43:39.261387 18166 layer_factory.hpp:77] Creating layer relu2\n",
            "I0605 10:43:39.261401 18166 net.cpp:84] Creating Layer relu2\n",
            "I0605 10:43:39.261412 18166 net.cpp:406] relu2 <- conv2\n",
            "I0605 10:43:39.261425 18166 net.cpp:367] relu2 -> conv2 (in-place)\n",
            "I0605 10:43:39.261515 18166 net.cpp:122] Setting up relu2\n",
            "I0605 10:43:39.261567 18166 net.cpp:129] Top shape: 100 16 16 16 (409600)\n",
            "I0605 10:43:39.261579 18166 net.cpp:137] Memory required for data: 24167600\n",
            "I0605 10:43:39.261631 18166 layer_factory.hpp:77] Creating layer pool2\n",
            "I0605 10:43:39.261656 18166 net.cpp:84] Creating Layer pool2\n",
            "I0605 10:43:39.261682 18166 net.cpp:406] pool2 <- conv2\n",
            "I0605 10:43:39.261739 18166 net.cpp:380] pool2 -> pool2\n",
            "I0605 10:43:39.261755 18166 net.cpp:122] Setting up pool2\n",
            "I0605 10:43:39.261768 18166 net.cpp:129] Top shape: 100 16 8 8 (102400)\n",
            "I0605 10:43:39.261780 18166 net.cpp:137] Memory required for data: 24577200\n",
            "I0605 10:43:39.261788 18166 layer_factory.hpp:77] Creating layer conv3\n",
            "I0605 10:43:39.261814 18166 net.cpp:84] Creating Layer conv3\n",
            "I0605 10:43:39.261829 18166 net.cpp:406] conv3 <- pool2\n",
            "I0605 10:43:39.261842 18166 net.cpp:380] conv3 -> conv3\n",
            "I0605 10:43:39.262200 18166 net.cpp:122] Setting up conv3\n",
            "I0605 10:43:39.262219 18166 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:43:39.262229 18166 net.cpp:137] Memory required for data: 25396400\n",
            "I0605 10:43:39.262243 18166 layer_factory.hpp:77] Creating layer relu3\n",
            "I0605 10:43:39.262259 18166 net.cpp:84] Creating Layer relu3\n",
            "I0605 10:43:39.262269 18166 net.cpp:406] relu3 <- conv3\n",
            "I0605 10:43:39.262279 18166 net.cpp:367] relu3 -> conv3 (in-place)\n",
            "I0605 10:43:39.262306 18166 net.cpp:122] Setting up relu3\n",
            "I0605 10:43:39.262414 18166 net.cpp:129] Top shape: 100 32 8 8 (204800)\n",
            "I0605 10:43:39.262431 18166 net.cpp:137] Memory required for data: 26215600\n",
            "I0605 10:43:39.262441 18166 layer_factory.hpp:77] Creating layer pool3\n",
            "I0605 10:43:39.262454 18166 net.cpp:84] Creating Layer pool3\n",
            "I0605 10:43:39.262464 18166 net.cpp:406] pool3 <- conv3\n",
            "I0605 10:43:39.262501 18166 net.cpp:380] pool3 -> pool3\n",
            "I0605 10:43:39.262516 18166 net.cpp:122] Setting up pool3\n",
            "I0605 10:43:39.262531 18166 net.cpp:129] Top shape: 100 32 4 4 (51200)\n",
            "I0605 10:43:39.262563 18166 net.cpp:137] Memory required for data: 26420400\n",
            "I0605 10:43:39.262601 18166 layer_factory.hpp:77] Creating layer ip1\n",
            "I0605 10:43:39.262619 18166 net.cpp:84] Creating Layer ip1\n",
            "I0605 10:43:39.262630 18166 net.cpp:406] ip1 <- pool3\n",
            "I0605 10:43:39.262643 18166 net.cpp:380] ip1 -> ip1\n",
            "I0605 10:43:39.262738 18166 net.cpp:122] Setting up ip1\n",
            "I0605 10:43:39.262754 18166 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:43:39.262763 18166 net.cpp:137] Memory required for data: 26424400\n",
            "I0605 10:43:39.262778 18166 layer_factory.hpp:77] Creating layer ip1_ip1_0_split\n",
            "I0605 10:43:39.262812 18166 net.cpp:84] Creating Layer ip1_ip1_0_split\n",
            "I0605 10:43:39.262823 18166 net.cpp:406] ip1_ip1_0_split <- ip1\n",
            "I0605 10:43:39.262836 18166 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0\n",
            "I0605 10:43:39.262850 18166 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1\n",
            "I0605 10:43:39.262864 18166 net.cpp:122] Setting up ip1_ip1_0_split\n",
            "I0605 10:43:39.262905 18166 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:43:39.262917 18166 net.cpp:129] Top shape: 100 10 (1000)\n",
            "I0605 10:43:39.262925 18166 net.cpp:137] Memory required for data: 26432400\n",
            "I0605 10:43:39.262934 18166 layer_factory.hpp:77] Creating layer accuracy\n",
            "I0605 10:43:39.262948 18166 net.cpp:84] Creating Layer accuracy\n",
            "I0605 10:43:39.262974 18166 net.cpp:406] accuracy <- ip1_ip1_0_split_0\n",
            "I0605 10:43:39.262984 18166 net.cpp:406] accuracy <- label_data_1_split_0\n",
            "I0605 10:43:39.263010 18166 net.cpp:380] accuracy -> accuracy\n",
            "I0605 10:43:39.263039 18166 net.cpp:122] Setting up accuracy\n",
            "I0605 10:43:39.263067 18166 net.cpp:129] Top shape: (1)\n",
            "I0605 10:43:39.263077 18166 net.cpp:137] Memory required for data: 26432404\n",
            "I0605 10:43:39.263096 18166 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:43:39.263124 18166 net.cpp:84] Creating Layer loss\n",
            "I0605 10:43:39.263159 18166 net.cpp:406] loss <- ip1_ip1_0_split_1\n",
            "I0605 10:43:39.263170 18166 net.cpp:406] loss <- label_data_1_split_1\n",
            "I0605 10:43:39.263180 18166 net.cpp:380] loss -> loss\n",
            "I0605 10:43:39.263196 18166 layer_factory.hpp:77] Creating layer loss\n",
            "I0605 10:43:39.263254 18166 net.cpp:122] Setting up loss\n",
            "I0605 10:43:39.263293 18166 net.cpp:129] Top shape: (1)\n",
            "I0605 10:43:39.263324 18166 net.cpp:132]     with loss weight 1\n",
            "I0605 10:43:39.263351 18166 net.cpp:137] Memory required for data: 26432408\n",
            "I0605 10:43:39.263362 18166 net.cpp:198] loss needs backward computation.\n",
            "I0605 10:43:39.263376 18166 net.cpp:200] accuracy does not need backward computation.\n",
            "I0605 10:43:39.263391 18166 net.cpp:198] ip1_ip1_0_split needs backward computation.\n",
            "I0605 10:43:39.263401 18166 net.cpp:198] ip1 needs backward computation.\n",
            "I0605 10:43:39.263422 18166 net.cpp:198] pool3 needs backward computation.\n",
            "I0605 10:43:39.263433 18166 net.cpp:198] relu3 needs backward computation.\n",
            "I0605 10:43:39.263444 18166 net.cpp:198] conv3 needs backward computation.\n",
            "I0605 10:43:39.263464 18166 net.cpp:198] pool2 needs backward computation.\n",
            "I0605 10:43:39.263474 18166 net.cpp:198] relu2 needs backward computation.\n",
            "I0605 10:43:39.263484 18166 net.cpp:198] conv2 needs backward computation.\n",
            "I0605 10:43:39.263505 18166 net.cpp:198] relu1 needs backward computation.\n",
            "I0605 10:43:39.263515 18166 net.cpp:198] pool1 needs backward computation.\n",
            "I0605 10:43:39.263525 18166 net.cpp:198] conv1 needs backward computation.\n",
            "I0605 10:43:39.263536 18166 net.cpp:200] label_data_1_split does not need backward computation.\n",
            "I0605 10:43:39.263546 18166 net.cpp:200] data does not need backward computation.\n",
            "I0605 10:43:39.263562 18166 net.cpp:242] This network produces output accuracy\n",
            "I0605 10:43:39.263573 18166 net.cpp:242] This network produces output loss\n",
            "I0605 10:43:39.263625 18166 net.cpp:255] Network initialization done.\n",
            "Generating parameter file: examples/cifar10/code/m4_small/parameter.h\n",
            "Generating file: examples/cifar10/code/m4_small/main.cpp\n",
            "Layer: conv1, required memory: 3200, im2col buffer size: 3200\n",
            "Layer: conv2, required memory: 1600, im2col buffer size: 3200\n",
            "Layer: conv3, required memory: 3200, im2col buffer size: 3200\n",
            "Layer: ip1, required memory: 20, im2col buffer size: 3200\n",
            "Layer: conv1, required memory: 35840, buffer size: 35840\n",
            "Layer: pool1, required memory: 40960, buffer size: 40960\n",
            "Layer: conv2, required memory: 12288, buffer size: 40960\n",
            "Layer: pool2, required memory: 5120, buffer size: 40960\n",
            "Layer: conv3, required memory: 3072, buffer size: 40960\n",
            "Layer: pool3, required memory: 2560, buffer size: 40960\n",
            "Layer: ip1, required memory: 522, buffer size: 40960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWOsBwPJo_CV",
        "colab_type": "text"
      },
      "source": [
        "## Download the generated code to local machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkD7RCd8qfxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('examples/cifar10/code/m4_small/weights.h')\n",
        "files.download('examples/cifar10/code/m4_small/main.cpp')\n",
        "files.download('examples/cifar10/code/m4_small/parameter.h')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjHmnkj2pU7v",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "If the model structure is unchanged, we just need to take those data from \n",
        "- (a) weights.h - (weights and bias)\n",
        "- (b) parameter.h - (bias, out shift values)\n",
        "\n",
        "Those are the bias and out shift values to replace in your project source file. If you project is based on the [official CMSIS-NN cifar10 example](https://github.com/ARM-software/CMSIS_5/tree/develop/CMSIS/NN/Examples/ARM/arm_nn_examples/cifar10), they are inside file `arm_nnexamples_cifar10_weights.h`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1Xb4ZmDqfxK",
        "colab_type": "code",
        "outputId": "0b0d07e1-eb1c-41ab-c69f-ab2933c9ecf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!cat examples/cifar10/code/m4_small/parameter.h | grep SHIFT"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#define CONV1_BIAS_LSHIFT 0\n",
            "#define CONV1_OUT_RSHIFT 9\n",
            "#define CONV2_BIAS_LSHIFT 0\n",
            "#define CONV2_OUT_RSHIFT 11\n",
            "#define CONV3_BIAS_LSHIFT 0\n",
            "#define CONV3_OUT_RSHIFT 8\n",
            "#define IP1_BIAS_LSHIFT 2\n",
            "#define IP1_OUT_RSHIFT 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kLn-fqZTh4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('examples/cifar10/cifar10_m4_small.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqiuHhz1iE6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}